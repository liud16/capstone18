{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import numpy as np\n",
    "import peakutils\n",
    "import syntheticdata\n",
    "import threegaussians\n",
    "import lorentzian\n",
    "from peakutils.plot import plot as pplot\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "from astropy.modeling import models, fitting\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Earth_Peakutils(nm_array, timedelay,threshold,min_dist):\n",
    "    import numpy\n",
    "    import matplotlib.pyplot as plt\n",
    "    from pyearth import Earth\n",
    "    \n",
    "    \"\"\"\n",
    "     ============================================\n",
    "     Plotting derivatives of simple sine function\n",
    "    ============================================\n",
    "\n",
    "     A simple example plotting a fit of the sine function\n",
    "    and the derivatives computed by Earth.\n",
    "    \n",
    "    Notes\n",
    "    -----   \n",
    "    generates a denoise curve from the TA data\n",
    "    Parameters\n",
    "    ----------\n",
    "        nm_array: wavelength array\n",
    "        timedelay: time delay array\n",
    "        noise_coefficient: the noise coefficients that user want to generate\n",
    "    Returns\n",
    "    -------\n",
    "        a smoothing curve from the original noise curve   \n",
    "    \"\"\"\n",
    "    # Create some fake data\n",
    "    # generate some noisy data from syntheticdata:\n",
    "    np.random.seed(1729)\n",
    "    y_noise = 0.1 * np.random.normal(size=nm_array.size)\n",
    "    ydata = timedelay + y_noise\n",
    "    \n",
    "   # Fit an Earth model\n",
    "    model = Earth(max_degree=2, minspan_alpha=.5, smooth=True)\n",
    "    model.fit(nm_array, ydata)\n",
    "    \n",
    "   # Get the predicted values and derivatives\n",
    "    y_hat = model.predict(nm_array)\n",
    "   \n",
    "    # use peakutils to find peak indexs\n",
    "    peak_indices_true = peakutils.indexes(timedelay, thres=threshold, min_dist=min_dist)\n",
    "    peak_indices_smooth = peakutils.indexes(y_hat, thres=threshold, min_dist=min_dist)\n",
    "    \n",
    "    return peak_indices_true,peak_indices_smooth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astropy_Peakutils(nm_array,timedelay,gg_init,threshold,min_dist):\n",
    "    # Generate fake data\n",
    "    np.random.seed(42)\n",
    "    ydata = timedelay + 0.1*np.random.normal(size=nm_array.size)\n",
    "    # Now to fit the data create a new superposition with initial\n",
    "    # guesses for the parameters:\n",
    "    fitter = fitting.SLSQPLSQFitter()\n",
    "    gg_fit = fitter(gg_init, nm_array, ydata)\n",
    "    # use peakutils to find peak\n",
    "    peak_indices_true = peakutils.indexes(timedelay, thres=threshold, min_dist=min_dist)\n",
    "    peak_indices_smooth = peakutils.indexes(gg_fit(nm_array), thres=threshold, min_dist=min_dist)\n",
    "  \n",
    "    return peak_indices_true,peak_indices_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astropy_Smoothing(nm_array,timedelay,noise_coefficient,gg_init):\n",
    "    # Generate fake data\n",
    "    np.random.seed(42)\n",
    "    ydata = timedelay + noise_coefficient*np.random.normal(size=nm_array.size)\n",
    "    # Now to fit the data create a new superposition with initial\n",
    "    # guesses for the parameters:\n",
    "    fitter = fitting.SLSQPLSQFitter()\n",
    "    gg_fit = fitter(gg_init, nm_array, ydata)\n",
    "  \n",
    "    return gg_fit(nm_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Earth_Smoothing(nm_array, y_array,noise_coefficient):        \n",
    "    \"\"\"\n",
    "    ============================================\n",
    "     Plotting derivatives of simple sine function\n",
    "    ============================================\n",
    "\n",
    "     A simple example plotting a fit of the sine function\n",
    "    and the derivatives computed by Earth.\n",
    "    \n",
    "    Notes\n",
    "    -----   \n",
    "    generates a denoise curve from the TA data\n",
    "    Parameters\n",
    "    ----------\n",
    "        nm_array: wavelength array\n",
    "        timedelay: time delay array\n",
    "        noise_coefficient: the noise coefficients that user want to generate\n",
    "    Returns\n",
    "    -------\n",
    "        a smoothing curve from the original noise curve   \n",
    "    \"\"\"\n",
    "    from pyearth import Earth\n",
    "   # Fit an Earth model\n",
    "    model = Earth(smooth=True)\n",
    "    np.random.seed(42)\n",
    "    ydata = y_array + noise_coefficient*np.random.normal(size=nm_array.size)\n",
    "    model.fit(nm_array, ydata)\n",
    "\n",
    "   # Print the model\n",
    "    #print(model.trace())\n",
    "    #print(model.summary())\n",
    "\n",
    "   # Get the predicted values and derivatives\n",
    "    y_hat = model.predict(nm_array)\n",
    "    \n",
    "    return  y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get noise data and smoothing data dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* astropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astropy_smooth_matrix(nm_array,data_matrix,noise_coefficient,gg_init):\n",
    "    num_array = np.shape(data_matrix)[0]\n",
    "    \n",
    "    smooth_matx = pd.DataFrame(np.empty((num_array,1)), columns = ['a'])\n",
    "    noise_matx = pd.DataFrame(np.empty((num_array,1)), columns = ['a'])\n",
    "    \n",
    "    for i in range(num_array):\n",
    "        data_array = data_matrix[:, i]\n",
    "        \n",
    "        # get noise and smooth list\n",
    "        noise_array = add_noise(nm_array, data_array, noise_coefficient).tolist()\n",
    "        smooth_array = astropy_Smoothing(nm_array,data_array,noise_coefficient,gg_init).tolist()\n",
    "        \n",
    "        # get noise dataframe\n",
    "        DF = pd.DataFrame(noise_array,columns = [i])\n",
    "        noise_matx = noise_matx.join(DF)\n",
    "        \n",
    "        # get smooth dataframe\n",
    "        df = pd.DataFrame(smooth_array,columns = [i])\n",
    "        smooth_matx = smooth_matx.join(df)\n",
    "        \n",
    "    # drop the first columns  \n",
    "    noise_matx = noise_matx.drop(columns='a')\n",
    "    smooth_matx = smooth_matx.drop(columns='a')\n",
    "        \n",
    "    return noise_matx, smooth_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7495624261835365\n",
      "            Iterations: 35\n",
      "            Function evaluations: 286\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749416522632002\n",
      "            Iterations: 26\n",
      "            Function evaluations: 213\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749433287148435\n",
      "            Iterations: 35\n",
      "            Function evaluations: 286\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749375198981689\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749431472957076\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749409344316003\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749200312059827\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749305522959776\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749341610095242\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749320229483381\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749404956209617\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749556728076309\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749288978968815\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749487160186972\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749579139834748\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7493488312673495\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749364788920609\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749548188186964\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749472460921579\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749476131671374\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749514754553356\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749526311860512\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749361347630389\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749290477323845\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749253530740409\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749440478050193\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749443685396146\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749262796585006\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749341489705365\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7495461039148665\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749321122123099\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749392845514771\n",
      "            Iterations: 35\n",
      "            Function evaluations: 284\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749352302227528\n",
      "            Iterations: 35\n",
      "            Function evaluations: 284\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749345670041293\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749337052502616\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749386666903677\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749403253158012\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74943937218452\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749231582258712\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749372560100794\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749372368294726\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749402007284543\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749120628475032\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749316680218414\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749372267100967\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749412093576252\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749271343513335\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749136486564211\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749301468876689\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74942842666794\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491513620241\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749236462064379\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749212430977229\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7493380702730725\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749245081925409\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749256913800864\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749183444840559\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7494621141373745\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749416384799405\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749270546505583\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749252247695248\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749408976222682\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749192207775534\n",
      "            Iterations: 37\n",
      "            Function evaluations: 302\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491359404989755\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749260313710795\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749185573649983\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749408035657625\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749106048821613\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748951735787758\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749184348914614\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749094885214447\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749205601135504\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491118257669065\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749382665544383\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749405903085465\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749165153052614\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749190553388953\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749211004743304\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749181534395437\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749093908424613\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748982964647777\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749130093999115\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749289068624899\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749215959618139\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491290293996045\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749187656405055\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491637041985815\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749159481774589\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7492333082193685\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749272297819244\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749027049491023\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749070979223582\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74926041809535\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749079371698109\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491312220013615\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748944514626919\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748953338636654\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749004311056142\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74901032493074\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7490293789098335\n",
      "            Iterations: 43\n",
      "            Function evaluations: 350\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749068920719398\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749091413623764\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74899359839679\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749064972149217\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748976949956735\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749055580667931\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748995725657107\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748982713191491\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748896960608702\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748946666030651\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748905525260417\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748865030148847\n",
      "            Iterations: 44\n",
      "            Function evaluations: 358\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748945989283872\n",
      "            Iterations: 44\n",
      "            Function evaluations: 358\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748907217388468\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748900689925913\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748781862721528\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748996624324925\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7488884416510055\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7487997602008925\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748782798182194\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748754145004412\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748900892978499\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748801029986401\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748746895082606\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748711363917186\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748880849885803\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748752416105077\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748661141921264\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748842285937474\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748800957790325\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748742193943585\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74879151595751\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748605768604892\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74865350621814\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748480403121148\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7486411060249765\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748586215762827\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748612924182304\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748686606096324\n",
      "            Iterations: 37\n",
      "            Function evaluations: 302\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748515350562538\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748582161065579\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748604476904286\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748535036984373\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748493560958088\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748494553291147\n",
      "            Iterations: 45\n",
      "            Function evaluations: 366\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7486679379897145\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748521223952126\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748383480228792\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748426698735318\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748398432277382\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748345433112869\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748429324636312\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7483030721013035\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748428494777546\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748261709256058\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748366767432577\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748337115588772\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748210239071977\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748194346193193\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74832111083588\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748252105176622\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748203925605677\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748257131080866\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748320284191468\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748188325741804\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748235462362633\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748063618358449\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748193669537185\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7481634494978975\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748093303325129\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74796916770591\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747916153442661\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7481260610394305\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747999012637914\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747889944000153\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7479975762430495\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747986711530788\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748082809598378\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747879808626496\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747916339284938\n",
      "            Iterations: 47\n",
      "            Function evaluations: 382\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747846955538366\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747849954216267\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747823668332578\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747770416060757\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747686724992781\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747855703114417\n",
      "            Iterations: 48\n",
      "            Function evaluations: 390\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7476844648464205\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747627729841216\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747831596706291\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747749359092728\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747608532795676\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747598379393086\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747657546871226\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747684996470715\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74765149262811\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747426959636813\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747541288826001\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747526752987696\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7475736323967626\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747478833351527\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747533390966419\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7473897531291\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74736378527109\n",
      "            Iterations: 48\n",
      "            Function evaluations: 390\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747430629208637\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747317194444093\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7473499754978885\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747372115786428\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747276954637641\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747259905378247\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747251807554061\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74720190978801\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747095326089495\n",
      "            Iterations: 45\n",
      "            Function evaluations: 366\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747185754238129\n",
      "            Iterations: 47\n",
      "            Function evaluations: 382\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747161905295105\n",
      "            Iterations: 49\n",
      "            Function evaluations: 398\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747165470199147\n",
      "            Iterations: 50\n",
      "            Function evaluations: 406\n",
      "            Gradient evaluations: 50\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747213469700437\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747101075867979\n",
      "            Iterations: 51\n",
      "            Function evaluations: 413\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7472346078466074\n",
      "            Iterations: 50\n",
      "            Function evaluations: 405\n",
      "            Gradient evaluations: 50\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747150564377902\n",
      "            Iterations: 42\n",
      "            Function evaluations: 343\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74716832458271\n",
      "            Iterations: 49\n",
      "            Function evaluations: 399\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747077209858885\n",
      "            Iterations: 51\n",
      "            Function evaluations: 413\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7471288813309584\n",
      "            Iterations: 51\n",
      "            Function evaluations: 413\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747196781960074\n",
      "            Iterations: 52\n",
      "            Function evaluations: 422\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747113668258866\n",
      "            Iterations: 52\n",
      "            Function evaluations: 422\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747193710651607\n",
      "            Iterations: 52\n",
      "            Function evaluations: 423\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747123568681408\n",
      "            Iterations: 52\n",
      "            Function evaluations: 422\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747212291286938\n",
      "            Iterations: 51\n",
      "            Function evaluations: 414\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747115155987256\n",
      "            Iterations: 51\n",
      "            Function evaluations: 414\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.750784644247817\n",
      "            Iterations: 37\n",
      "            Function evaluations: 303\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747046028868947\n",
      "            Iterations: 49\n",
      "            Function evaluations: 399\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7470167793812\n",
      "            Iterations: 51\n",
      "            Function evaluations: 415\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7471967642509725\n",
      "            Iterations: 52\n",
      "            Function evaluations: 422\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747226977064121\n",
      "            Iterations: 53\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747027836706405\n",
      "            Iterations: 53\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747121162495429\n",
      "            Iterations: 53\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747045021405496\n",
      "            Iterations: 50\n",
      "            Function evaluations: 407\n",
      "            Gradient evaluations: 50\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747113976982268\n",
      "            Iterations: 52\n",
      "            Function evaluations: 423\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747195678964372\n",
      "            Iterations: 50\n",
      "            Function evaluations: 406\n",
      "            Gradient evaluations: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747117122252923\n",
      "            Iterations: 49\n",
      "            Function evaluations: 398\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747102761675739\n",
      "            Iterations: 49\n",
      "            Function evaluations: 398\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751285750828931\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747392746246069\n",
      "            Iterations: 54\n",
      "            Function evaluations: 437\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74718397002313\n",
      "            Iterations: 54\n",
      "            Function evaluations: 437\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747215990424024\n",
      "            Iterations: 55\n",
      "            Function evaluations: 445\n",
      "            Gradient evaluations: 55\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747227714960811\n",
      "            Iterations: 55\n",
      "            Function evaluations: 445\n",
      "            Gradient evaluations: 55\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7471537547071865\n",
      "            Iterations: 53\n",
      "            Function evaluations: 429\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747239618660497\n",
      "            Iterations: 51\n",
      "            Function evaluations: 414\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7514626663894965\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751609588775356\n",
      "            Iterations: 37\n",
      "            Function evaluations: 302\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7472998440776175\n",
      "            Iterations: 53\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751665438147538\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747423072809673\n",
      "            Iterations: 54\n",
      "            Function evaluations: 438\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747393268405542\n",
      "            Iterations: 54\n",
      "            Function evaluations: 438\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7517479274923\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751849987135918\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751895991126965\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752018637158235\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751885938948294\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752031701492686\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752080098569529\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752143378003625\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747760562294637\n",
      "            Iterations: 55\n",
      "            Function evaluations: 447\n",
      "            Gradient evaluations: 55\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.75222644242307\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752176021150273\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752319589485917\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752387861634235\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7524175457280045\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752497823182225\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752425797201136\n",
      "            Iterations: 40\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752685116091097\n",
      "            Iterations: 40\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74811464558959\n",
      "            Iterations: 57\n",
      "            Function evaluations: 462\n",
      "            Gradient evaluations: 57\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748148043613547\n",
      "            Iterations: 56\n",
      "            Function evaluations: 454\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7481594000508895\n",
      "            Iterations: 57\n",
      "            Function evaluations: 462\n",
      "            Gradient evaluations: 57\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7482032650013135\n",
      "            Iterations: 56\n",
      "            Function evaluations: 455\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752874090009354\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.75289329308394\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752901892478635\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753073065157718\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753115752745154\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748707386310372\n",
      "            Iterations: 56\n",
      "            Function evaluations: 456\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748767697070375\n",
      "            Iterations: 57\n",
      "            Function evaluations: 462\n",
      "            Gradient evaluations: 57\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7487205795910725\n",
      "            Iterations: 56\n",
      "            Function evaluations: 454\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753346898094247\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.75330267004631\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753310979964867\n",
      "            Iterations: 35\n",
      "            Function evaluations: 287\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7489934172404284\n",
      "            Iterations: 56\n",
      "            Function evaluations: 454\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753625012449016\n",
      "            Iterations: 40\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753651799654451\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753706534030714\n",
      "            Iterations: 40\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753743463787355\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753834393858087\n",
      "            Iterations: 42\n",
      "            Function evaluations: 342\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749378044095565\n",
      "            Iterations: 58\n",
      "            Function evaluations: 470\n",
      "            Gradient evaluations: 58\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753853067676875\n",
      "            Iterations: 37\n",
      "            Function evaluations: 303\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754057983785377\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754086878579014\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754138762020551\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754211271061097\n",
      "            Iterations: 37\n",
      "            Function evaluations: 304\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754265798627566\n",
      "            Iterations: 40\n",
      "            Function evaluations: 328\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754405242881142\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7544590255311245\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754452547168025\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754561174650329\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754586061590451\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754719582057401\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754783768614982\n",
      "            Iterations: 38\n",
      "            Function evaluations: 311\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754913858495211\n",
      "            Iterations: 43\n",
      "            Function evaluations: 350\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754952621622719\n",
      "            Iterations: 43\n",
      "            Function evaluations: 352\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754962077313234\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7550128840354215\n",
      "            Iterations: 41\n",
      "            Function evaluations: 337\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755118647079288\n",
      "            Iterations: 38\n",
      "            Function evaluations: 312\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755032385797021\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7552122159279815\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7553800572646505\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755363030735204\n",
      "            Iterations: 38\n",
      "            Function evaluations: 312\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755553711604055\n",
      "            Iterations: 43\n",
      "            Function evaluations: 350\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755500459962966\n",
      "            Iterations: 42\n",
      "            Function evaluations: 342\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755633165255419\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755515675303961\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755657509661916\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755724289984852\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755840911030926\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755814705337782\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7559214949339275\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756080657413387\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7560975783965\n",
      "            Iterations: 45\n",
      "            Function evaluations: 366\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7561540878547355\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756364594640262\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772846333779112\n",
      "            Iterations: 29\n",
      "            Function evaluations: 237\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772830138071013\n",
      "            Iterations: 27\n",
      "            Function evaluations: 223\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756514583953676\n",
      "            Iterations: 45\n",
      "            Function evaluations: 367\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772896773172324\n",
      "            Iterations: 30\n",
      "            Function evaluations: 246\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756663961706618\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772916742272347\n",
      "            Iterations: 27\n",
      "            Function evaluations: 223\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756761095645025\n",
      "            Iterations: 44\n",
      "            Function evaluations: 359\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772895604833524\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756960026947854\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772936031880828\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7728940553616255\n",
      "            Iterations: 30\n",
      "            Function evaluations: 246\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772908338731893\n",
      "            Iterations: 29\n",
      "            Function evaluations: 237\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77286948480983\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772933774424264\n",
      "            Iterations: 30\n",
      "            Function evaluations: 246\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773068172536438\n",
      "            Iterations: 28\n",
      "            Function evaluations: 231\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772913853572449\n",
      "            Iterations: 29\n",
      "            Function evaluations: 239\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.757528491867862\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7730043141486975\n",
      "            Iterations: 29\n",
      "            Function evaluations: 239\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773008228934704\n",
      "            Iterations: 30\n",
      "            Function evaluations: 248\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7730224268167465\n",
      "            Iterations: 28\n",
      "            Function evaluations: 231\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773059377501074\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773041384830977\n",
      "            Iterations: 31\n",
      "            Function evaluations: 256\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773017374025967\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772961576311316\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773097477755426\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77313751798707\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773176143999249\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773139237893447\n",
      "            Iterations: 28\n",
      "            Function evaluations: 232\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773114966154575\n",
      "            Iterations: 29\n",
      "            Function evaluations: 238\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77311412793755\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773318663207655\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773146310854472\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773147992252777\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773329450015539\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773165324260232\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773290200179722\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773199245019052\n",
      "            Iterations: 32\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773219385397935\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7734277398837115\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773377931280914\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773228568014874\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773297133330447\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773416957576715\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773374047566849\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773367601758247\n",
      "            Iterations: 31\n",
      "            Function evaluations: 256\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773359871994581\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773465018011027\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773454735987348\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773380799621481\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773381319411396\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7735008458642865\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7734995569070096\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7735196138831775\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773558744780768\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773410254567464\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773493946537339\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773590818251513\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77355731919638\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77359683320087\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773565249698628\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773655239056619\n",
      "            Iterations: 34\n",
      "            Function evaluations: 280\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7736719155268075\n",
      "            Iterations: 32\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773625909102958\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773696208353428\n",
      "            Iterations: 30\n",
      "            Function evaluations: 248\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773754705096071\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773731143512379\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773676879914525\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773758199182567\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77358527448223\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77387972918667\n",
      "            Iterations: 32\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773681707468513\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773816475474296\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773783293994764\n",
      "            Iterations: 31\n",
      "            Function evaluations: 256\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773840196975427\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7737964928605106\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7738112430682165\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773852451574591\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773806594523434\n",
      "            Iterations: 31\n",
      "            Function evaluations: 258\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773933338217876\n",
      "            Iterations: 32\n",
      "            Function evaluations: 266\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773851300083674\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773909152720805\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773947712885036\n",
      "            Iterations: 32\n",
      "            Function evaluations: 265\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773940513543278\n",
      "            Iterations: 32\n",
      "            Function evaluations: 266\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773910178286139\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773954635413543\n",
      "            Iterations: 32\n",
      "            Function evaluations: 265\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774027854803709\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774031903899405\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774102402831328\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774015817032727\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773959731300182\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774066855640488\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774152025297214\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774092898163669\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774032002620352\n",
      "            Iterations: 32\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774139141445698\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774147515534414\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774182202270225\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774213700052295\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774323315235808\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77430592454492\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774147894310373\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774278412607508\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774284421567199\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774279829081984\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774255553306047\n",
      "            Iterations: 32\n",
      "            Function evaluations: 265\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774285404601775\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774254719478771\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774320854050344\n",
      "            Iterations: 32\n",
      "            Function evaluations: 265\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774403905042709\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774284561574538\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774356732235045\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774407306811416\n",
      "            Iterations: 32\n",
      "            Function evaluations: 266\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774465312610029\n",
      "            Iterations: 34\n",
      "            Function evaluations: 279\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774384021895722\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774395990397547\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774412121023855\n",
      "            Iterations: 29\n",
      "            Function evaluations: 242\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774513145250202\n",
      "            Iterations: 34\n",
      "            Function evaluations: 279\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774439560127461\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774520515175775\n",
      "            Iterations: 34\n",
      "            Function evaluations: 281\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774489585989851\n",
      "            Iterations: 34\n",
      "            Function evaluations: 282\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774484805827692\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774498809442136\n",
      "            Iterations: 34\n",
      "            Function evaluations: 280\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774536204159903\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774509354642108\n",
      "            Iterations: 34\n",
      "            Function evaluations: 281\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774516068974865\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774548013676938\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774554310154793\n",
      "            Iterations: 35\n",
      "            Function evaluations: 288\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774544111305115\n",
      "            Iterations: 35\n",
      "            Function evaluations: 288\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7746134902315305\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77460195953955\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774523575105703\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774654767722738\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774663250593441\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774602073529332\n",
      "            Iterations: 31\n",
      "            Function evaluations: 260\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774652238885522\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7746717439487565\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774667667494004\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774689665957936\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774689548882403\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77471568263059\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7747407480563595\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774739352996761\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77475405799699\n",
      "            Iterations: 36\n",
      "            Function evaluations: 297\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774769774421261\n",
      "            Iterations: 37\n",
      "            Function evaluations: 308\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774781691885833\n",
      "            Iterations: 36\n",
      "            Function evaluations: 300\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774782198734451\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774781185725278\n",
      "            Iterations: 35\n",
      "            Function evaluations: 290\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774778615319569\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774796725889008\n",
      "            Iterations: 37\n",
      "            Function evaluations: 307\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774820424037973\n",
      "            Iterations: 36\n",
      "            Function evaluations: 300\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774826078750889\n",
      "            Iterations: 35\n",
      "            Function evaluations: 290\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774841925358913\n",
      "            Iterations: 35\n",
      "            Function evaluations: 292\n",
      "            Gradient evaluations: 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774845555167865\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774851504280549\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774854701263748\n",
      "            Iterations: 34\n",
      "            Function evaluations: 281\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774885757388015\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774879286064013\n",
      "            Iterations: 37\n",
      "            Function evaluations: 306\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77488114433636\n",
      "            Iterations: 37\n",
      "            Function evaluations: 307\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774897549563491\n",
      "            Iterations: 37\n",
      "            Function evaluations: 308\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774899367988725\n",
      "            Iterations: 38\n",
      "            Function evaluations: 315\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774920393626444\n",
      "            Iterations: 37\n",
      "            Function evaluations: 306\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774931235444745\n",
      "            Iterations: 37\n",
      "            Function evaluations: 306\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774943113921643\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77495545178495\n",
      "            Iterations: 40\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7749503260616075\n",
      "            Iterations: 39\n",
      "            Function evaluations: 323\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7749635209348\n",
      "            Iterations: 38\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774981036601162\n",
      "            Iterations: 37\n",
      "            Function evaluations: 303\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7749909497776795\n",
      "            Iterations: 39\n",
      "            Function evaluations: 322\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.775014466572431\n",
      "            Iterations: 43\n",
      "            Function evaluations: 359\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7750121302733985\n",
      "            Iterations: 43\n",
      "            Function evaluations: 360\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.775016537879161\n",
      "            Iterations: 39\n",
      "            Function evaluations: 322\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.775045470466733\n",
      "            Iterations: 42\n",
      "            Function evaluations: 347\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.775052005884613\n",
      "            Iterations: 38\n",
      "            Function evaluations: 312\n",
      "            Gradient evaluations: 38\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 500 is out of bounds for axis 1 with size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-149-0e5856768489>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoise_matx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_matx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastropy_smooth_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatanm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataz_matx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgg_init\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-148-972652ba7702>\u001b[0m in \u001b[0;36mastropy_smooth_matrix\u001b[0;34m(nm_array, data_matrix, noise_coefficient, gg_init)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mdata_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# get noise and smooth list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 500 is out of bounds for axis 1 with size 500"
     ]
    }
   ],
   "source": [
    "noise_matx, smooth_matx = astropy_smooth_matrix(datanm,dataz_matx,0.1,gg_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'noise_matx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d7003b425c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoise_matx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'noise_matx' is not defined"
     ]
    }
   ],
   "source": [
    "noise_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619229</td>\n",
       "      <td>0.639381</td>\n",
       "      <td>0.632596</td>\n",
       "      <td>0.627576</td>\n",
       "      <td>0.621739</td>\n",
       "      <td>0.587789</td>\n",
       "      <td>0.581754</td>\n",
       "      <td>0.575493</td>\n",
       "      <td>0.600561</td>\n",
       "      <td>0.540163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049092</td>\n",
       "      <td>0.049046</td>\n",
       "      <td>0.049001</td>\n",
       "      <td>0.048956</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>0.048891</td>\n",
       "      <td>0.048847</td>\n",
       "      <td>0.048804</td>\n",
       "      <td>0.048762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.628734</td>\n",
       "      <td>0.647048</td>\n",
       "      <td>0.640308</td>\n",
       "      <td>0.635249</td>\n",
       "      <td>0.629414</td>\n",
       "      <td>0.597417</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.585167</td>\n",
       "      <td>0.608132</td>\n",
       "      <td>0.551522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>0.042777</td>\n",
       "      <td>0.042733</td>\n",
       "      <td>0.042691</td>\n",
       "      <td>0.042648</td>\n",
       "      <td>0.042682</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>0.042598</td>\n",
       "      <td>0.042557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.638239</td>\n",
       "      <td>0.654715</td>\n",
       "      <td>0.648020</td>\n",
       "      <td>0.642922</td>\n",
       "      <td>0.637089</td>\n",
       "      <td>0.607046</td>\n",
       "      <td>0.601043</td>\n",
       "      <td>0.594840</td>\n",
       "      <td>0.615704</td>\n",
       "      <td>0.562880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036639</td>\n",
       "      <td>0.036595</td>\n",
       "      <td>0.036552</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.036432</td>\n",
       "      <td>0.036391</td>\n",
       "      <td>0.036352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.647744</td>\n",
       "      <td>0.662381</td>\n",
       "      <td>0.655732</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.644765</td>\n",
       "      <td>0.616675</td>\n",
       "      <td>0.610687</td>\n",
       "      <td>0.604514</td>\n",
       "      <td>0.623275</td>\n",
       "      <td>0.574239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030412</td>\n",
       "      <td>0.030369</td>\n",
       "      <td>0.030328</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.030206</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.030224</td>\n",
       "      <td>0.030185</td>\n",
       "      <td>0.030146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.657248</td>\n",
       "      <td>0.670048</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>0.658268</td>\n",
       "      <td>0.652440</td>\n",
       "      <td>0.626303</td>\n",
       "      <td>0.620332</td>\n",
       "      <td>0.614187</td>\n",
       "      <td>0.630847</td>\n",
       "      <td>0.585598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024186</td>\n",
       "      <td>0.024144</td>\n",
       "      <td>0.024103</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.023941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666753</td>\n",
       "      <td>0.677715</td>\n",
       "      <td>0.671157</td>\n",
       "      <td>0.665941</td>\n",
       "      <td>0.660115</td>\n",
       "      <td>0.635932</td>\n",
       "      <td>0.629976</td>\n",
       "      <td>0.623861</td>\n",
       "      <td>0.638418</td>\n",
       "      <td>0.596956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.017801</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0.017846</td>\n",
       "      <td>0.017809</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>0.017736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.676258</td>\n",
       "      <td>0.685382</td>\n",
       "      <td>0.678869</td>\n",
       "      <td>0.673614</td>\n",
       "      <td>0.667790</td>\n",
       "      <td>0.645561</td>\n",
       "      <td>0.639620</td>\n",
       "      <td>0.633535</td>\n",
       "      <td>0.645989</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011733</td>\n",
       "      <td>0.011693</td>\n",
       "      <td>0.011654</td>\n",
       "      <td>0.011616</td>\n",
       "      <td>0.011579</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.011531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.685763</td>\n",
       "      <td>0.693049</td>\n",
       "      <td>0.686581</td>\n",
       "      <td>0.681287</td>\n",
       "      <td>0.675466</td>\n",
       "      <td>0.655189</td>\n",
       "      <td>0.649265</td>\n",
       "      <td>0.643208</td>\n",
       "      <td>0.653561</td>\n",
       "      <td>0.619674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.005325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.695267</td>\n",
       "      <td>0.700716</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.688960</td>\n",
       "      <td>0.683141</td>\n",
       "      <td>0.664818</td>\n",
       "      <td>0.658909</td>\n",
       "      <td>0.652882</td>\n",
       "      <td>0.661132</td>\n",
       "      <td>0.631033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>-0.000617</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>-0.000686</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.000635</td>\n",
       "      <td>-0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.704772</td>\n",
       "      <td>0.708382</td>\n",
       "      <td>0.702005</td>\n",
       "      <td>0.696633</td>\n",
       "      <td>0.690816</td>\n",
       "      <td>0.674447</td>\n",
       "      <td>0.668554</td>\n",
       "      <td>0.662555</td>\n",
       "      <td>0.668704</td>\n",
       "      <td>0.642391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006096</td>\n",
       "      <td>-0.006134</td>\n",
       "      <td>-0.006170</td>\n",
       "      <td>-0.006206</td>\n",
       "      <td>-0.006240</td>\n",
       "      <td>-0.006273</td>\n",
       "      <td>-0.006145</td>\n",
       "      <td>-0.006178</td>\n",
       "      <td>-0.006211</td>\n",
       "      <td>-0.006242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.714277</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.709717</td>\n",
       "      <td>0.704306</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.684075</td>\n",
       "      <td>0.678198</td>\n",
       "      <td>0.672229</td>\n",
       "      <td>0.676275</td>\n",
       "      <td>0.653750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011274</td>\n",
       "      <td>-0.011312</td>\n",
       "      <td>-0.011348</td>\n",
       "      <td>-0.011383</td>\n",
       "      <td>-0.011417</td>\n",
       "      <td>-0.011450</td>\n",
       "      <td>-0.011313</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-0.011378</td>\n",
       "      <td>-0.011409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.723781</td>\n",
       "      <td>0.723716</td>\n",
       "      <td>0.717429</td>\n",
       "      <td>0.711979</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>0.693704</td>\n",
       "      <td>0.687842</td>\n",
       "      <td>0.681903</td>\n",
       "      <td>0.683847</td>\n",
       "      <td>0.665109</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016051</td>\n",
       "      <td>-0.016089</td>\n",
       "      <td>-0.016125</td>\n",
       "      <td>-0.016161</td>\n",
       "      <td>-0.016195</td>\n",
       "      <td>-0.016227</td>\n",
       "      <td>-0.016083</td>\n",
       "      <td>-0.016116</td>\n",
       "      <td>-0.016148</td>\n",
       "      <td>-0.016178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.733286</td>\n",
       "      <td>0.731383</td>\n",
       "      <td>0.725141</td>\n",
       "      <td>0.719652</td>\n",
       "      <td>0.713842</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.697487</td>\n",
       "      <td>0.691576</td>\n",
       "      <td>0.691418</td>\n",
       "      <td>0.676467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020438</td>\n",
       "      <td>-0.020476</td>\n",
       "      <td>-0.020512</td>\n",
       "      <td>-0.020548</td>\n",
       "      <td>-0.020582</td>\n",
       "      <td>-0.020615</td>\n",
       "      <td>-0.020464</td>\n",
       "      <td>-0.020497</td>\n",
       "      <td>-0.020530</td>\n",
       "      <td>-0.020560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.742791</td>\n",
       "      <td>0.739050</td>\n",
       "      <td>0.732853</td>\n",
       "      <td>0.727325</td>\n",
       "      <td>0.721518</td>\n",
       "      <td>0.712962</td>\n",
       "      <td>0.707131</td>\n",
       "      <td>0.701250</td>\n",
       "      <td>0.698989</td>\n",
       "      <td>0.687826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024443</td>\n",
       "      <td>-0.024482</td>\n",
       "      <td>-0.024520</td>\n",
       "      <td>-0.024556</td>\n",
       "      <td>-0.024591</td>\n",
       "      <td>-0.024624</td>\n",
       "      <td>-0.024468</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>-0.024534</td>\n",
       "      <td>-0.024565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.752296</td>\n",
       "      <td>0.746717</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.734998</td>\n",
       "      <td>0.729193</td>\n",
       "      <td>0.722590</td>\n",
       "      <td>0.716776</td>\n",
       "      <td>0.710923</td>\n",
       "      <td>0.706561</td>\n",
       "      <td>0.699185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028079</td>\n",
       "      <td>-0.028119</td>\n",
       "      <td>-0.028157</td>\n",
       "      <td>-0.028194</td>\n",
       "      <td>-0.028230</td>\n",
       "      <td>-0.028264</td>\n",
       "      <td>-0.028104</td>\n",
       "      <td>-0.028138</td>\n",
       "      <td>-0.028172</td>\n",
       "      <td>-0.028204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.761800</td>\n",
       "      <td>0.754383</td>\n",
       "      <td>0.748277</td>\n",
       "      <td>0.742671</td>\n",
       "      <td>0.736868</td>\n",
       "      <td>0.732219</td>\n",
       "      <td>0.726420</td>\n",
       "      <td>0.720597</td>\n",
       "      <td>0.714132</td>\n",
       "      <td>0.710544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031354</td>\n",
       "      <td>-0.031395</td>\n",
       "      <td>-0.031435</td>\n",
       "      <td>-0.031473</td>\n",
       "      <td>-0.031510</td>\n",
       "      <td>-0.031546</td>\n",
       "      <td>-0.031382</td>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.031452</td>\n",
       "      <td>-0.031485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.771305</td>\n",
       "      <td>0.762050</td>\n",
       "      <td>0.755990</td>\n",
       "      <td>0.750344</td>\n",
       "      <td>0.744543</td>\n",
       "      <td>0.741848</td>\n",
       "      <td>0.736064</td>\n",
       "      <td>0.730271</td>\n",
       "      <td>0.721704</td>\n",
       "      <td>0.721902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034280</td>\n",
       "      <td>-0.034323</td>\n",
       "      <td>-0.034364</td>\n",
       "      <td>-0.034404</td>\n",
       "      <td>-0.034442</td>\n",
       "      <td>-0.034479</td>\n",
       "      <td>-0.034314</td>\n",
       "      <td>-0.034351</td>\n",
       "      <td>-0.034387</td>\n",
       "      <td>-0.034421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.780810</td>\n",
       "      <td>0.769717</td>\n",
       "      <td>0.763702</td>\n",
       "      <td>0.758017</td>\n",
       "      <td>0.752219</td>\n",
       "      <td>0.751476</td>\n",
       "      <td>0.745709</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.729275</td>\n",
       "      <td>0.733261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036867</td>\n",
       "      <td>-0.036912</td>\n",
       "      <td>-0.036955</td>\n",
       "      <td>-0.036996</td>\n",
       "      <td>-0.037036</td>\n",
       "      <td>-0.037074</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.036947</td>\n",
       "      <td>-0.036985</td>\n",
       "      <td>-0.037021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.790315</td>\n",
       "      <td>0.777384</td>\n",
       "      <td>0.771414</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.759894</td>\n",
       "      <td>0.761105</td>\n",
       "      <td>0.755353</td>\n",
       "      <td>0.749618</td>\n",
       "      <td>0.736847</td>\n",
       "      <td>0.744620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039125</td>\n",
       "      <td>-0.039172</td>\n",
       "      <td>-0.039217</td>\n",
       "      <td>-0.039260</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>-0.039342</td>\n",
       "      <td>-0.039177</td>\n",
       "      <td>-0.039217</td>\n",
       "      <td>-0.039257</td>\n",
       "      <td>-0.039294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.799819</td>\n",
       "      <td>0.785051</td>\n",
       "      <td>0.779126</td>\n",
       "      <td>0.773363</td>\n",
       "      <td>0.767569</td>\n",
       "      <td>0.770734</td>\n",
       "      <td>0.764998</td>\n",
       "      <td>0.759291</td>\n",
       "      <td>0.744418</td>\n",
       "      <td>0.755978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041065</td>\n",
       "      <td>-0.041114</td>\n",
       "      <td>-0.041161</td>\n",
       "      <td>-0.041206</td>\n",
       "      <td>-0.041251</td>\n",
       "      <td>-0.041293</td>\n",
       "      <td>-0.041129</td>\n",
       "      <td>-0.041172</td>\n",
       "      <td>-0.041213</td>\n",
       "      <td>-0.041253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.809324</td>\n",
       "      <td>0.792718</td>\n",
       "      <td>0.786838</td>\n",
       "      <td>0.781036</td>\n",
       "      <td>0.775245</td>\n",
       "      <td>0.780362</td>\n",
       "      <td>0.774642</td>\n",
       "      <td>0.768965</td>\n",
       "      <td>0.751989</td>\n",
       "      <td>0.767337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.042748</td>\n",
       "      <td>-0.042798</td>\n",
       "      <td>-0.042845</td>\n",
       "      <td>-0.042892</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>-0.042775</td>\n",
       "      <td>-0.042820</td>\n",
       "      <td>-0.042864</td>\n",
       "      <td>-0.042906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.818829</td>\n",
       "      <td>0.800384</td>\n",
       "      <td>0.794550</td>\n",
       "      <td>0.788709</td>\n",
       "      <td>0.782920</td>\n",
       "      <td>0.789991</td>\n",
       "      <td>0.784287</td>\n",
       "      <td>0.778639</td>\n",
       "      <td>0.759561</td>\n",
       "      <td>0.778696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044030</td>\n",
       "      <td>-0.044085</td>\n",
       "      <td>-0.044137</td>\n",
       "      <td>-0.044188</td>\n",
       "      <td>-0.044237</td>\n",
       "      <td>-0.044285</td>\n",
       "      <td>-0.044126</td>\n",
       "      <td>-0.044173</td>\n",
       "      <td>-0.044219</td>\n",
       "      <td>-0.044264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.808051</td>\n",
       "      <td>0.802262</td>\n",
       "      <td>0.796382</td>\n",
       "      <td>0.790595</td>\n",
       "      <td>0.799620</td>\n",
       "      <td>0.793931</td>\n",
       "      <td>0.788312</td>\n",
       "      <td>0.767132</td>\n",
       "      <td>0.790055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045077</td>\n",
       "      <td>-0.045134</td>\n",
       "      <td>-0.045189</td>\n",
       "      <td>-0.045243</td>\n",
       "      <td>-0.045295</td>\n",
       "      <td>-0.045346</td>\n",
       "      <td>-0.045191</td>\n",
       "      <td>-0.045241</td>\n",
       "      <td>-0.045290</td>\n",
       "      <td>-0.045338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.815718</td>\n",
       "      <td>0.809974</td>\n",
       "      <td>0.804055</td>\n",
       "      <td>0.798270</td>\n",
       "      <td>0.809248</td>\n",
       "      <td>0.803575</td>\n",
       "      <td>0.797986</td>\n",
       "      <td>0.774704</td>\n",
       "      <td>0.801413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045847</td>\n",
       "      <td>-0.045907</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.046022</td>\n",
       "      <td>-0.046077</td>\n",
       "      <td>-0.046131</td>\n",
       "      <td>-0.045981</td>\n",
       "      <td>-0.046035</td>\n",
       "      <td>-0.046086</td>\n",
       "      <td>-0.046137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.847343</td>\n",
       "      <td>0.823385</td>\n",
       "      <td>0.817686</td>\n",
       "      <td>0.811729</td>\n",
       "      <td>0.805946</td>\n",
       "      <td>0.818877</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.807659</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.812772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046349</td>\n",
       "      <td>-0.046413</td>\n",
       "      <td>-0.046475</td>\n",
       "      <td>-0.046535</td>\n",
       "      <td>-0.046594</td>\n",
       "      <td>-0.046650</td>\n",
       "      <td>-0.046506</td>\n",
       "      <td>-0.046563</td>\n",
       "      <td>-0.046618</td>\n",
       "      <td>-0.046672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.856848</td>\n",
       "      <td>0.831052</td>\n",
       "      <td>0.825398</td>\n",
       "      <td>0.819402</td>\n",
       "      <td>0.813621</td>\n",
       "      <td>0.828506</td>\n",
       "      <td>0.822864</td>\n",
       "      <td>0.817333</td>\n",
       "      <td>0.789847</td>\n",
       "      <td>0.824131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046596</td>\n",
       "      <td>-0.046663</td>\n",
       "      <td>-0.046729</td>\n",
       "      <td>-0.046792</td>\n",
       "      <td>-0.046855</td>\n",
       "      <td>-0.046915</td>\n",
       "      <td>-0.046777</td>\n",
       "      <td>-0.046837</td>\n",
       "      <td>-0.046896</td>\n",
       "      <td>-0.046953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.866352</td>\n",
       "      <td>0.838785</td>\n",
       "      <td>0.833177</td>\n",
       "      <td>0.827139</td>\n",
       "      <td>0.821360</td>\n",
       "      <td>0.838134</td>\n",
       "      <td>0.832509</td>\n",
       "      <td>0.827007</td>\n",
       "      <td>0.797472</td>\n",
       "      <td>0.835205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.046668</td>\n",
       "      <td>-0.046737</td>\n",
       "      <td>-0.046804</td>\n",
       "      <td>-0.046870</td>\n",
       "      <td>-0.046934</td>\n",
       "      <td>-0.046804</td>\n",
       "      <td>-0.046868</td>\n",
       "      <td>-0.046930</td>\n",
       "      <td>-0.046990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.875857</td>\n",
       "      <td>0.846632</td>\n",
       "      <td>0.841069</td>\n",
       "      <td>0.834987</td>\n",
       "      <td>0.829207</td>\n",
       "      <td>0.847763</td>\n",
       "      <td>0.842153</td>\n",
       "      <td>0.836680</td>\n",
       "      <td>0.805188</td>\n",
       "      <td>0.845715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046362</td>\n",
       "      <td>-0.046437</td>\n",
       "      <td>-0.046510</td>\n",
       "      <td>-0.046581</td>\n",
       "      <td>-0.046651</td>\n",
       "      <td>-0.046719</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.046664</td>\n",
       "      <td>-0.046730</td>\n",
       "      <td>-0.046794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.885362</td>\n",
       "      <td>0.854564</td>\n",
       "      <td>0.849046</td>\n",
       "      <td>0.842918</td>\n",
       "      <td>0.837136</td>\n",
       "      <td>0.857392</td>\n",
       "      <td>0.851797</td>\n",
       "      <td>0.846354</td>\n",
       "      <td>0.812973</td>\n",
       "      <td>0.855669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045902</td>\n",
       "      <td>-0.045981</td>\n",
       "      <td>-0.046058</td>\n",
       "      <td>-0.046133</td>\n",
       "      <td>-0.046207</td>\n",
       "      <td>-0.046279</td>\n",
       "      <td>-0.046166</td>\n",
       "      <td>-0.046237</td>\n",
       "      <td>-0.046307</td>\n",
       "      <td>-0.046375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.894625</td>\n",
       "      <td>0.862553</td>\n",
       "      <td>0.857079</td>\n",
       "      <td>0.850903</td>\n",
       "      <td>0.845119</td>\n",
       "      <td>0.866783</td>\n",
       "      <td>0.861205</td>\n",
       "      <td>0.855791</td>\n",
       "      <td>0.820803</td>\n",
       "      <td>0.865073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045227</td>\n",
       "      <td>-0.045310</td>\n",
       "      <td>-0.045392</td>\n",
       "      <td>-0.045471</td>\n",
       "      <td>-0.045549</td>\n",
       "      <td>-0.045626</td>\n",
       "      <td>-0.045522</td>\n",
       "      <td>-0.045597</td>\n",
       "      <td>-0.045671</td>\n",
       "      <td>-0.045743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.227583</td>\n",
       "      <td>0.227506</td>\n",
       "      <td>0.225269</td>\n",
       "      <td>0.223033</td>\n",
       "      <td>0.220826</td>\n",
       "      <td>0.215201</td>\n",
       "      <td>0.213287</td>\n",
       "      <td>0.211122</td>\n",
       "      <td>0.208027</td>\n",
       "      <td>0.195976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>-0.000983</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>-0.000946</td>\n",
       "      <td>-0.000927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.225356</td>\n",
       "      <td>0.225687</td>\n",
       "      <td>0.223466</td>\n",
       "      <td>0.221247</td>\n",
       "      <td>0.219056</td>\n",
       "      <td>0.212981</td>\n",
       "      <td>0.211075</td>\n",
       "      <td>0.208931</td>\n",
       "      <td>0.206354</td>\n",
       "      <td>0.194603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.000971</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.223090</td>\n",
       "      <td>0.223848</td>\n",
       "      <td>0.221643</td>\n",
       "      <td>0.219440</td>\n",
       "      <td>0.217265</td>\n",
       "      <td>0.210776</td>\n",
       "      <td>0.208879</td>\n",
       "      <td>0.206755</td>\n",
       "      <td>0.204663</td>\n",
       "      <td>0.193212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>-0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.220784</td>\n",
       "      <td>0.221987</td>\n",
       "      <td>0.219799</td>\n",
       "      <td>0.217612</td>\n",
       "      <td>0.215454</td>\n",
       "      <td>0.208587</td>\n",
       "      <td>0.206699</td>\n",
       "      <td>0.204595</td>\n",
       "      <td>0.202954</td>\n",
       "      <td>0.191804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>-0.000967</td>\n",
       "      <td>-0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.218467</td>\n",
       "      <td>0.220106</td>\n",
       "      <td>0.217935</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.213622</td>\n",
       "      <td>0.206414</td>\n",
       "      <td>0.204535</td>\n",
       "      <td>0.202451</td>\n",
       "      <td>0.201226</td>\n",
       "      <td>0.190379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.000485</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.001010</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>-0.000975</td>\n",
       "      <td>-0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.216167</td>\n",
       "      <td>0.218204</td>\n",
       "      <td>0.216050</td>\n",
       "      <td>0.213896</td>\n",
       "      <td>0.211771</td>\n",
       "      <td>0.204256</td>\n",
       "      <td>0.202386</td>\n",
       "      <td>0.200322</td>\n",
       "      <td>0.199480</td>\n",
       "      <td>0.188936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000526</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.000984</td>\n",
       "      <td>-0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.213884</td>\n",
       "      <td>0.216281</td>\n",
       "      <td>0.214145</td>\n",
       "      <td>0.212007</td>\n",
       "      <td>0.209899</td>\n",
       "      <td>0.202114</td>\n",
       "      <td>0.200252</td>\n",
       "      <td>0.198208</td>\n",
       "      <td>0.197716</td>\n",
       "      <td>0.187475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.000482</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>-0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.211619</td>\n",
       "      <td>0.214338</td>\n",
       "      <td>0.212219</td>\n",
       "      <td>0.210099</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>0.199987</td>\n",
       "      <td>0.198135</td>\n",
       "      <td>0.196110</td>\n",
       "      <td>0.195945</td>\n",
       "      <td>0.186008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.000482</td>\n",
       "      <td>-0.001034</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>-0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.209371</td>\n",
       "      <td>0.212375</td>\n",
       "      <td>0.210273</td>\n",
       "      <td>0.208170</td>\n",
       "      <td>0.206096</td>\n",
       "      <td>0.197876</td>\n",
       "      <td>0.196032</td>\n",
       "      <td>0.194028</td>\n",
       "      <td>0.194179</td>\n",
       "      <td>0.184543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000564</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>-0.001027</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>-0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.207140</td>\n",
       "      <td>0.210391</td>\n",
       "      <td>0.208307</td>\n",
       "      <td>0.206222</td>\n",
       "      <td>0.204165</td>\n",
       "      <td>0.195780</td>\n",
       "      <td>0.193945</td>\n",
       "      <td>0.191960</td>\n",
       "      <td>0.192419</td>\n",
       "      <td>0.183083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>-0.000552</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>-0.001021</td>\n",
       "      <td>-0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.204926</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.206334</td>\n",
       "      <td>0.204266</td>\n",
       "      <td>0.202227</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.191874</td>\n",
       "      <td>0.189908</td>\n",
       "      <td>0.190665</td>\n",
       "      <td>0.181625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.001063</td>\n",
       "      <td>-0.001047</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>-0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.202729</td>\n",
       "      <td>0.206416</td>\n",
       "      <td>0.204368</td>\n",
       "      <td>0.202318</td>\n",
       "      <td>0.200296</td>\n",
       "      <td>0.191634</td>\n",
       "      <td>0.189817</td>\n",
       "      <td>0.187871</td>\n",
       "      <td>0.188915</td>\n",
       "      <td>0.180172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.000583</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.001074</td>\n",
       "      <td>-0.001058</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>-0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.200549</td>\n",
       "      <td>0.204440</td>\n",
       "      <td>0.202409</td>\n",
       "      <td>0.200376</td>\n",
       "      <td>0.198371</td>\n",
       "      <td>0.189584</td>\n",
       "      <td>0.187776</td>\n",
       "      <td>0.185849</td>\n",
       "      <td>0.187171</td>\n",
       "      <td>0.178722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>-0.001040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.198385</td>\n",
       "      <td>0.202469</td>\n",
       "      <td>0.200456</td>\n",
       "      <td>0.198441</td>\n",
       "      <td>0.196453</td>\n",
       "      <td>0.187550</td>\n",
       "      <td>0.185750</td>\n",
       "      <td>0.183842</td>\n",
       "      <td>0.185433</td>\n",
       "      <td>0.177275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000642</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>-0.000618</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>-0.001067</td>\n",
       "      <td>-0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.196239</td>\n",
       "      <td>0.200506</td>\n",
       "      <td>0.198511</td>\n",
       "      <td>0.196512</td>\n",
       "      <td>0.194542</td>\n",
       "      <td>0.185530</td>\n",
       "      <td>0.183740</td>\n",
       "      <td>0.181850</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.175833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>-0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.194109</td>\n",
       "      <td>0.198550</td>\n",
       "      <td>0.196572</td>\n",
       "      <td>0.194591</td>\n",
       "      <td>0.192638</td>\n",
       "      <td>0.183525</td>\n",
       "      <td>0.181744</td>\n",
       "      <td>0.179873</td>\n",
       "      <td>0.181973</td>\n",
       "      <td>0.174394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.000633</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>-0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.191997</td>\n",
       "      <td>0.196601</td>\n",
       "      <td>0.194641</td>\n",
       "      <td>0.192677</td>\n",
       "      <td>0.190741</td>\n",
       "      <td>0.181536</td>\n",
       "      <td>0.179763</td>\n",
       "      <td>0.177911</td>\n",
       "      <td>0.180252</td>\n",
       "      <td>0.172959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>-0.000654</td>\n",
       "      <td>-0.000642</td>\n",
       "      <td>-0.001135</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>-0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.194659</td>\n",
       "      <td>0.192716</td>\n",
       "      <td>0.190770</td>\n",
       "      <td>0.188851</td>\n",
       "      <td>0.179561</td>\n",
       "      <td>0.177798</td>\n",
       "      <td>0.175964</td>\n",
       "      <td>0.178536</td>\n",
       "      <td>0.171527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>-0.001150</td>\n",
       "      <td>-0.001136</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>-0.001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.187820</td>\n",
       "      <td>0.192725</td>\n",
       "      <td>0.190799</td>\n",
       "      <td>0.188869</td>\n",
       "      <td>0.186968</td>\n",
       "      <td>0.177602</td>\n",
       "      <td>0.175847</td>\n",
       "      <td>0.174031</td>\n",
       "      <td>0.176826</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>-0.000684</td>\n",
       "      <td>-0.001165</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>-0.001138</td>\n",
       "      <td>-0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.185757</td>\n",
       "      <td>0.190798</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.185092</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.173911</td>\n",
       "      <td>0.172114</td>\n",
       "      <td>0.175122</td>\n",
       "      <td>0.168676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>-0.001180</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>-0.001154</td>\n",
       "      <td>-0.001142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.183710</td>\n",
       "      <td>0.188877</td>\n",
       "      <td>0.186986</td>\n",
       "      <td>0.185091</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.173727</td>\n",
       "      <td>0.171990</td>\n",
       "      <td>0.170211</td>\n",
       "      <td>0.173424</td>\n",
       "      <td>0.167256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>-0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.181679</td>\n",
       "      <td>0.186965</td>\n",
       "      <td>0.185091</td>\n",
       "      <td>0.183212</td>\n",
       "      <td>0.181361</td>\n",
       "      <td>0.171812</td>\n",
       "      <td>0.170084</td>\n",
       "      <td>0.168323</td>\n",
       "      <td>0.171732</td>\n",
       "      <td>0.165840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>-0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.179665</td>\n",
       "      <td>0.185060</td>\n",
       "      <td>0.183203</td>\n",
       "      <td>0.181341</td>\n",
       "      <td>0.179507</td>\n",
       "      <td>0.169911</td>\n",
       "      <td>0.168193</td>\n",
       "      <td>0.166449</td>\n",
       "      <td>0.170045</td>\n",
       "      <td>0.164428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.000807</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.177666</td>\n",
       "      <td>0.183162</td>\n",
       "      <td>0.181322</td>\n",
       "      <td>0.179477</td>\n",
       "      <td>0.177660</td>\n",
       "      <td>0.168026</td>\n",
       "      <td>0.166316</td>\n",
       "      <td>0.164590</td>\n",
       "      <td>0.168365</td>\n",
       "      <td>0.163020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>-0.000799</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>-0.001243</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>-0.001207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.175684</td>\n",
       "      <td>0.181272</td>\n",
       "      <td>0.179449</td>\n",
       "      <td>0.177621</td>\n",
       "      <td>0.175820</td>\n",
       "      <td>0.166154</td>\n",
       "      <td>0.164454</td>\n",
       "      <td>0.162746</td>\n",
       "      <td>0.166691</td>\n",
       "      <td>0.161617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>-0.001258</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.173718</td>\n",
       "      <td>0.179389</td>\n",
       "      <td>0.177583</td>\n",
       "      <td>0.175772</td>\n",
       "      <td>0.173988</td>\n",
       "      <td>0.164298</td>\n",
       "      <td>0.162607</td>\n",
       "      <td>0.160916</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>0.160217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>-0.000849</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>-0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.171768</td>\n",
       "      <td>0.177514</td>\n",
       "      <td>0.175725</td>\n",
       "      <td>0.173930</td>\n",
       "      <td>0.172163</td>\n",
       "      <td>0.162456</td>\n",
       "      <td>0.160774</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.163362</td>\n",
       "      <td>0.158821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.001268</td>\n",
       "      <td>-0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.169834</td>\n",
       "      <td>0.175647</td>\n",
       "      <td>0.173875</td>\n",
       "      <td>0.172097</td>\n",
       "      <td>0.170346</td>\n",
       "      <td>0.160628</td>\n",
       "      <td>0.158955</td>\n",
       "      <td>0.157299</td>\n",
       "      <td>0.161706</td>\n",
       "      <td>0.157430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.000882</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>-0.001273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.167916</td>\n",
       "      <td>0.173788</td>\n",
       "      <td>0.172033</td>\n",
       "      <td>0.170271</td>\n",
       "      <td>0.168536</td>\n",
       "      <td>0.158815</td>\n",
       "      <td>0.157151</td>\n",
       "      <td>0.155512</td>\n",
       "      <td>0.160057</td>\n",
       "      <td>0.156042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>-0.001290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.166013</td>\n",
       "      <td>0.171936</td>\n",
       "      <td>0.170198</td>\n",
       "      <td>0.168453</td>\n",
       "      <td>0.166734</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>0.155361</td>\n",
       "      <td>0.153739</td>\n",
       "      <td>0.158415</td>\n",
       "      <td>0.154659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000955</td>\n",
       "      <td>-0.000947</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>-0.001306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.619229  0.639381  0.632596  0.627576  0.621739  0.587789  0.581754   \n",
       "1    0.628734  0.647048  0.640308  0.635249  0.629414  0.597417  0.591398   \n",
       "2    0.638239  0.654715  0.648020  0.642922  0.637089  0.607046  0.601043   \n",
       "3    0.647744  0.662381  0.655732  0.650595  0.644765  0.616675  0.610687   \n",
       "4    0.657248  0.670048  0.663444  0.658268  0.652440  0.626303  0.620332   \n",
       "5    0.666753  0.677715  0.671157  0.665941  0.660115  0.635932  0.629976   \n",
       "6    0.676258  0.685382  0.678869  0.673614  0.667790  0.645561  0.639620   \n",
       "7    0.685763  0.693049  0.686581  0.681287  0.675466  0.655189  0.649265   \n",
       "8    0.695267  0.700716  0.694293  0.688960  0.683141  0.664818  0.658909   \n",
       "9    0.704772  0.708382  0.702005  0.696633  0.690816  0.674447  0.668554   \n",
       "10   0.714277  0.716049  0.709717  0.704306  0.698492  0.684075  0.678198   \n",
       "11   0.723781  0.723716  0.717429  0.711979  0.706167  0.693704  0.687842   \n",
       "12   0.733286  0.731383  0.725141  0.719652  0.713842  0.703333  0.697487   \n",
       "13   0.742791  0.739050  0.732853  0.727325  0.721518  0.712962  0.707131   \n",
       "14   0.752296  0.746717  0.740565  0.734998  0.729193  0.722590  0.716776   \n",
       "15   0.761800  0.754383  0.748277  0.742671  0.736868  0.732219  0.726420   \n",
       "16   0.771305  0.762050  0.755990  0.750344  0.744543  0.741848  0.736064   \n",
       "17   0.780810  0.769717  0.763702  0.758017  0.752219  0.751476  0.745709   \n",
       "18   0.790315  0.777384  0.771414  0.765690  0.759894  0.761105  0.755353   \n",
       "19   0.799819  0.785051  0.779126  0.773363  0.767569  0.770734  0.764998   \n",
       "20   0.809324  0.792718  0.786838  0.781036  0.775245  0.780362  0.774642   \n",
       "21   0.818829  0.800384  0.794550  0.788709  0.782920  0.789991  0.784287   \n",
       "22   0.828333  0.808051  0.802262  0.796382  0.790595  0.799620  0.793931   \n",
       "23   0.837838  0.815718  0.809974  0.804055  0.798270  0.809248  0.803575   \n",
       "24   0.847343  0.823385  0.817686  0.811729  0.805946  0.818877  0.813220   \n",
       "25   0.856848  0.831052  0.825398  0.819402  0.813621  0.828506  0.822864   \n",
       "26   0.866352  0.838785  0.833177  0.827139  0.821360  0.838134  0.832509   \n",
       "27   0.875857  0.846632  0.841069  0.834987  0.829207  0.847763  0.842153   \n",
       "28   0.885362  0.854564  0.849046  0.842918  0.837136  0.857392  0.851797   \n",
       "29   0.894625  0.862553  0.857079  0.850903  0.845119  0.866783  0.861205   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "470  0.227583  0.227506  0.225269  0.223033  0.220826  0.215201  0.213287   \n",
       "471  0.225356  0.225687  0.223466  0.221247  0.219056  0.212981  0.211075   \n",
       "472  0.223090  0.223848  0.221643  0.219440  0.217265  0.210776  0.208879   \n",
       "473  0.220784  0.221987  0.219799  0.217612  0.215454  0.208587  0.206699   \n",
       "474  0.218467  0.220106  0.217935  0.215764  0.213622  0.206414  0.204535   \n",
       "475  0.216167  0.218204  0.216050  0.213896  0.211771  0.204256  0.202386   \n",
       "476  0.213884  0.216281  0.214145  0.212007  0.209899  0.202114  0.200252   \n",
       "477  0.211619  0.214338  0.212219  0.210099  0.208008  0.199987  0.198135   \n",
       "478  0.209371  0.212375  0.210273  0.208170  0.206096  0.197876  0.196032   \n",
       "479  0.207140  0.210391  0.208307  0.206222  0.204165  0.195780  0.193945   \n",
       "480  0.204926  0.208400  0.206334  0.204266  0.202227  0.193700  0.191874   \n",
       "481  0.202729  0.206416  0.204368  0.202318  0.200296  0.191634  0.189817   \n",
       "482  0.200549  0.204440  0.202409  0.200376  0.198371  0.189584  0.187776   \n",
       "483  0.198385  0.202469  0.200456  0.198441  0.196453  0.187550  0.185750   \n",
       "484  0.196239  0.200506  0.198511  0.196512  0.194542  0.185530  0.183740   \n",
       "485  0.194109  0.198550  0.196572  0.194591  0.192638  0.183525  0.181744   \n",
       "486  0.191997  0.196601  0.194641  0.192677  0.190741  0.181536  0.179763   \n",
       "487  0.189900  0.194659  0.192716  0.190770  0.188851  0.179561  0.177798   \n",
       "488  0.187820  0.192725  0.190799  0.188869  0.186968  0.177602  0.175847   \n",
       "489  0.185757  0.190798  0.188889  0.186976  0.185092  0.175657  0.173911   \n",
       "490  0.183710  0.188877  0.186986  0.185091  0.183223  0.173727  0.171990   \n",
       "491  0.181679  0.186965  0.185091  0.183212  0.181361  0.171812  0.170084   \n",
       "492  0.179665  0.185060  0.183203  0.181341  0.179507  0.169911  0.168193   \n",
       "493  0.177666  0.183162  0.181322  0.179477  0.177660  0.168026  0.166316   \n",
       "494  0.175684  0.181272  0.179449  0.177621  0.175820  0.166154  0.164454   \n",
       "495  0.173718  0.179389  0.177583  0.175772  0.173988  0.164298  0.162607   \n",
       "496  0.171768  0.177514  0.175725  0.173930  0.172163  0.162456  0.160774   \n",
       "497  0.169834  0.175647  0.173875  0.172097  0.170346  0.160628  0.158955   \n",
       "498  0.167916  0.173788  0.172033  0.170271  0.168536  0.158815  0.157151   \n",
       "499  0.166013  0.171936  0.170198  0.168453  0.166734  0.157016  0.155361   \n",
       "\n",
       "          7         8         9      ...          490       491       492  \\\n",
       "0    0.575493  0.600561  0.540163    ...     0.049092  0.049046  0.049001   \n",
       "1    0.585167  0.608132  0.551522    ...     0.042865  0.042821  0.042777   \n",
       "2    0.594840  0.615704  0.562880    ...     0.036639  0.036595  0.036552   \n",
       "3    0.604514  0.623275  0.574239    ...     0.030412  0.030369  0.030328   \n",
       "4    0.614187  0.630847  0.585598    ...     0.024186  0.024144  0.024103   \n",
       "5    0.623861  0.638418  0.596956    ...     0.017959  0.017918  0.017879   \n",
       "6    0.633535  0.645989  0.608315    ...     0.011733  0.011693  0.011654   \n",
       "7    0.643208  0.653561  0.619674    ...     0.005506  0.005467  0.005429   \n",
       "8    0.652882  0.661132  0.631033    ...    -0.000506 -0.000544 -0.000581   \n",
       "9    0.662555  0.668704  0.642391    ...    -0.006096 -0.006134 -0.006170   \n",
       "10   0.672229  0.676275  0.653750    ...    -0.011274 -0.011312 -0.011348   \n",
       "11   0.681903  0.683847  0.665109    ...    -0.016051 -0.016089 -0.016125   \n",
       "12   0.691576  0.691418  0.676467    ...    -0.020438 -0.020476 -0.020512   \n",
       "13   0.701250  0.698989  0.687826    ...    -0.024443 -0.024482 -0.024520   \n",
       "14   0.710923  0.706561  0.699185    ...    -0.028079 -0.028119 -0.028157   \n",
       "15   0.720597  0.714132  0.710544    ...    -0.031354 -0.031395 -0.031435   \n",
       "16   0.730271  0.721704  0.721902    ...    -0.034280 -0.034323 -0.034364   \n",
       "17   0.739944  0.729275  0.733261    ...    -0.036867 -0.036912 -0.036955   \n",
       "18   0.749618  0.736847  0.744620    ...    -0.039125 -0.039172 -0.039217   \n",
       "19   0.759291  0.744418  0.755978    ...    -0.041065 -0.041114 -0.041161   \n",
       "20   0.768965  0.751989  0.767337    ...    -0.042697 -0.042748 -0.042798   \n",
       "21   0.778639  0.759561  0.778696    ...    -0.044030 -0.044085 -0.044137   \n",
       "22   0.788312  0.767132  0.790055    ...    -0.045077 -0.045134 -0.045189   \n",
       "23   0.797986  0.774704  0.801413    ...    -0.045847 -0.045907 -0.045965   \n",
       "24   0.807659  0.782275  0.812772    ...    -0.046349 -0.046413 -0.046475   \n",
       "25   0.817333  0.789847  0.824131    ...    -0.046596 -0.046663 -0.046729   \n",
       "26   0.827007  0.797472  0.835205    ...    -0.046597 -0.046668 -0.046737   \n",
       "27   0.836680  0.805188  0.845715    ...    -0.046362 -0.046437 -0.046510   \n",
       "28   0.846354  0.812973  0.855669    ...    -0.045902 -0.045981 -0.046058   \n",
       "29   0.855791  0.820803  0.865073    ...    -0.045227 -0.045310 -0.045392   \n",
       "..        ...       ...       ...    ...          ...       ...       ...   \n",
       "470  0.211122  0.208027  0.195976    ...    -0.000475 -0.000459 -0.000443   \n",
       "471  0.208931  0.206354  0.194603    ...    -0.000484 -0.000468 -0.000453   \n",
       "472  0.206755  0.204663  0.193212    ...    -0.000494 -0.000478 -0.000463   \n",
       "473  0.204595  0.202954  0.191804    ...    -0.000504 -0.000489 -0.000474   \n",
       "474  0.202451  0.201226  0.190379    ...    -0.000514 -0.000500 -0.000485   \n",
       "475  0.200322  0.199480  0.188936    ...    -0.000526 -0.000511 -0.000497   \n",
       "476  0.198208  0.197716  0.187475    ...    -0.000538 -0.000524 -0.000510   \n",
       "477  0.196110  0.195945  0.186008    ...    -0.000551 -0.000537 -0.000523   \n",
       "478  0.194028  0.194179  0.184543    ...    -0.000564 -0.000550 -0.000537   \n",
       "479  0.191960  0.192419  0.183083    ...    -0.000578 -0.000565 -0.000552   \n",
       "480  0.189908  0.190665  0.181625    ...    -0.000593 -0.000580 -0.000567   \n",
       "481  0.187871  0.188915  0.180172    ...    -0.000608 -0.000596 -0.000583   \n",
       "482  0.185849  0.187171  0.178722    ...    -0.000625 -0.000613 -0.000600   \n",
       "483  0.183842  0.185433  0.177275    ...    -0.000642 -0.000630 -0.000618   \n",
       "484  0.181850  0.183700  0.175833    ...    -0.000660 -0.000648 -0.000637   \n",
       "485  0.179873  0.181973  0.174394    ...    -0.000679 -0.000667 -0.000656   \n",
       "486  0.177911  0.180252  0.172959    ...    -0.000698 -0.000687 -0.000676   \n",
       "487  0.175964  0.178536  0.171527    ...    -0.000718 -0.000707 -0.000696   \n",
       "488  0.174031  0.176826  0.170100    ...    -0.000738 -0.000727 -0.000716   \n",
       "489  0.172114  0.175122  0.168676    ...    -0.000758 -0.000747 -0.000737   \n",
       "490  0.170211  0.173424  0.167256    ...    -0.000777 -0.000767 -0.000757   \n",
       "491  0.168323  0.171732  0.165840    ...    -0.000797 -0.000787 -0.000777   \n",
       "492  0.166449  0.170045  0.164428    ...    -0.000817 -0.000807 -0.000797   \n",
       "493  0.164590  0.168365  0.163020    ...    -0.000836 -0.000827 -0.000818   \n",
       "494  0.162746  0.166691  0.161617    ...    -0.000856 -0.000847 -0.000838   \n",
       "495  0.160916  0.165023  0.160217    ...    -0.000876 -0.000867 -0.000858   \n",
       "496  0.159100  0.163362  0.158821    ...    -0.000896 -0.000887 -0.000878   \n",
       "497  0.157299  0.161706  0.157430    ...    -0.000915 -0.000907 -0.000899   \n",
       "498  0.155512  0.160057  0.156042    ...    -0.000935 -0.000927 -0.000919   \n",
       "499  0.153739  0.158415  0.154659    ...    -0.000955 -0.000947 -0.000939   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    0.048956  0.048913  0.048869  0.048891  0.048847  0.048804  0.048762  \n",
       "1    0.042733  0.042691  0.042648  0.042682  0.042640  0.042598  0.042557  \n",
       "2    0.036510  0.036468  0.036427  0.036473  0.036432  0.036391  0.036352  \n",
       "3    0.030286  0.030246  0.030206  0.030264  0.030224  0.030185  0.030146  \n",
       "4    0.024063  0.024024  0.023985  0.024055  0.024016  0.023978  0.023941  \n",
       "5    0.017839  0.017801  0.017764  0.017846  0.017809  0.017772  0.017736  \n",
       "6    0.011616  0.011579  0.011543  0.011637  0.011601  0.011565  0.011531  \n",
       "7    0.005392  0.005357  0.005321  0.005428  0.005393  0.005359  0.005325  \n",
       "8   -0.000617 -0.000652 -0.000686 -0.000568 -0.000602 -0.000635 -0.000667  \n",
       "9   -0.006206 -0.006240 -0.006273 -0.006145 -0.006178 -0.006211 -0.006242  \n",
       "10  -0.011383 -0.011417 -0.011450 -0.011313 -0.011346 -0.011378 -0.011409  \n",
       "11  -0.016161 -0.016195 -0.016227 -0.016083 -0.016116 -0.016148 -0.016178  \n",
       "12  -0.020548 -0.020582 -0.020615 -0.020464 -0.020497 -0.020530 -0.020560  \n",
       "13  -0.024556 -0.024591 -0.024624 -0.024468 -0.024502 -0.024534 -0.024565  \n",
       "14  -0.028194 -0.028230 -0.028264 -0.028104 -0.028138 -0.028172 -0.028204  \n",
       "15  -0.031473 -0.031510 -0.031546 -0.031382 -0.031418 -0.031452 -0.031485  \n",
       "16  -0.034404 -0.034442 -0.034479 -0.034314 -0.034351 -0.034387 -0.034421  \n",
       "17  -0.036996 -0.037036 -0.037074 -0.036909 -0.036947 -0.036985 -0.037021  \n",
       "18  -0.039260 -0.039302 -0.039342 -0.039177 -0.039217 -0.039257 -0.039294  \n",
       "19  -0.041206 -0.041251 -0.041293 -0.041129 -0.041172 -0.041213 -0.041253  \n",
       "20  -0.042845 -0.042892 -0.042937 -0.042775 -0.042820 -0.042864 -0.042906  \n",
       "21  -0.044188 -0.044237 -0.044285 -0.044126 -0.044173 -0.044219 -0.044264  \n",
       "22  -0.045243 -0.045295 -0.045346 -0.045191 -0.045241 -0.045290 -0.045338  \n",
       "23  -0.046022 -0.046077 -0.046131 -0.045981 -0.046035 -0.046086 -0.046137  \n",
       "24  -0.046535 -0.046594 -0.046650 -0.046506 -0.046563 -0.046618 -0.046672  \n",
       "25  -0.046792 -0.046855 -0.046915 -0.046777 -0.046837 -0.046896 -0.046953  \n",
       "26  -0.046804 -0.046870 -0.046934 -0.046804 -0.046868 -0.046930 -0.046990  \n",
       "27  -0.046581 -0.046651 -0.046719 -0.046597 -0.046664 -0.046730 -0.046794  \n",
       "28  -0.046133 -0.046207 -0.046279 -0.046166 -0.046237 -0.046307 -0.046375  \n",
       "29  -0.045471 -0.045549 -0.045626 -0.045522 -0.045597 -0.045671 -0.045743  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "470 -0.000427 -0.000411 -0.000396 -0.000983 -0.000964 -0.000946 -0.000927  \n",
       "471 -0.000437 -0.000422 -0.000406 -0.000989 -0.000971 -0.000953 -0.000934  \n",
       "472 -0.000448 -0.000433 -0.000417 -0.000996 -0.000978 -0.000960 -0.000942  \n",
       "473 -0.000459 -0.000444 -0.000429 -0.001003 -0.000985 -0.000967 -0.000950  \n",
       "474 -0.000470 -0.000456 -0.000441 -0.001010 -0.000992 -0.000975 -0.000958  \n",
       "475 -0.000483 -0.000469 -0.000454 -0.001017 -0.001000 -0.000984 -0.000967  \n",
       "476 -0.000496 -0.000482 -0.000468 -0.001026 -0.001009 -0.000992 -0.000976  \n",
       "477 -0.000509 -0.000496 -0.000482 -0.001034 -0.001018 -0.001002 -0.000985  \n",
       "478 -0.000524 -0.000510 -0.000497 -0.001043 -0.001027 -0.001011 -0.000995  \n",
       "479 -0.000539 -0.000525 -0.000512 -0.001053 -0.001037 -0.001021 -0.001006  \n",
       "480 -0.000554 -0.000541 -0.000529 -0.001063 -0.001047 -0.001032 -0.001017  \n",
       "481 -0.000571 -0.000558 -0.000546 -0.001074 -0.001058 -0.001043 -0.001028  \n",
       "482 -0.000588 -0.000576 -0.000563 -0.001085 -0.001070 -0.001055 -0.001040  \n",
       "483 -0.000606 -0.000594 -0.000582 -0.001096 -0.001082 -0.001067 -0.001053  \n",
       "484 -0.000625 -0.000613 -0.000601 -0.001109 -0.001095 -0.001080 -0.001066  \n",
       "485 -0.000644 -0.000633 -0.000622 -0.001122 -0.001108 -0.001094 -0.001080  \n",
       "486 -0.000665 -0.000654 -0.000642 -0.001135 -0.001122 -0.001108 -0.001095  \n",
       "487 -0.000685 -0.000674 -0.000663 -0.001150 -0.001136 -0.001123 -0.001110  \n",
       "488 -0.000706 -0.000695 -0.000684 -0.001165 -0.001151 -0.001138 -0.001125  \n",
       "489 -0.000726 -0.000716 -0.000705 -0.001180 -0.001167 -0.001154 -0.001142  \n",
       "490 -0.000747 -0.000737 -0.000726 -0.001196 -0.001183 -0.001171 -0.001158  \n",
       "491 -0.000767 -0.000757 -0.000747 -0.001211 -0.001199 -0.001187 -0.001175  \n",
       "492 -0.000788 -0.000778 -0.000768 -0.001227 -0.001215 -0.001203 -0.001191  \n",
       "493 -0.000808 -0.000799 -0.000789 -0.001243 -0.001231 -0.001219 -0.001207  \n",
       "494 -0.000829 -0.000820 -0.000810 -0.001258 -0.001247 -0.001235 -0.001224  \n",
       "495 -0.000849 -0.000840 -0.000831 -0.001274 -0.001263 -0.001251 -0.001240  \n",
       "496 -0.000870 -0.000861 -0.000852 -0.001289 -0.001278 -0.001268 -0.001257  \n",
       "497 -0.000890 -0.000882 -0.000873 -0.001305 -0.001294 -0.001284 -0.001273  \n",
       "498 -0.000911 -0.000903 -0.000894 -0.001321 -0.001310 -0.001300 -0.001290  \n",
       "499 -0.000931 -0.000923 -0.000915 -0.001336 -0.001326 -0.001316 -0.001306  \n",
       "\n",
       "[500 rows x 500 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_matx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* py-earth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earth_smooth_matrix(nm_array,data_matrix,noise_coefficient):\n",
    "    num_array = np.shape(data_matrix)[0]\n",
    "    \n",
    "    smooth_matx = pd.DataFrame(np.empty((num_array,1)), columns = ['a'])\n",
    "    noise_matx = pd.DataFrame(np.empty((num_array,1)), columns = ['a'])\n",
    "    \n",
    "    for i in range(num_array):\n",
    "        data_array = data_matrix[:, i]\n",
    "        \n",
    "        # get noise and smooth list\n",
    "        noise_array = add_noise(nm_array, data_array, noise_coefficient).tolist()\n",
    "        smooth_array =earth_Smoothing(nm_array,data_array,noise_coefficient).tolist()\n",
    "        \n",
    "        # get noise dataframe\n",
    "        DF = pd.DataFrame(noise_array,columns = [i])\n",
    "        noise_matx = noise_matx.join(DF)\n",
    "        \n",
    "        # get smooth dataframe\n",
    "        df = pd.DataFrame(smooth_array,columns = [i])\n",
    "        smooth_matx = smooth_matx.join(df)\n",
    "        \n",
    "    # drop the first columns  \n",
    "    noise_matx = noise_matx.drop(columns='a')\n",
    "    smooth_matx = smooth_matx.drop(columns='a')\n",
    "        \n",
    "    return noise_matx, smooth_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datanm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-73b93b796033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnoisez_matx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmooth_matx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mearth_smooth_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatanm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataz_matx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'datanm' is not defined"
     ]
    }
   ],
   "source": [
    "noisez_matx, smooth_matx = earth_smooth_matrix(datanm,dataz_matx,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.642958</td>\n",
       "      <td>0.637558</td>\n",
       "      <td>0.632158</td>\n",
       "      <td>0.626758</td>\n",
       "      <td>0.621458</td>\n",
       "      <td>0.616158</td>\n",
       "      <td>0.610958</td>\n",
       "      <td>0.605758</td>\n",
       "      <td>0.600558</td>\n",
       "      <td>0.595458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037439</td>\n",
       "      <td>0.037421</td>\n",
       "      <td>0.037403</td>\n",
       "      <td>0.037385</td>\n",
       "      <td>0.037368</td>\n",
       "      <td>0.037351</td>\n",
       "      <td>0.037335</td>\n",
       "      <td>0.037318</td>\n",
       "      <td>0.037302</td>\n",
       "      <td>0.037286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750254</td>\n",
       "      <td>0.744754</td>\n",
       "      <td>0.739254</td>\n",
       "      <td>0.733854</td>\n",
       "      <td>0.728454</td>\n",
       "      <td>0.723154</td>\n",
       "      <td>0.717754</td>\n",
       "      <td>0.712554</td>\n",
       "      <td>0.707354</td>\n",
       "      <td>0.702154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.132581</td>\n",
       "      <td>0.132563</td>\n",
       "      <td>0.132544</td>\n",
       "      <td>0.132526</td>\n",
       "      <td>0.132508</td>\n",
       "      <td>0.132490</td>\n",
       "      <td>0.132473</td>\n",
       "      <td>0.132456</td>\n",
       "      <td>0.132440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.516295</td>\n",
       "      <td>0.510695</td>\n",
       "      <td>0.505195</td>\n",
       "      <td>0.499695</td>\n",
       "      <td>0.494295</td>\n",
       "      <td>0.488895</td>\n",
       "      <td>0.483495</td>\n",
       "      <td>0.478195</td>\n",
       "      <td>0.472895</td>\n",
       "      <td>0.467695</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.113389</td>\n",
       "      <td>-0.113410</td>\n",
       "      <td>-0.113429</td>\n",
       "      <td>-0.113449</td>\n",
       "      <td>-0.113468</td>\n",
       "      <td>-0.113487</td>\n",
       "      <td>-0.113505</td>\n",
       "      <td>-0.113524</td>\n",
       "      <td>-0.113542</td>\n",
       "      <td>-0.113559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.594156</td>\n",
       "      <td>0.588556</td>\n",
       "      <td>0.582956</td>\n",
       "      <td>0.577456</td>\n",
       "      <td>0.571956</td>\n",
       "      <td>0.566456</td>\n",
       "      <td>0.561056</td>\n",
       "      <td>0.555656</td>\n",
       "      <td>0.550356</td>\n",
       "      <td>0.545056</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.047556</td>\n",
       "      <td>-0.047577</td>\n",
       "      <td>-0.047598</td>\n",
       "      <td>-0.047618</td>\n",
       "      <td>-0.047638</td>\n",
       "      <td>-0.047658</td>\n",
       "      <td>-0.047678</td>\n",
       "      <td>-0.047697</td>\n",
       "      <td>-0.047716</td>\n",
       "      <td>-0.047735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.727119</td>\n",
       "      <td>0.721419</td>\n",
       "      <td>0.715819</td>\n",
       "      <td>0.710219</td>\n",
       "      <td>0.704619</td>\n",
       "      <td>0.699119</td>\n",
       "      <td>0.693619</td>\n",
       "      <td>0.688219</td>\n",
       "      <td>0.682819</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073384</td>\n",
       "      <td>0.073362</td>\n",
       "      <td>0.073340</td>\n",
       "      <td>0.073318</td>\n",
       "      <td>0.073297</td>\n",
       "      <td>0.073276</td>\n",
       "      <td>0.073255</td>\n",
       "      <td>0.073235</td>\n",
       "      <td>0.073214</td>\n",
       "      <td>0.073195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.660581</td>\n",
       "      <td>0.654881</td>\n",
       "      <td>0.649181</td>\n",
       "      <td>0.643581</td>\n",
       "      <td>0.637981</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.626881</td>\n",
       "      <td>0.621381</td>\n",
       "      <td>0.615881</td>\n",
       "      <td>0.610481</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005073</td>\n",
       "      <td>-0.005097</td>\n",
       "      <td>-0.005120</td>\n",
       "      <td>-0.005143</td>\n",
       "      <td>-0.005165</td>\n",
       "      <td>-0.005188</td>\n",
       "      <td>-0.005209</td>\n",
       "      <td>-0.005231</td>\n",
       "      <td>-0.005252</td>\n",
       "      <td>-0.005273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.863220</td>\n",
       "      <td>0.857420</td>\n",
       "      <td>0.851720</td>\n",
       "      <td>0.846020</td>\n",
       "      <td>0.840320</td>\n",
       "      <td>0.834720</td>\n",
       "      <td>0.829220</td>\n",
       "      <td>0.823620</td>\n",
       "      <td>0.818120</td>\n",
       "      <td>0.812620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185650</td>\n",
       "      <td>0.185626</td>\n",
       "      <td>0.185601</td>\n",
       "      <td>0.185577</td>\n",
       "      <td>0.185553</td>\n",
       "      <td>0.185530</td>\n",
       "      <td>0.185507</td>\n",
       "      <td>0.185484</td>\n",
       "      <td>0.185462</td>\n",
       "      <td>0.185440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.703915</td>\n",
       "      <td>0.698115</td>\n",
       "      <td>0.692315</td>\n",
       "      <td>0.686615</td>\n",
       "      <td>0.680915</td>\n",
       "      <td>0.675215</td>\n",
       "      <td>0.669615</td>\n",
       "      <td>0.664015</td>\n",
       "      <td>0.658515</td>\n",
       "      <td>0.652915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014535</td>\n",
       "      <td>0.014508</td>\n",
       "      <td>0.014483</td>\n",
       "      <td>0.014457</td>\n",
       "      <td>0.014432</td>\n",
       "      <td>0.014408</td>\n",
       "      <td>0.014383</td>\n",
       "      <td>0.014360</td>\n",
       "      <td>0.014336</td>\n",
       "      <td>0.014313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.871805</td>\n",
       "      <td>0.865905</td>\n",
       "      <td>0.860105</td>\n",
       "      <td>0.854305</td>\n",
       "      <td>0.848605</td>\n",
       "      <td>0.842805</td>\n",
       "      <td>0.837205</td>\n",
       "      <td>0.831505</td>\n",
       "      <td>0.825905</td>\n",
       "      <td>0.820405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170618</td>\n",
       "      <td>0.170591</td>\n",
       "      <td>0.170564</td>\n",
       "      <td>0.170537</td>\n",
       "      <td>0.170511</td>\n",
       "      <td>0.170485</td>\n",
       "      <td>0.170459</td>\n",
       "      <td>0.170434</td>\n",
       "      <td>0.170409</td>\n",
       "      <td>0.170385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.807060</td>\n",
       "      <td>0.801160</td>\n",
       "      <td>0.795360</td>\n",
       "      <td>0.789460</td>\n",
       "      <td>0.783760</td>\n",
       "      <td>0.777960</td>\n",
       "      <td>0.772260</td>\n",
       "      <td>0.766560</td>\n",
       "      <td>0.760960</td>\n",
       "      <td>0.755360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094271</td>\n",
       "      <td>0.094243</td>\n",
       "      <td>0.094214</td>\n",
       "      <td>0.094186</td>\n",
       "      <td>0.094158</td>\n",
       "      <td>0.094131</td>\n",
       "      <td>0.094104</td>\n",
       "      <td>0.094078</td>\n",
       "      <td>0.094052</td>\n",
       "      <td>0.094026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.689850</td>\n",
       "      <td>0.683950</td>\n",
       "      <td>0.678050</td>\n",
       "      <td>0.672150</td>\n",
       "      <td>0.666350</td>\n",
       "      <td>0.660550</td>\n",
       "      <td>0.654750</td>\n",
       "      <td>0.649050</td>\n",
       "      <td>0.643350</td>\n",
       "      <td>0.637750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034535</td>\n",
       "      <td>-0.034566</td>\n",
       "      <td>-0.034596</td>\n",
       "      <td>-0.034625</td>\n",
       "      <td>-0.034655</td>\n",
       "      <td>-0.034683</td>\n",
       "      <td>-0.034711</td>\n",
       "      <td>-0.034739</td>\n",
       "      <td>-0.034767</td>\n",
       "      <td>-0.034794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.893187</td>\n",
       "      <td>0.887187</td>\n",
       "      <td>0.881287</td>\n",
       "      <td>0.875387</td>\n",
       "      <td>0.869487</td>\n",
       "      <td>0.863687</td>\n",
       "      <td>0.857887</td>\n",
       "      <td>0.852087</td>\n",
       "      <td>0.846387</td>\n",
       "      <td>0.840687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.157310</td>\n",
       "      <td>0.157278</td>\n",
       "      <td>0.157246</td>\n",
       "      <td>0.157215</td>\n",
       "      <td>0.157185</td>\n",
       "      <td>0.157154</td>\n",
       "      <td>0.157125</td>\n",
       "      <td>0.157095</td>\n",
       "      <td>0.157067</td>\n",
       "      <td>0.157038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.818009</td>\n",
       "      <td>0.812009</td>\n",
       "      <td>0.806009</td>\n",
       "      <td>0.800109</td>\n",
       "      <td>0.794209</td>\n",
       "      <td>0.788409</td>\n",
       "      <td>0.782509</td>\n",
       "      <td>0.776709</td>\n",
       "      <td>0.771009</td>\n",
       "      <td>0.765309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070845</td>\n",
       "      <td>0.070812</td>\n",
       "      <td>0.070779</td>\n",
       "      <td>0.070746</td>\n",
       "      <td>0.070714</td>\n",
       "      <td>0.070682</td>\n",
       "      <td>0.070651</td>\n",
       "      <td>0.070620</td>\n",
       "      <td>0.070590</td>\n",
       "      <td>0.070560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.947519</td>\n",
       "      <td>0.941419</td>\n",
       "      <td>0.935419</td>\n",
       "      <td>0.929419</td>\n",
       "      <td>0.923519</td>\n",
       "      <td>0.917619</td>\n",
       "      <td>0.911819</td>\n",
       "      <td>0.905919</td>\n",
       "      <td>0.900219</td>\n",
       "      <td>0.894419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189074</td>\n",
       "      <td>0.189039</td>\n",
       "      <td>0.189004</td>\n",
       "      <td>0.188970</td>\n",
       "      <td>0.188936</td>\n",
       "      <td>0.188903</td>\n",
       "      <td>0.188870</td>\n",
       "      <td>0.188837</td>\n",
       "      <td>0.188806</td>\n",
       "      <td>0.188774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.561685</td>\n",
       "      <td>0.555685</td>\n",
       "      <td>0.549585</td>\n",
       "      <td>0.543685</td>\n",
       "      <td>0.537685</td>\n",
       "      <td>0.531785</td>\n",
       "      <td>0.525885</td>\n",
       "      <td>0.519985</td>\n",
       "      <td>0.514185</td>\n",
       "      <td>0.508385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207735</td>\n",
       "      <td>-0.207772</td>\n",
       "      <td>-0.207809</td>\n",
       "      <td>-0.207845</td>\n",
       "      <td>-0.207880</td>\n",
       "      <td>-0.207915</td>\n",
       "      <td>-0.207950</td>\n",
       "      <td>-0.207984</td>\n",
       "      <td>-0.208017</td>\n",
       "      <td>-0.208050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.696854</td>\n",
       "      <td>0.690754</td>\n",
       "      <td>0.684654</td>\n",
       "      <td>0.678654</td>\n",
       "      <td>0.672654</td>\n",
       "      <td>0.666754</td>\n",
       "      <td>0.660854</td>\n",
       "      <td>0.654954</td>\n",
       "      <td>0.649054</td>\n",
       "      <td>0.643254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083535</td>\n",
       "      <td>-0.083574</td>\n",
       "      <td>-0.083613</td>\n",
       "      <td>-0.083651</td>\n",
       "      <td>-0.083688</td>\n",
       "      <td>-0.083725</td>\n",
       "      <td>-0.083761</td>\n",
       "      <td>-0.083797</td>\n",
       "      <td>-0.083832</td>\n",
       "      <td>-0.083866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.635469</td>\n",
       "      <td>0.629369</td>\n",
       "      <td>0.623269</td>\n",
       "      <td>0.617169</td>\n",
       "      <td>0.611169</td>\n",
       "      <td>0.605269</td>\n",
       "      <td>0.599269</td>\n",
       "      <td>0.593369</td>\n",
       "      <td>0.587469</td>\n",
       "      <td>0.581669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.155684</td>\n",
       "      <td>-0.155725</td>\n",
       "      <td>-0.155765</td>\n",
       "      <td>-0.155805</td>\n",
       "      <td>-0.155844</td>\n",
       "      <td>-0.155882</td>\n",
       "      <td>-0.155920</td>\n",
       "      <td>-0.155958</td>\n",
       "      <td>-0.155995</td>\n",
       "      <td>-0.156031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.874754</td>\n",
       "      <td>0.868654</td>\n",
       "      <td>0.862554</td>\n",
       "      <td>0.856454</td>\n",
       "      <td>0.850454</td>\n",
       "      <td>0.844454</td>\n",
       "      <td>0.838454</td>\n",
       "      <td>0.832554</td>\n",
       "      <td>0.826654</td>\n",
       "      <td>0.820754</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073044</td>\n",
       "      <td>0.073001</td>\n",
       "      <td>0.072959</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>0.072876</td>\n",
       "      <td>0.072836</td>\n",
       "      <td>0.072796</td>\n",
       "      <td>0.072757</td>\n",
       "      <td>0.072718</td>\n",
       "      <td>0.072680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.938265</td>\n",
       "      <td>0.932165</td>\n",
       "      <td>0.926065</td>\n",
       "      <td>0.919965</td>\n",
       "      <td>0.913865</td>\n",
       "      <td>0.907865</td>\n",
       "      <td>0.901865</td>\n",
       "      <td>0.895965</td>\n",
       "      <td>0.890065</td>\n",
       "      <td>0.884165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126205</td>\n",
       "      <td>0.126160</td>\n",
       "      <td>0.126115</td>\n",
       "      <td>0.126072</td>\n",
       "      <td>0.126029</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.125944</td>\n",
       "      <td>0.125903</td>\n",
       "      <td>0.125863</td>\n",
       "      <td>0.125823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.938089</td>\n",
       "      <td>0.931889</td>\n",
       "      <td>0.925789</td>\n",
       "      <td>0.919689</td>\n",
       "      <td>0.913589</td>\n",
       "      <td>0.907589</td>\n",
       "      <td>0.901589</td>\n",
       "      <td>0.895589</td>\n",
       "      <td>0.889689</td>\n",
       "      <td>0.883789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115785</td>\n",
       "      <td>0.115738</td>\n",
       "      <td>0.115691</td>\n",
       "      <td>0.115646</td>\n",
       "      <td>0.115600</td>\n",
       "      <td>0.115556</td>\n",
       "      <td>0.115512</td>\n",
       "      <td>0.115469</td>\n",
       "      <td>0.115426</td>\n",
       "      <td>0.115384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.717956</td>\n",
       "      <td>0.711756</td>\n",
       "      <td>0.705656</td>\n",
       "      <td>0.699556</td>\n",
       "      <td>0.693456</td>\n",
       "      <td>0.687456</td>\n",
       "      <td>0.681456</td>\n",
       "      <td>0.675456</td>\n",
       "      <td>0.669556</td>\n",
       "      <td>0.663556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.114285</td>\n",
       "      <td>-0.114334</td>\n",
       "      <td>-0.114383</td>\n",
       "      <td>-0.114431</td>\n",
       "      <td>-0.114478</td>\n",
       "      <td>-0.114525</td>\n",
       "      <td>-0.114570</td>\n",
       "      <td>-0.114616</td>\n",
       "      <td>-0.114660</td>\n",
       "      <td>-0.114704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.755214</td>\n",
       "      <td>0.749014</td>\n",
       "      <td>0.742914</td>\n",
       "      <td>0.736814</td>\n",
       "      <td>0.730714</td>\n",
       "      <td>0.724714</td>\n",
       "      <td>0.718614</td>\n",
       "      <td>0.712714</td>\n",
       "      <td>0.706714</td>\n",
       "      <td>0.700814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086756</td>\n",
       "      <td>-0.086808</td>\n",
       "      <td>-0.086859</td>\n",
       "      <td>-0.086909</td>\n",
       "      <td>-0.086959</td>\n",
       "      <td>-0.087007</td>\n",
       "      <td>-0.087055</td>\n",
       "      <td>-0.087103</td>\n",
       "      <td>-0.087150</td>\n",
       "      <td>-0.087196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.673962</td>\n",
       "      <td>0.667762</td>\n",
       "      <td>0.661662</td>\n",
       "      <td>0.655562</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.643362</td>\n",
       "      <td>0.637362</td>\n",
       "      <td>0.631362</td>\n",
       "      <td>0.625462</td>\n",
       "      <td>0.619462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177530</td>\n",
       "      <td>-0.177584</td>\n",
       "      <td>-0.177638</td>\n",
       "      <td>-0.177690</td>\n",
       "      <td>-0.177742</td>\n",
       "      <td>-0.177793</td>\n",
       "      <td>-0.177843</td>\n",
       "      <td>-0.177893</td>\n",
       "      <td>-0.177942</td>\n",
       "      <td>-0.177990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.942117</td>\n",
       "      <td>0.935917</td>\n",
       "      <td>0.929817</td>\n",
       "      <td>0.923617</td>\n",
       "      <td>0.917617</td>\n",
       "      <td>0.911517</td>\n",
       "      <td>0.905517</td>\n",
       "      <td>0.899517</td>\n",
       "      <td>0.893517</td>\n",
       "      <td>0.887617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>0.081254</td>\n",
       "      <td>0.081198</td>\n",
       "      <td>0.081143</td>\n",
       "      <td>0.081089</td>\n",
       "      <td>0.081036</td>\n",
       "      <td>0.080983</td>\n",
       "      <td>0.080931</td>\n",
       "      <td>0.080880</td>\n",
       "      <td>0.080829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.887098</td>\n",
       "      <td>0.880898</td>\n",
       "      <td>0.874798</td>\n",
       "      <td>0.868698</td>\n",
       "      <td>0.862598</td>\n",
       "      <td>0.856498</td>\n",
       "      <td>0.850498</td>\n",
       "      <td>0.844498</td>\n",
       "      <td>0.838598</td>\n",
       "      <td>0.832598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017285</td>\n",
       "      <td>0.017226</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>0.017110</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.016998</td>\n",
       "      <td>0.016943</td>\n",
       "      <td>0.016888</td>\n",
       "      <td>0.016835</td>\n",
       "      <td>0.016782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.080096</td>\n",
       "      <td>1.073896</td>\n",
       "      <td>1.067796</td>\n",
       "      <td>1.061696</td>\n",
       "      <td>1.055596</td>\n",
       "      <td>1.049496</td>\n",
       "      <td>1.043496</td>\n",
       "      <td>1.037496</td>\n",
       "      <td>1.031596</td>\n",
       "      <td>1.025596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201485</td>\n",
       "      <td>0.201423</td>\n",
       "      <td>0.201362</td>\n",
       "      <td>0.201302</td>\n",
       "      <td>0.201243</td>\n",
       "      <td>0.201185</td>\n",
       "      <td>0.201127</td>\n",
       "      <td>0.201070</td>\n",
       "      <td>0.201014</td>\n",
       "      <td>0.200959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.891969</td>\n",
       "      <td>0.885769</td>\n",
       "      <td>0.879669</td>\n",
       "      <td>0.873569</td>\n",
       "      <td>0.867469</td>\n",
       "      <td>0.861469</td>\n",
       "      <td>0.855469</td>\n",
       "      <td>0.849469</td>\n",
       "      <td>0.843469</td>\n",
       "      <td>0.837569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.004677</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004554</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.004435</td>\n",
       "      <td>0.004376</td>\n",
       "      <td>0.004319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.865321</td>\n",
       "      <td>0.859121</td>\n",
       "      <td>0.853021</td>\n",
       "      <td>0.846921</td>\n",
       "      <td>0.840921</td>\n",
       "      <td>0.834921</td>\n",
       "      <td>0.828921</td>\n",
       "      <td>0.822921</td>\n",
       "      <td>0.816921</td>\n",
       "      <td>0.811021</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029961</td>\n",
       "      <td>-0.030028</td>\n",
       "      <td>-0.030094</td>\n",
       "      <td>-0.030160</td>\n",
       "      <td>-0.030225</td>\n",
       "      <td>-0.030288</td>\n",
       "      <td>-0.030351</td>\n",
       "      <td>-0.030413</td>\n",
       "      <td>-0.030475</td>\n",
       "      <td>-0.030535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.896608</td>\n",
       "      <td>0.890508</td>\n",
       "      <td>0.884408</td>\n",
       "      <td>0.878308</td>\n",
       "      <td>0.872308</td>\n",
       "      <td>0.866308</td>\n",
       "      <td>0.860308</td>\n",
       "      <td>0.854308</td>\n",
       "      <td>0.848408</td>\n",
       "      <td>0.842508</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006546</td>\n",
       "      <td>-0.006616</td>\n",
       "      <td>-0.006685</td>\n",
       "      <td>-0.006754</td>\n",
       "      <td>-0.006821</td>\n",
       "      <td>-0.006888</td>\n",
       "      <td>-0.006953</td>\n",
       "      <td>-0.007018</td>\n",
       "      <td>-0.007082</td>\n",
       "      <td>-0.007145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.929026</td>\n",
       "      <td>0.922926</td>\n",
       "      <td>0.916826</td>\n",
       "      <td>0.910726</td>\n",
       "      <td>0.904726</td>\n",
       "      <td>0.898726</td>\n",
       "      <td>0.892726</td>\n",
       "      <td>0.886826</td>\n",
       "      <td>0.880926</td>\n",
       "      <td>0.875026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.017922</td>\n",
       "      <td>0.017853</td>\n",
       "      <td>0.017784</td>\n",
       "      <td>0.017717</td>\n",
       "      <td>0.017650</td>\n",
       "      <td>0.017584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.194598</td>\n",
       "      <td>0.192298</td>\n",
       "      <td>0.189998</td>\n",
       "      <td>0.187698</td>\n",
       "      <td>0.185398</td>\n",
       "      <td>0.183198</td>\n",
       "      <td>0.180898</td>\n",
       "      <td>0.178698</td>\n",
       "      <td>0.176598</td>\n",
       "      <td>0.174398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038453</td>\n",
       "      <td>-0.038471</td>\n",
       "      <td>-0.038488</td>\n",
       "      <td>-0.038505</td>\n",
       "      <td>-0.038522</td>\n",
       "      <td>-0.038539</td>\n",
       "      <td>-0.038555</td>\n",
       "      <td>-0.038572</td>\n",
       "      <td>-0.038588</td>\n",
       "      <td>-0.038604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.029057</td>\n",
       "      <td>0.026657</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.022157</td>\n",
       "      <td>0.019857</td>\n",
       "      <td>0.017657</td>\n",
       "      <td>0.015457</td>\n",
       "      <td>0.013257</td>\n",
       "      <td>0.011057</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.202407</td>\n",
       "      <td>-0.202424</td>\n",
       "      <td>-0.202441</td>\n",
       "      <td>-0.202458</td>\n",
       "      <td>-0.202475</td>\n",
       "      <td>-0.202491</td>\n",
       "      <td>-0.202508</td>\n",
       "      <td>-0.202524</td>\n",
       "      <td>-0.202540</td>\n",
       "      <td>-0.202556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.443439</td>\n",
       "      <td>0.441139</td>\n",
       "      <td>0.438839</td>\n",
       "      <td>0.436639</td>\n",
       "      <td>0.434339</td>\n",
       "      <td>0.432139</td>\n",
       "      <td>0.429939</td>\n",
       "      <td>0.427739</td>\n",
       "      <td>0.425639</td>\n",
       "      <td>0.423539</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213663</td>\n",
       "      <td>0.213646</td>\n",
       "      <td>0.213629</td>\n",
       "      <td>0.213612</td>\n",
       "      <td>0.213595</td>\n",
       "      <td>0.213579</td>\n",
       "      <td>0.213562</td>\n",
       "      <td>0.213546</td>\n",
       "      <td>0.213530</td>\n",
       "      <td>0.213515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.161617</td>\n",
       "      <td>0.159317</td>\n",
       "      <td>0.157117</td>\n",
       "      <td>0.154817</td>\n",
       "      <td>0.152617</td>\n",
       "      <td>0.150417</td>\n",
       "      <td>0.148217</td>\n",
       "      <td>0.146117</td>\n",
       "      <td>0.144017</td>\n",
       "      <td>0.141817</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066472</td>\n",
       "      <td>-0.066489</td>\n",
       "      <td>-0.066505</td>\n",
       "      <td>-0.066522</td>\n",
       "      <td>-0.066539</td>\n",
       "      <td>-0.066555</td>\n",
       "      <td>-0.066571</td>\n",
       "      <td>-0.066587</td>\n",
       "      <td>-0.066603</td>\n",
       "      <td>-0.066619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.367776</td>\n",
       "      <td>0.365576</td>\n",
       "      <td>0.363276</td>\n",
       "      <td>0.361076</td>\n",
       "      <td>0.358876</td>\n",
       "      <td>0.356676</td>\n",
       "      <td>0.354576</td>\n",
       "      <td>0.352376</td>\n",
       "      <td>0.350276</td>\n",
       "      <td>0.348176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141375</td>\n",
       "      <td>0.141358</td>\n",
       "      <td>0.141341</td>\n",
       "      <td>0.141325</td>\n",
       "      <td>0.141308</td>\n",
       "      <td>0.141292</td>\n",
       "      <td>0.141276</td>\n",
       "      <td>0.141260</td>\n",
       "      <td>0.141244</td>\n",
       "      <td>0.141229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>-0.074660</td>\n",
       "      <td>-0.076960</td>\n",
       "      <td>-0.079160</td>\n",
       "      <td>-0.081360</td>\n",
       "      <td>-0.083560</td>\n",
       "      <td>-0.085760</td>\n",
       "      <td>-0.087860</td>\n",
       "      <td>-0.090060</td>\n",
       "      <td>-0.092160</td>\n",
       "      <td>-0.094160</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.299474</td>\n",
       "      <td>-0.299490</td>\n",
       "      <td>-0.299507</td>\n",
       "      <td>-0.299524</td>\n",
       "      <td>-0.299540</td>\n",
       "      <td>-0.299556</td>\n",
       "      <td>-0.299572</td>\n",
       "      <td>-0.299588</td>\n",
       "      <td>-0.299603</td>\n",
       "      <td>-0.299619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.212663</td>\n",
       "      <td>0.210463</td>\n",
       "      <td>0.208263</td>\n",
       "      <td>0.206063</td>\n",
       "      <td>0.203863</td>\n",
       "      <td>0.201763</td>\n",
       "      <td>0.199663</td>\n",
       "      <td>0.197563</td>\n",
       "      <td>0.195463</td>\n",
       "      <td>0.193363</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010363</td>\n",
       "      <td>-0.010380</td>\n",
       "      <td>-0.010397</td>\n",
       "      <td>-0.010413</td>\n",
       "      <td>-0.010429</td>\n",
       "      <td>-0.010445</td>\n",
       "      <td>-0.010461</td>\n",
       "      <td>-0.010477</td>\n",
       "      <td>-0.010492</td>\n",
       "      <td>-0.010507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.088698</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.084298</td>\n",
       "      <td>0.082098</td>\n",
       "      <td>0.079998</td>\n",
       "      <td>0.077898</td>\n",
       "      <td>0.075698</td>\n",
       "      <td>0.073698</td>\n",
       "      <td>0.071598</td>\n",
       "      <td>0.069498</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.132641</td>\n",
       "      <td>-0.132658</td>\n",
       "      <td>-0.132674</td>\n",
       "      <td>-0.132690</td>\n",
       "      <td>-0.132706</td>\n",
       "      <td>-0.132722</td>\n",
       "      <td>-0.132738</td>\n",
       "      <td>-0.132753</td>\n",
       "      <td>-0.132769</td>\n",
       "      <td>-0.132784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.123390</td>\n",
       "      <td>0.121190</td>\n",
       "      <td>0.118990</td>\n",
       "      <td>0.116890</td>\n",
       "      <td>0.114690</td>\n",
       "      <td>0.112590</td>\n",
       "      <td>0.110490</td>\n",
       "      <td>0.108490</td>\n",
       "      <td>0.106390</td>\n",
       "      <td>0.104390</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096262</td>\n",
       "      <td>-0.096278</td>\n",
       "      <td>-0.096295</td>\n",
       "      <td>-0.096311</td>\n",
       "      <td>-0.096327</td>\n",
       "      <td>-0.096342</td>\n",
       "      <td>-0.096358</td>\n",
       "      <td>-0.096373</td>\n",
       "      <td>-0.096389</td>\n",
       "      <td>-0.096404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.239567</td>\n",
       "      <td>0.237367</td>\n",
       "      <td>0.235167</td>\n",
       "      <td>0.233067</td>\n",
       "      <td>0.230967</td>\n",
       "      <td>0.228867</td>\n",
       "      <td>0.226767</td>\n",
       "      <td>0.224667</td>\n",
       "      <td>0.222667</td>\n",
       "      <td>0.220667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021602</td>\n",
       "      <td>0.021586</td>\n",
       "      <td>0.021570</td>\n",
       "      <td>0.021554</td>\n",
       "      <td>0.021538</td>\n",
       "      <td>0.021522</td>\n",
       "      <td>0.021507</td>\n",
       "      <td>0.021492</td>\n",
       "      <td>0.021476</td>\n",
       "      <td>0.021461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.233948</td>\n",
       "      <td>0.231848</td>\n",
       "      <td>0.229648</td>\n",
       "      <td>0.227548</td>\n",
       "      <td>0.225448</td>\n",
       "      <td>0.223348</td>\n",
       "      <td>0.221348</td>\n",
       "      <td>0.219248</td>\n",
       "      <td>0.217248</td>\n",
       "      <td>0.215248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017770</td>\n",
       "      <td>0.017754</td>\n",
       "      <td>0.017738</td>\n",
       "      <td>0.017722</td>\n",
       "      <td>0.017707</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.017676</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>0.017645</td>\n",
       "      <td>0.017631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.382432</td>\n",
       "      <td>0.380232</td>\n",
       "      <td>0.378132</td>\n",
       "      <td>0.376032</td>\n",
       "      <td>0.373932</td>\n",
       "      <td>0.371932</td>\n",
       "      <td>0.369832</td>\n",
       "      <td>0.367832</td>\n",
       "      <td>0.365832</td>\n",
       "      <td>0.363832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167941</td>\n",
       "      <td>0.167925</td>\n",
       "      <td>0.167909</td>\n",
       "      <td>0.167894</td>\n",
       "      <td>0.167878</td>\n",
       "      <td>0.167863</td>\n",
       "      <td>0.167847</td>\n",
       "      <td>0.167832</td>\n",
       "      <td>0.167817</td>\n",
       "      <td>0.167803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.192031</td>\n",
       "      <td>0.189931</td>\n",
       "      <td>0.187831</td>\n",
       "      <td>0.185731</td>\n",
       "      <td>0.183631</td>\n",
       "      <td>0.181631</td>\n",
       "      <td>0.179631</td>\n",
       "      <td>0.177631</td>\n",
       "      <td>0.175631</td>\n",
       "      <td>0.173631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020673</td>\n",
       "      <td>-0.020689</td>\n",
       "      <td>-0.020704</td>\n",
       "      <td>-0.020720</td>\n",
       "      <td>-0.020735</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.020766</td>\n",
       "      <td>-0.020781</td>\n",
       "      <td>-0.020796</td>\n",
       "      <td>-0.020810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.183056</td>\n",
       "      <td>0.180956</td>\n",
       "      <td>0.178856</td>\n",
       "      <td>0.176756</td>\n",
       "      <td>0.174656</td>\n",
       "      <td>0.172656</td>\n",
       "      <td>0.170656</td>\n",
       "      <td>0.168656</td>\n",
       "      <td>0.166656</td>\n",
       "      <td>0.164756</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027961</td>\n",
       "      <td>-0.027977</td>\n",
       "      <td>-0.027992</td>\n",
       "      <td>-0.028008</td>\n",
       "      <td>-0.028023</td>\n",
       "      <td>-0.028038</td>\n",
       "      <td>-0.028053</td>\n",
       "      <td>-0.028068</td>\n",
       "      <td>-0.028083</td>\n",
       "      <td>-0.028097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.160880</td>\n",
       "      <td>0.158780</td>\n",
       "      <td>0.156680</td>\n",
       "      <td>0.154680</td>\n",
       "      <td>0.152580</td>\n",
       "      <td>0.150580</td>\n",
       "      <td>0.148580</td>\n",
       "      <td>0.146680</td>\n",
       "      <td>0.144680</td>\n",
       "      <td>0.142780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048350</td>\n",
       "      <td>-0.048366</td>\n",
       "      <td>-0.048381</td>\n",
       "      <td>-0.048397</td>\n",
       "      <td>-0.048412</td>\n",
       "      <td>-0.048427</td>\n",
       "      <td>-0.048442</td>\n",
       "      <td>-0.048456</td>\n",
       "      <td>-0.048471</td>\n",
       "      <td>-0.048485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.299381</td>\n",
       "      <td>0.297381</td>\n",
       "      <td>0.295281</td>\n",
       "      <td>0.293281</td>\n",
       "      <td>0.291181</td>\n",
       "      <td>0.289181</td>\n",
       "      <td>0.287281</td>\n",
       "      <td>0.285281</td>\n",
       "      <td>0.283381</td>\n",
       "      <td>0.281381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091938</td>\n",
       "      <td>0.091922</td>\n",
       "      <td>0.091907</td>\n",
       "      <td>0.091892</td>\n",
       "      <td>0.091877</td>\n",
       "      <td>0.091862</td>\n",
       "      <td>0.091847</td>\n",
       "      <td>0.091832</td>\n",
       "      <td>0.091818</td>\n",
       "      <td>0.091804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.105001</td>\n",
       "      <td>0.102901</td>\n",
       "      <td>0.100901</td>\n",
       "      <td>0.098801</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.094901</td>\n",
       "      <td>0.092901</td>\n",
       "      <td>0.090901</td>\n",
       "      <td>0.089001</td>\n",
       "      <td>0.087101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100756</td>\n",
       "      <td>-0.100771</td>\n",
       "      <td>-0.100786</td>\n",
       "      <td>-0.100801</td>\n",
       "      <td>-0.100816</td>\n",
       "      <td>-0.100831</td>\n",
       "      <td>-0.100845</td>\n",
       "      <td>-0.100860</td>\n",
       "      <td>-0.100874</td>\n",
       "      <td>-0.100888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.148407</td>\n",
       "      <td>0.146307</td>\n",
       "      <td>0.144307</td>\n",
       "      <td>0.142307</td>\n",
       "      <td>0.140307</td>\n",
       "      <td>0.138407</td>\n",
       "      <td>0.136407</td>\n",
       "      <td>0.134507</td>\n",
       "      <td>0.132607</td>\n",
       "      <td>0.130707</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055563</td>\n",
       "      <td>-0.055578</td>\n",
       "      <td>-0.055593</td>\n",
       "      <td>-0.055608</td>\n",
       "      <td>-0.055623</td>\n",
       "      <td>-0.055638</td>\n",
       "      <td>-0.055652</td>\n",
       "      <td>-0.055666</td>\n",
       "      <td>-0.055681</td>\n",
       "      <td>-0.055695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.233220</td>\n",
       "      <td>0.231220</td>\n",
       "      <td>0.229220</td>\n",
       "      <td>0.227220</td>\n",
       "      <td>0.225220</td>\n",
       "      <td>0.223320</td>\n",
       "      <td>0.221320</td>\n",
       "      <td>0.219420</td>\n",
       "      <td>0.217520</td>\n",
       "      <td>0.215720</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031037</td>\n",
       "      <td>0.031022</td>\n",
       "      <td>0.031007</td>\n",
       "      <td>0.030992</td>\n",
       "      <td>0.030977</td>\n",
       "      <td>0.030963</td>\n",
       "      <td>0.030948</td>\n",
       "      <td>0.030934</td>\n",
       "      <td>0.030920</td>\n",
       "      <td>0.030906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.359458</td>\n",
       "      <td>0.357458</td>\n",
       "      <td>0.355458</td>\n",
       "      <td>0.353458</td>\n",
       "      <td>0.351558</td>\n",
       "      <td>0.349558</td>\n",
       "      <td>0.347658</td>\n",
       "      <td>0.345758</td>\n",
       "      <td>0.343958</td>\n",
       "      <td>0.342058</td>\n",
       "      <td>...</td>\n",
       "      <td>0.159061</td>\n",
       "      <td>0.159046</td>\n",
       "      <td>0.159032</td>\n",
       "      <td>0.159017</td>\n",
       "      <td>0.159002</td>\n",
       "      <td>0.158988</td>\n",
       "      <td>0.158974</td>\n",
       "      <td>0.158960</td>\n",
       "      <td>0.158946</td>\n",
       "      <td>0.158932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.125839</td>\n",
       "      <td>0.123839</td>\n",
       "      <td>0.121839</td>\n",
       "      <td>0.119939</td>\n",
       "      <td>0.117939</td>\n",
       "      <td>0.116039</td>\n",
       "      <td>0.114139</td>\n",
       "      <td>0.112339</td>\n",
       "      <td>0.110439</td>\n",
       "      <td>0.108639</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072771</td>\n",
       "      <td>-0.072786</td>\n",
       "      <td>-0.072800</td>\n",
       "      <td>-0.072815</td>\n",
       "      <td>-0.072829</td>\n",
       "      <td>-0.072844</td>\n",
       "      <td>-0.072858</td>\n",
       "      <td>-0.072872</td>\n",
       "      <td>-0.072886</td>\n",
       "      <td>-0.072899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.112814</td>\n",
       "      <td>0.110814</td>\n",
       "      <td>0.108914</td>\n",
       "      <td>0.106914</td>\n",
       "      <td>0.105014</td>\n",
       "      <td>0.103114</td>\n",
       "      <td>0.101214</td>\n",
       "      <td>0.099414</td>\n",
       "      <td>0.097514</td>\n",
       "      <td>0.095714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.084009</td>\n",
       "      <td>-0.084024</td>\n",
       "      <td>-0.084039</td>\n",
       "      <td>-0.084053</td>\n",
       "      <td>-0.084067</td>\n",
       "      <td>-0.084081</td>\n",
       "      <td>-0.084095</td>\n",
       "      <td>-0.084109</td>\n",
       "      <td>-0.084123</td>\n",
       "      <td>-0.084137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.190441</td>\n",
       "      <td>0.188441</td>\n",
       "      <td>0.186541</td>\n",
       "      <td>0.184641</td>\n",
       "      <td>0.182741</td>\n",
       "      <td>0.180841</td>\n",
       "      <td>0.178941</td>\n",
       "      <td>0.177141</td>\n",
       "      <td>0.175341</td>\n",
       "      <td>0.173541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004596</td>\n",
       "      <td>-0.004610</td>\n",
       "      <td>-0.004625</td>\n",
       "      <td>-0.004639</td>\n",
       "      <td>-0.004653</td>\n",
       "      <td>-0.004667</td>\n",
       "      <td>-0.004681</td>\n",
       "      <td>-0.004695</td>\n",
       "      <td>-0.004708</td>\n",
       "      <td>-0.004722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.176704</td>\n",
       "      <td>0.174704</td>\n",
       "      <td>0.172804</td>\n",
       "      <td>0.170904</td>\n",
       "      <td>0.169004</td>\n",
       "      <td>0.167204</td>\n",
       "      <td>0.165304</td>\n",
       "      <td>0.163504</td>\n",
       "      <td>0.161704</td>\n",
       "      <td>0.159904</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016546</td>\n",
       "      <td>-0.016561</td>\n",
       "      <td>-0.016575</td>\n",
       "      <td>-0.016589</td>\n",
       "      <td>-0.016603</td>\n",
       "      <td>-0.016617</td>\n",
       "      <td>-0.016631</td>\n",
       "      <td>-0.016644</td>\n",
       "      <td>-0.016658</td>\n",
       "      <td>-0.016671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.290498</td>\n",
       "      <td>0.288498</td>\n",
       "      <td>0.286598</td>\n",
       "      <td>0.284798</td>\n",
       "      <td>0.282898</td>\n",
       "      <td>0.281098</td>\n",
       "      <td>0.279198</td>\n",
       "      <td>0.277398</td>\n",
       "      <td>0.275598</td>\n",
       "      <td>0.273898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099034</td>\n",
       "      <td>0.099020</td>\n",
       "      <td>0.099006</td>\n",
       "      <td>0.098992</td>\n",
       "      <td>0.098978</td>\n",
       "      <td>0.098964</td>\n",
       "      <td>0.098951</td>\n",
       "      <td>0.098937</td>\n",
       "      <td>0.098924</td>\n",
       "      <td>0.098911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.339584</td>\n",
       "      <td>0.337684</td>\n",
       "      <td>0.335884</td>\n",
       "      <td>0.333984</td>\n",
       "      <td>0.332184</td>\n",
       "      <td>0.330284</td>\n",
       "      <td>0.328484</td>\n",
       "      <td>0.326684</td>\n",
       "      <td>0.324984</td>\n",
       "      <td>0.323184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150007</td>\n",
       "      <td>0.149993</td>\n",
       "      <td>0.149978</td>\n",
       "      <td>0.149965</td>\n",
       "      <td>0.149951</td>\n",
       "      <td>0.149937</td>\n",
       "      <td>0.149924</td>\n",
       "      <td>0.149910</td>\n",
       "      <td>0.149897</td>\n",
       "      <td>0.149884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.219351</td>\n",
       "      <td>0.217551</td>\n",
       "      <td>0.215651</td>\n",
       "      <td>0.213751</td>\n",
       "      <td>0.211951</td>\n",
       "      <td>0.210151</td>\n",
       "      <td>0.208351</td>\n",
       "      <td>0.206551</td>\n",
       "      <td>0.204851</td>\n",
       "      <td>0.203051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031560</td>\n",
       "      <td>0.031546</td>\n",
       "      <td>0.031532</td>\n",
       "      <td>0.031518</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>0.031491</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>0.031465</td>\n",
       "      <td>0.031452</td>\n",
       "      <td>0.031439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.380384</td>\n",
       "      <td>0.378584</td>\n",
       "      <td>0.376684</td>\n",
       "      <td>0.374884</td>\n",
       "      <td>0.373084</td>\n",
       "      <td>0.371284</td>\n",
       "      <td>0.369484</td>\n",
       "      <td>0.367684</td>\n",
       "      <td>0.365984</td>\n",
       "      <td>0.364284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194380</td>\n",
       "      <td>0.194366</td>\n",
       "      <td>0.194352</td>\n",
       "      <td>0.194338</td>\n",
       "      <td>0.194325</td>\n",
       "      <td>0.194312</td>\n",
       "      <td>0.194298</td>\n",
       "      <td>0.194285</td>\n",
       "      <td>0.194272</td>\n",
       "      <td>0.194259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.027074</td>\n",
       "      <td>0.025274</td>\n",
       "      <td>0.023374</td>\n",
       "      <td>0.021574</td>\n",
       "      <td>0.019774</td>\n",
       "      <td>0.017974</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.014574</td>\n",
       "      <td>0.012774</td>\n",
       "      <td>0.011074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157144</td>\n",
       "      <td>-0.157158</td>\n",
       "      <td>-0.157171</td>\n",
       "      <td>-0.157185</td>\n",
       "      <td>-0.157198</td>\n",
       "      <td>-0.157211</td>\n",
       "      <td>-0.157224</td>\n",
       "      <td>-0.157237</td>\n",
       "      <td>-0.157250</td>\n",
       "      <td>-0.157263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.215008</td>\n",
       "      <td>0.213208</td>\n",
       "      <td>0.211308</td>\n",
       "      <td>0.209508</td>\n",
       "      <td>0.207808</td>\n",
       "      <td>0.206008</td>\n",
       "      <td>0.204308</td>\n",
       "      <td>0.202608</td>\n",
       "      <td>0.200808</td>\n",
       "      <td>0.199208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032577</td>\n",
       "      <td>0.032563</td>\n",
       "      <td>0.032549</td>\n",
       "      <td>0.032536</td>\n",
       "      <td>0.032523</td>\n",
       "      <td>0.032510</td>\n",
       "      <td>0.032497</td>\n",
       "      <td>0.032484</td>\n",
       "      <td>0.032471</td>\n",
       "      <td>0.032459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.642958  0.637558  0.632158  0.626758  0.621458  0.616158  0.610958   \n",
       "1    0.750254  0.744754  0.739254  0.733854  0.728454  0.723154  0.717754   \n",
       "2    0.516295  0.510695  0.505195  0.499695  0.494295  0.488895  0.483495   \n",
       "3    0.594156  0.588556  0.582956  0.577456  0.571956  0.566456  0.561056   \n",
       "4    0.727119  0.721419  0.715819  0.710219  0.704619  0.699119  0.693619   \n",
       "5    0.660581  0.654881  0.649181  0.643581  0.637981  0.632381  0.626881   \n",
       "6    0.863220  0.857420  0.851720  0.846020  0.840320  0.834720  0.829220   \n",
       "7    0.703915  0.698115  0.692315  0.686615  0.680915  0.675215  0.669615   \n",
       "8    0.871805  0.865905  0.860105  0.854305  0.848605  0.842805  0.837205   \n",
       "9    0.807060  0.801160  0.795360  0.789460  0.783760  0.777960  0.772260   \n",
       "10   0.689850  0.683950  0.678050  0.672150  0.666350  0.660550  0.654750   \n",
       "11   0.893187  0.887187  0.881287  0.875387  0.869487  0.863687  0.857887   \n",
       "12   0.818009  0.812009  0.806009  0.800109  0.794209  0.788409  0.782509   \n",
       "13   0.947519  0.941419  0.935419  0.929419  0.923519  0.917619  0.911819   \n",
       "14   0.561685  0.555685  0.549585  0.543685  0.537685  0.531785  0.525885   \n",
       "15   0.696854  0.690754  0.684654  0.678654  0.672654  0.666754  0.660854   \n",
       "16   0.635469  0.629369  0.623269  0.617169  0.611169  0.605269  0.599269   \n",
       "17   0.874754  0.868654  0.862554  0.856454  0.850454  0.844454  0.838454   \n",
       "18   0.938265  0.932165  0.926065  0.919965  0.913865  0.907865  0.901865   \n",
       "19   0.938089  0.931889  0.925789  0.919689  0.913589  0.907589  0.901589   \n",
       "20   0.717956  0.711756  0.705656  0.699556  0.693456  0.687456  0.681456   \n",
       "21   0.755214  0.749014  0.742914  0.736814  0.730714  0.724714  0.718614   \n",
       "22   0.673962  0.667762  0.661662  0.655562  0.649462  0.643362  0.637362   \n",
       "23   0.942117  0.935917  0.929817  0.923617  0.917617  0.911517  0.905517   \n",
       "24   0.887098  0.880898  0.874798  0.868698  0.862598  0.856498  0.850498   \n",
       "25   1.080096  1.073896  1.067796  1.061696  1.055596  1.049496  1.043496   \n",
       "26   0.891969  0.885769  0.879669  0.873569  0.867469  0.861469  0.855469   \n",
       "27   0.865321  0.859121  0.853021  0.846921  0.840921  0.834921  0.828921   \n",
       "28   0.896608  0.890508  0.884408  0.878308  0.872308  0.866308  0.860308   \n",
       "29   0.929026  0.922926  0.916826  0.910726  0.904726  0.898726  0.892726   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "470  0.194598  0.192298  0.189998  0.187698  0.185398  0.183198  0.180898   \n",
       "471  0.029057  0.026657  0.024357  0.022157  0.019857  0.017657  0.015457   \n",
       "472  0.443439  0.441139  0.438839  0.436639  0.434339  0.432139  0.429939   \n",
       "473  0.161617  0.159317  0.157117  0.154817  0.152617  0.150417  0.148217   \n",
       "474  0.367776  0.365576  0.363276  0.361076  0.358876  0.356676  0.354576   \n",
       "475 -0.074660 -0.076960 -0.079160 -0.081360 -0.083560 -0.085760 -0.087860   \n",
       "476  0.212663  0.210463  0.208263  0.206063  0.203863  0.201763  0.199663   \n",
       "477  0.088698  0.086498  0.084298  0.082098  0.079998  0.077898  0.075698   \n",
       "478  0.123390  0.121190  0.118990  0.116890  0.114690  0.112590  0.110490   \n",
       "479  0.239567  0.237367  0.235167  0.233067  0.230967  0.228867  0.226767   \n",
       "480  0.233948  0.231848  0.229648  0.227548  0.225448  0.223348  0.221348   \n",
       "481  0.382432  0.380232  0.378132  0.376032  0.373932  0.371932  0.369832   \n",
       "482  0.192031  0.189931  0.187831  0.185731  0.183631  0.181631  0.179631   \n",
       "483  0.183056  0.180956  0.178856  0.176756  0.174656  0.172656  0.170656   \n",
       "484  0.160880  0.158780  0.156680  0.154680  0.152580  0.150580  0.148580   \n",
       "485  0.299381  0.297381  0.295281  0.293281  0.291181  0.289181  0.287281   \n",
       "486  0.105001  0.102901  0.100901  0.098801  0.096801  0.094901  0.092901   \n",
       "487  0.148407  0.146307  0.144307  0.142307  0.140307  0.138407  0.136407   \n",
       "488  0.233220  0.231220  0.229220  0.227220  0.225220  0.223320  0.221320   \n",
       "489  0.359458  0.357458  0.355458  0.353458  0.351558  0.349558  0.347658   \n",
       "490  0.125839  0.123839  0.121839  0.119939  0.117939  0.116039  0.114139   \n",
       "491  0.112814  0.110814  0.108914  0.106914  0.105014  0.103114  0.101214   \n",
       "492  0.190441  0.188441  0.186541  0.184641  0.182741  0.180841  0.178941   \n",
       "493  0.176704  0.174704  0.172804  0.170904  0.169004  0.167204  0.165304   \n",
       "494  0.290498  0.288498  0.286598  0.284798  0.282898  0.281098  0.279198   \n",
       "495  0.339584  0.337684  0.335884  0.333984  0.332184  0.330284  0.328484   \n",
       "496  0.219351  0.217551  0.215651  0.213751  0.211951  0.210151  0.208351   \n",
       "497  0.380384  0.378584  0.376684  0.374884  0.373084  0.371284  0.369484   \n",
       "498  0.027074  0.025274  0.023374  0.021574  0.019774  0.017974  0.016274   \n",
       "499  0.215008  0.213208  0.211308  0.209508  0.207808  0.206008  0.204308   \n",
       "\n",
       "          7         8         9      ...          490       491       492  \\\n",
       "0    0.605758  0.600558  0.595458    ...     0.037439  0.037421  0.037403   \n",
       "1    0.712554  0.707354  0.702154    ...     0.132600  0.132581  0.132563   \n",
       "2    0.478195  0.472895  0.467695    ...    -0.113389 -0.113410 -0.113429   \n",
       "3    0.555656  0.550356  0.545056    ...    -0.047556 -0.047577 -0.047598   \n",
       "4    0.688219  0.682819  0.677419    ...     0.073384  0.073362  0.073340   \n",
       "5    0.621381  0.615881  0.610481    ...    -0.005073 -0.005097 -0.005120   \n",
       "6    0.823620  0.818120  0.812620    ...     0.185650  0.185626  0.185601   \n",
       "7    0.664015  0.658515  0.652915    ...     0.014535  0.014508  0.014483   \n",
       "8    0.831505  0.825905  0.820405    ...     0.170618  0.170591  0.170564   \n",
       "9    0.766560  0.760960  0.755360    ...     0.094271  0.094243  0.094214   \n",
       "10   0.649050  0.643350  0.637750    ...    -0.034535 -0.034566 -0.034596   \n",
       "11   0.852087  0.846387  0.840687    ...     0.157310  0.157278  0.157246   \n",
       "12   0.776709  0.771009  0.765309    ...     0.070845  0.070812  0.070779   \n",
       "13   0.905919  0.900219  0.894419    ...     0.189074  0.189039  0.189004   \n",
       "14   0.519985  0.514185  0.508385    ...    -0.207735 -0.207772 -0.207809   \n",
       "15   0.654954  0.649054  0.643254    ...    -0.083535 -0.083574 -0.083613   \n",
       "16   0.593369  0.587469  0.581669    ...    -0.155684 -0.155725 -0.155765   \n",
       "17   0.832554  0.826654  0.820754    ...     0.073044  0.073001  0.072959   \n",
       "18   0.895965  0.890065  0.884165    ...     0.126205  0.126160  0.126115   \n",
       "19   0.895589  0.889689  0.883789    ...     0.115785  0.115738  0.115691   \n",
       "20   0.675456  0.669556  0.663556    ...    -0.114285 -0.114334 -0.114383   \n",
       "21   0.712714  0.706714  0.700814    ...    -0.086756 -0.086808 -0.086859   \n",
       "22   0.631362  0.625462  0.619462    ...    -0.177530 -0.177584 -0.177638   \n",
       "23   0.899517  0.893517  0.887617    ...     0.081310  0.081254  0.081198   \n",
       "24   0.844498  0.838598  0.832598    ...     0.017285  0.017226  0.017168   \n",
       "25   1.037496  1.031596  1.025596    ...     0.201485  0.201423  0.201362   \n",
       "26   0.849469  0.843469  0.837569    ...     0.004868  0.004804  0.004740   \n",
       "27   0.822921  0.816921  0.811021    ...    -0.029961 -0.030028 -0.030094   \n",
       "28   0.854308  0.848408  0.842508    ...    -0.006546 -0.006616 -0.006685   \n",
       "29   0.886826  0.880926  0.875026    ...     0.018210  0.018136  0.018064   \n",
       "..        ...       ...       ...    ...          ...       ...       ...   \n",
       "470  0.178698  0.176598  0.174398    ...    -0.038453 -0.038471 -0.038488   \n",
       "471  0.013257  0.011057  0.008957    ...    -0.202407 -0.202424 -0.202441   \n",
       "472  0.427739  0.425639  0.423539    ...     0.213663  0.213646  0.213629   \n",
       "473  0.146117  0.144017  0.141817    ...    -0.066472 -0.066489 -0.066505   \n",
       "474  0.352376  0.350276  0.348176    ...     0.141375  0.141358  0.141341   \n",
       "475 -0.090060 -0.092160 -0.094160    ...    -0.299474 -0.299490 -0.299507   \n",
       "476  0.197563  0.195463  0.193363    ...    -0.010363 -0.010380 -0.010397   \n",
       "477  0.073698  0.071598  0.069498    ...    -0.132641 -0.132658 -0.132674   \n",
       "478  0.108490  0.106390  0.104390    ...    -0.096262 -0.096278 -0.096295   \n",
       "479  0.224667  0.222667  0.220667    ...     0.021602  0.021586  0.021570   \n",
       "480  0.219248  0.217248  0.215248    ...     0.017770  0.017754  0.017738   \n",
       "481  0.367832  0.365832  0.363832    ...     0.167941  0.167925  0.167909   \n",
       "482  0.177631  0.175631  0.173631    ...    -0.020673 -0.020689 -0.020704   \n",
       "483  0.168656  0.166656  0.164756    ...    -0.027961 -0.027977 -0.027992   \n",
       "484  0.146680  0.144680  0.142780    ...    -0.048350 -0.048366 -0.048381   \n",
       "485  0.285281  0.283381  0.281381    ...     0.091938  0.091922  0.091907   \n",
       "486  0.090901  0.089001  0.087101    ...    -0.100756 -0.100771 -0.100786   \n",
       "487  0.134507  0.132607  0.130707    ...    -0.055563 -0.055578 -0.055593   \n",
       "488  0.219420  0.217520  0.215720    ...     0.031037  0.031022  0.031007   \n",
       "489  0.345758  0.343958  0.342058    ...     0.159061  0.159046  0.159032   \n",
       "490  0.112339  0.110439  0.108639    ...    -0.072771 -0.072786 -0.072800   \n",
       "491  0.099414  0.097514  0.095714    ...    -0.084009 -0.084024 -0.084039   \n",
       "492  0.177141  0.175341  0.173541    ...    -0.004596 -0.004610 -0.004625   \n",
       "493  0.163504  0.161704  0.159904    ...    -0.016546 -0.016561 -0.016575   \n",
       "494  0.277398  0.275598  0.273898    ...     0.099034  0.099020  0.099006   \n",
       "495  0.326684  0.324984  0.323184    ...     0.150007  0.149993  0.149978   \n",
       "496  0.206551  0.204851  0.203051    ...     0.031560  0.031546  0.031532   \n",
       "497  0.367684  0.365984  0.364284    ...     0.194380  0.194366  0.194352   \n",
       "498  0.014574  0.012774  0.011074    ...    -0.157144 -0.157158 -0.157171   \n",
       "499  0.202608  0.200808  0.199208    ...     0.032577  0.032563  0.032549   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    0.037385  0.037368  0.037351  0.037335  0.037318  0.037302  0.037286  \n",
       "1    0.132544  0.132526  0.132508  0.132490  0.132473  0.132456  0.132440  \n",
       "2   -0.113449 -0.113468 -0.113487 -0.113505 -0.113524 -0.113542 -0.113559  \n",
       "3   -0.047618 -0.047638 -0.047658 -0.047678 -0.047697 -0.047716 -0.047735  \n",
       "4    0.073318  0.073297  0.073276  0.073255  0.073235  0.073214  0.073195  \n",
       "5   -0.005143 -0.005165 -0.005188 -0.005209 -0.005231 -0.005252 -0.005273  \n",
       "6    0.185577  0.185553  0.185530  0.185507  0.185484  0.185462  0.185440  \n",
       "7    0.014457  0.014432  0.014408  0.014383  0.014360  0.014336  0.014313  \n",
       "8    0.170537  0.170511  0.170485  0.170459  0.170434  0.170409  0.170385  \n",
       "9    0.094186  0.094158  0.094131  0.094104  0.094078  0.094052  0.094026  \n",
       "10  -0.034625 -0.034655 -0.034683 -0.034711 -0.034739 -0.034767 -0.034794  \n",
       "11   0.157215  0.157185  0.157154  0.157125  0.157095  0.157067  0.157038  \n",
       "12   0.070746  0.070714  0.070682  0.070651  0.070620  0.070590  0.070560  \n",
       "13   0.188970  0.188936  0.188903  0.188870  0.188837  0.188806  0.188774  \n",
       "14  -0.207845 -0.207880 -0.207915 -0.207950 -0.207984 -0.208017 -0.208050  \n",
       "15  -0.083651 -0.083688 -0.083725 -0.083761 -0.083797 -0.083832 -0.083866  \n",
       "16  -0.155805 -0.155844 -0.155882 -0.155920 -0.155958 -0.155995 -0.156031  \n",
       "17   0.072917  0.072876  0.072836  0.072796  0.072757  0.072718  0.072680  \n",
       "18   0.126072  0.126029  0.125986  0.125944  0.125903  0.125863  0.125823  \n",
       "19   0.115646  0.115600  0.115556  0.115512  0.115469  0.115426  0.115384  \n",
       "20  -0.114431 -0.114478 -0.114525 -0.114570 -0.114616 -0.114660 -0.114704  \n",
       "21  -0.086909 -0.086959 -0.087007 -0.087055 -0.087103 -0.087150 -0.087196  \n",
       "22  -0.177690 -0.177742 -0.177793 -0.177843 -0.177893 -0.177942 -0.177990  \n",
       "23   0.081143  0.081089  0.081036  0.080983  0.080931  0.080880  0.080829  \n",
       "24   0.017110  0.017054  0.016998  0.016943  0.016888  0.016835  0.016782  \n",
       "25   0.201302  0.201243  0.201185  0.201127  0.201070  0.201014  0.200959  \n",
       "26   0.004677  0.004615  0.004554  0.004494  0.004435  0.004376  0.004319  \n",
       "27  -0.030160 -0.030225 -0.030288 -0.030351 -0.030413 -0.030475 -0.030535  \n",
       "28  -0.006754 -0.006821 -0.006888 -0.006953 -0.007018 -0.007082 -0.007145  \n",
       "29   0.017993  0.017922  0.017853  0.017784  0.017717  0.017650  0.017584  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "470 -0.038505 -0.038522 -0.038539 -0.038555 -0.038572 -0.038588 -0.038604  \n",
       "471 -0.202458 -0.202475 -0.202491 -0.202508 -0.202524 -0.202540 -0.202556  \n",
       "472  0.213612  0.213595  0.213579  0.213562  0.213546  0.213530  0.213515  \n",
       "473 -0.066522 -0.066539 -0.066555 -0.066571 -0.066587 -0.066603 -0.066619  \n",
       "474  0.141325  0.141308  0.141292  0.141276  0.141260  0.141244  0.141229  \n",
       "475 -0.299524 -0.299540 -0.299556 -0.299572 -0.299588 -0.299603 -0.299619  \n",
       "476 -0.010413 -0.010429 -0.010445 -0.010461 -0.010477 -0.010492 -0.010507  \n",
       "477 -0.132690 -0.132706 -0.132722 -0.132738 -0.132753 -0.132769 -0.132784  \n",
       "478 -0.096311 -0.096327 -0.096342 -0.096358 -0.096373 -0.096389 -0.096404  \n",
       "479  0.021554  0.021538  0.021522  0.021507  0.021492  0.021476  0.021461  \n",
       "480  0.017722  0.017707  0.017691  0.017676  0.017661  0.017645  0.017631  \n",
       "481  0.167894  0.167878  0.167863  0.167847  0.167832  0.167817  0.167803  \n",
       "482 -0.020720 -0.020735 -0.020751 -0.020766 -0.020781 -0.020796 -0.020810  \n",
       "483 -0.028008 -0.028023 -0.028038 -0.028053 -0.028068 -0.028083 -0.028097  \n",
       "484 -0.048397 -0.048412 -0.048427 -0.048442 -0.048456 -0.048471 -0.048485  \n",
       "485  0.091892  0.091877  0.091862  0.091847  0.091832  0.091818  0.091804  \n",
       "486 -0.100801 -0.100816 -0.100831 -0.100845 -0.100860 -0.100874 -0.100888  \n",
       "487 -0.055608 -0.055623 -0.055638 -0.055652 -0.055666 -0.055681 -0.055695  \n",
       "488  0.030992  0.030977  0.030963  0.030948  0.030934  0.030920  0.030906  \n",
       "489  0.159017  0.159002  0.158988  0.158974  0.158960  0.158946  0.158932  \n",
       "490 -0.072815 -0.072829 -0.072844 -0.072858 -0.072872 -0.072886 -0.072899  \n",
       "491 -0.084053 -0.084067 -0.084081 -0.084095 -0.084109 -0.084123 -0.084137  \n",
       "492 -0.004639 -0.004653 -0.004667 -0.004681 -0.004695 -0.004708 -0.004722  \n",
       "493 -0.016589 -0.016603 -0.016617 -0.016631 -0.016644 -0.016658 -0.016671  \n",
       "494  0.098992  0.098978  0.098964  0.098951  0.098937  0.098924  0.098911  \n",
       "495  0.149965  0.149951  0.149937  0.149924  0.149910  0.149897  0.149884  \n",
       "496  0.031518  0.031505  0.031491  0.031478  0.031465  0.031452  0.031439  \n",
       "497  0.194338  0.194325  0.194312  0.194298  0.194285  0.194272  0.194259  \n",
       "498 -0.157185 -0.157198 -0.157211 -0.157224 -0.157237 -0.157250 -0.157263  \n",
       "499  0.032536  0.032523  0.032510  0.032497  0.032484  0.032471  0.032459  \n",
       "\n",
       "[500 rows x 500 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisez_matx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.619229</td>\n",
       "      <td>0.639381</td>\n",
       "      <td>0.632596</td>\n",
       "      <td>0.627576</td>\n",
       "      <td>0.621739</td>\n",
       "      <td>0.587789</td>\n",
       "      <td>0.581754</td>\n",
       "      <td>0.575493</td>\n",
       "      <td>0.600561</td>\n",
       "      <td>0.540163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049092</td>\n",
       "      <td>0.049046</td>\n",
       "      <td>0.049001</td>\n",
       "      <td>0.048956</td>\n",
       "      <td>0.048913</td>\n",
       "      <td>0.048869</td>\n",
       "      <td>0.048891</td>\n",
       "      <td>0.048847</td>\n",
       "      <td>0.048804</td>\n",
       "      <td>0.048762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.628734</td>\n",
       "      <td>0.647048</td>\n",
       "      <td>0.640308</td>\n",
       "      <td>0.635249</td>\n",
       "      <td>0.629414</td>\n",
       "      <td>0.597417</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.585167</td>\n",
       "      <td>0.608132</td>\n",
       "      <td>0.551522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.042821</td>\n",
       "      <td>0.042777</td>\n",
       "      <td>0.042733</td>\n",
       "      <td>0.042691</td>\n",
       "      <td>0.042648</td>\n",
       "      <td>0.042682</td>\n",
       "      <td>0.042640</td>\n",
       "      <td>0.042598</td>\n",
       "      <td>0.042557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.638239</td>\n",
       "      <td>0.654715</td>\n",
       "      <td>0.648020</td>\n",
       "      <td>0.642922</td>\n",
       "      <td>0.637089</td>\n",
       "      <td>0.607046</td>\n",
       "      <td>0.601043</td>\n",
       "      <td>0.594840</td>\n",
       "      <td>0.615704</td>\n",
       "      <td>0.562880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036639</td>\n",
       "      <td>0.036595</td>\n",
       "      <td>0.036552</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.036468</td>\n",
       "      <td>0.036427</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.036432</td>\n",
       "      <td>0.036391</td>\n",
       "      <td>0.036352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.647744</td>\n",
       "      <td>0.662381</td>\n",
       "      <td>0.655732</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.644765</td>\n",
       "      <td>0.616675</td>\n",
       "      <td>0.610687</td>\n",
       "      <td>0.604514</td>\n",
       "      <td>0.623275</td>\n",
       "      <td>0.574239</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030412</td>\n",
       "      <td>0.030369</td>\n",
       "      <td>0.030328</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>0.030246</td>\n",
       "      <td>0.030206</td>\n",
       "      <td>0.030264</td>\n",
       "      <td>0.030224</td>\n",
       "      <td>0.030185</td>\n",
       "      <td>0.030146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.657248</td>\n",
       "      <td>0.670048</td>\n",
       "      <td>0.663444</td>\n",
       "      <td>0.658268</td>\n",
       "      <td>0.652440</td>\n",
       "      <td>0.626303</td>\n",
       "      <td>0.620332</td>\n",
       "      <td>0.614187</td>\n",
       "      <td>0.630847</td>\n",
       "      <td>0.585598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024186</td>\n",
       "      <td>0.024144</td>\n",
       "      <td>0.024103</td>\n",
       "      <td>0.024063</td>\n",
       "      <td>0.024024</td>\n",
       "      <td>0.023985</td>\n",
       "      <td>0.024055</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.023978</td>\n",
       "      <td>0.023941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.666753</td>\n",
       "      <td>0.677715</td>\n",
       "      <td>0.671157</td>\n",
       "      <td>0.665941</td>\n",
       "      <td>0.660115</td>\n",
       "      <td>0.635932</td>\n",
       "      <td>0.629976</td>\n",
       "      <td>0.623861</td>\n",
       "      <td>0.638418</td>\n",
       "      <td>0.596956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>0.017918</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.017801</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0.017846</td>\n",
       "      <td>0.017809</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>0.017736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.676258</td>\n",
       "      <td>0.685382</td>\n",
       "      <td>0.678869</td>\n",
       "      <td>0.673614</td>\n",
       "      <td>0.667790</td>\n",
       "      <td>0.645561</td>\n",
       "      <td>0.639620</td>\n",
       "      <td>0.633535</td>\n",
       "      <td>0.645989</td>\n",
       "      <td>0.608315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011733</td>\n",
       "      <td>0.011693</td>\n",
       "      <td>0.011654</td>\n",
       "      <td>0.011616</td>\n",
       "      <td>0.011579</td>\n",
       "      <td>0.011543</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.011601</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>0.011531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.685763</td>\n",
       "      <td>0.693049</td>\n",
       "      <td>0.686581</td>\n",
       "      <td>0.681287</td>\n",
       "      <td>0.675466</td>\n",
       "      <td>0.655189</td>\n",
       "      <td>0.649265</td>\n",
       "      <td>0.643208</td>\n",
       "      <td>0.653561</td>\n",
       "      <td>0.619674</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005506</td>\n",
       "      <td>0.005467</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005393</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.005325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.695267</td>\n",
       "      <td>0.700716</td>\n",
       "      <td>0.694293</td>\n",
       "      <td>0.688960</td>\n",
       "      <td>0.683141</td>\n",
       "      <td>0.664818</td>\n",
       "      <td>0.658909</td>\n",
       "      <td>0.652882</td>\n",
       "      <td>0.661132</td>\n",
       "      <td>0.631033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>-0.000544</td>\n",
       "      <td>-0.000581</td>\n",
       "      <td>-0.000617</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>-0.000686</td>\n",
       "      <td>-0.000568</td>\n",
       "      <td>-0.000602</td>\n",
       "      <td>-0.000635</td>\n",
       "      <td>-0.000667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.704772</td>\n",
       "      <td>0.708382</td>\n",
       "      <td>0.702005</td>\n",
       "      <td>0.696633</td>\n",
       "      <td>0.690816</td>\n",
       "      <td>0.674447</td>\n",
       "      <td>0.668554</td>\n",
       "      <td>0.662555</td>\n",
       "      <td>0.668704</td>\n",
       "      <td>0.642391</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006096</td>\n",
       "      <td>-0.006134</td>\n",
       "      <td>-0.006170</td>\n",
       "      <td>-0.006206</td>\n",
       "      <td>-0.006240</td>\n",
       "      <td>-0.006273</td>\n",
       "      <td>-0.006145</td>\n",
       "      <td>-0.006178</td>\n",
       "      <td>-0.006211</td>\n",
       "      <td>-0.006242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.714277</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.709717</td>\n",
       "      <td>0.704306</td>\n",
       "      <td>0.698492</td>\n",
       "      <td>0.684075</td>\n",
       "      <td>0.678198</td>\n",
       "      <td>0.672229</td>\n",
       "      <td>0.676275</td>\n",
       "      <td>0.653750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011274</td>\n",
       "      <td>-0.011312</td>\n",
       "      <td>-0.011348</td>\n",
       "      <td>-0.011383</td>\n",
       "      <td>-0.011417</td>\n",
       "      <td>-0.011450</td>\n",
       "      <td>-0.011313</td>\n",
       "      <td>-0.011346</td>\n",
       "      <td>-0.011378</td>\n",
       "      <td>-0.011409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.723781</td>\n",
       "      <td>0.723716</td>\n",
       "      <td>0.717429</td>\n",
       "      <td>0.711979</td>\n",
       "      <td>0.706167</td>\n",
       "      <td>0.693704</td>\n",
       "      <td>0.687842</td>\n",
       "      <td>0.681903</td>\n",
       "      <td>0.683847</td>\n",
       "      <td>0.665109</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016051</td>\n",
       "      <td>-0.016089</td>\n",
       "      <td>-0.016125</td>\n",
       "      <td>-0.016161</td>\n",
       "      <td>-0.016195</td>\n",
       "      <td>-0.016227</td>\n",
       "      <td>-0.016083</td>\n",
       "      <td>-0.016116</td>\n",
       "      <td>-0.016148</td>\n",
       "      <td>-0.016178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.733286</td>\n",
       "      <td>0.731383</td>\n",
       "      <td>0.725141</td>\n",
       "      <td>0.719652</td>\n",
       "      <td>0.713842</td>\n",
       "      <td>0.703333</td>\n",
       "      <td>0.697487</td>\n",
       "      <td>0.691576</td>\n",
       "      <td>0.691418</td>\n",
       "      <td>0.676467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020438</td>\n",
       "      <td>-0.020476</td>\n",
       "      <td>-0.020512</td>\n",
       "      <td>-0.020548</td>\n",
       "      <td>-0.020582</td>\n",
       "      <td>-0.020615</td>\n",
       "      <td>-0.020464</td>\n",
       "      <td>-0.020497</td>\n",
       "      <td>-0.020530</td>\n",
       "      <td>-0.020560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.742791</td>\n",
       "      <td>0.739050</td>\n",
       "      <td>0.732853</td>\n",
       "      <td>0.727325</td>\n",
       "      <td>0.721518</td>\n",
       "      <td>0.712962</td>\n",
       "      <td>0.707131</td>\n",
       "      <td>0.701250</td>\n",
       "      <td>0.698989</td>\n",
       "      <td>0.687826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024443</td>\n",
       "      <td>-0.024482</td>\n",
       "      <td>-0.024520</td>\n",
       "      <td>-0.024556</td>\n",
       "      <td>-0.024591</td>\n",
       "      <td>-0.024624</td>\n",
       "      <td>-0.024468</td>\n",
       "      <td>-0.024502</td>\n",
       "      <td>-0.024534</td>\n",
       "      <td>-0.024565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.752296</td>\n",
       "      <td>0.746717</td>\n",
       "      <td>0.740565</td>\n",
       "      <td>0.734998</td>\n",
       "      <td>0.729193</td>\n",
       "      <td>0.722590</td>\n",
       "      <td>0.716776</td>\n",
       "      <td>0.710923</td>\n",
       "      <td>0.706561</td>\n",
       "      <td>0.699185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028079</td>\n",
       "      <td>-0.028119</td>\n",
       "      <td>-0.028157</td>\n",
       "      <td>-0.028194</td>\n",
       "      <td>-0.028230</td>\n",
       "      <td>-0.028264</td>\n",
       "      <td>-0.028104</td>\n",
       "      <td>-0.028138</td>\n",
       "      <td>-0.028172</td>\n",
       "      <td>-0.028204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.761800</td>\n",
       "      <td>0.754383</td>\n",
       "      <td>0.748277</td>\n",
       "      <td>0.742671</td>\n",
       "      <td>0.736868</td>\n",
       "      <td>0.732219</td>\n",
       "      <td>0.726420</td>\n",
       "      <td>0.720597</td>\n",
       "      <td>0.714132</td>\n",
       "      <td>0.710544</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031354</td>\n",
       "      <td>-0.031395</td>\n",
       "      <td>-0.031435</td>\n",
       "      <td>-0.031473</td>\n",
       "      <td>-0.031510</td>\n",
       "      <td>-0.031546</td>\n",
       "      <td>-0.031382</td>\n",
       "      <td>-0.031418</td>\n",
       "      <td>-0.031452</td>\n",
       "      <td>-0.031485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.771305</td>\n",
       "      <td>0.762050</td>\n",
       "      <td>0.755990</td>\n",
       "      <td>0.750344</td>\n",
       "      <td>0.744543</td>\n",
       "      <td>0.741848</td>\n",
       "      <td>0.736064</td>\n",
       "      <td>0.730271</td>\n",
       "      <td>0.721704</td>\n",
       "      <td>0.721902</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034280</td>\n",
       "      <td>-0.034323</td>\n",
       "      <td>-0.034364</td>\n",
       "      <td>-0.034404</td>\n",
       "      <td>-0.034442</td>\n",
       "      <td>-0.034479</td>\n",
       "      <td>-0.034314</td>\n",
       "      <td>-0.034351</td>\n",
       "      <td>-0.034387</td>\n",
       "      <td>-0.034421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.780810</td>\n",
       "      <td>0.769717</td>\n",
       "      <td>0.763702</td>\n",
       "      <td>0.758017</td>\n",
       "      <td>0.752219</td>\n",
       "      <td>0.751476</td>\n",
       "      <td>0.745709</td>\n",
       "      <td>0.739944</td>\n",
       "      <td>0.729275</td>\n",
       "      <td>0.733261</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036867</td>\n",
       "      <td>-0.036912</td>\n",
       "      <td>-0.036955</td>\n",
       "      <td>-0.036996</td>\n",
       "      <td>-0.037036</td>\n",
       "      <td>-0.037074</td>\n",
       "      <td>-0.036909</td>\n",
       "      <td>-0.036947</td>\n",
       "      <td>-0.036985</td>\n",
       "      <td>-0.037021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.790315</td>\n",
       "      <td>0.777384</td>\n",
       "      <td>0.771414</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.759894</td>\n",
       "      <td>0.761105</td>\n",
       "      <td>0.755353</td>\n",
       "      <td>0.749618</td>\n",
       "      <td>0.736847</td>\n",
       "      <td>0.744620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039125</td>\n",
       "      <td>-0.039172</td>\n",
       "      <td>-0.039217</td>\n",
       "      <td>-0.039260</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>-0.039342</td>\n",
       "      <td>-0.039177</td>\n",
       "      <td>-0.039217</td>\n",
       "      <td>-0.039257</td>\n",
       "      <td>-0.039294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.799819</td>\n",
       "      <td>0.785051</td>\n",
       "      <td>0.779126</td>\n",
       "      <td>0.773363</td>\n",
       "      <td>0.767569</td>\n",
       "      <td>0.770734</td>\n",
       "      <td>0.764998</td>\n",
       "      <td>0.759291</td>\n",
       "      <td>0.744418</td>\n",
       "      <td>0.755978</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041065</td>\n",
       "      <td>-0.041114</td>\n",
       "      <td>-0.041161</td>\n",
       "      <td>-0.041206</td>\n",
       "      <td>-0.041251</td>\n",
       "      <td>-0.041293</td>\n",
       "      <td>-0.041129</td>\n",
       "      <td>-0.041172</td>\n",
       "      <td>-0.041213</td>\n",
       "      <td>-0.041253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.809324</td>\n",
       "      <td>0.792718</td>\n",
       "      <td>0.786838</td>\n",
       "      <td>0.781036</td>\n",
       "      <td>0.775245</td>\n",
       "      <td>0.780362</td>\n",
       "      <td>0.774642</td>\n",
       "      <td>0.768965</td>\n",
       "      <td>0.751989</td>\n",
       "      <td>0.767337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042697</td>\n",
       "      <td>-0.042748</td>\n",
       "      <td>-0.042798</td>\n",
       "      <td>-0.042845</td>\n",
       "      <td>-0.042892</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>-0.042775</td>\n",
       "      <td>-0.042820</td>\n",
       "      <td>-0.042864</td>\n",
       "      <td>-0.042906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.818829</td>\n",
       "      <td>0.800384</td>\n",
       "      <td>0.794550</td>\n",
       "      <td>0.788709</td>\n",
       "      <td>0.782920</td>\n",
       "      <td>0.789991</td>\n",
       "      <td>0.784287</td>\n",
       "      <td>0.778639</td>\n",
       "      <td>0.759561</td>\n",
       "      <td>0.778696</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044030</td>\n",
       "      <td>-0.044085</td>\n",
       "      <td>-0.044137</td>\n",
       "      <td>-0.044188</td>\n",
       "      <td>-0.044237</td>\n",
       "      <td>-0.044285</td>\n",
       "      <td>-0.044126</td>\n",
       "      <td>-0.044173</td>\n",
       "      <td>-0.044219</td>\n",
       "      <td>-0.044264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.808051</td>\n",
       "      <td>0.802262</td>\n",
       "      <td>0.796382</td>\n",
       "      <td>0.790595</td>\n",
       "      <td>0.799620</td>\n",
       "      <td>0.793931</td>\n",
       "      <td>0.788312</td>\n",
       "      <td>0.767132</td>\n",
       "      <td>0.790055</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045077</td>\n",
       "      <td>-0.045134</td>\n",
       "      <td>-0.045189</td>\n",
       "      <td>-0.045243</td>\n",
       "      <td>-0.045295</td>\n",
       "      <td>-0.045346</td>\n",
       "      <td>-0.045191</td>\n",
       "      <td>-0.045241</td>\n",
       "      <td>-0.045290</td>\n",
       "      <td>-0.045338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.837838</td>\n",
       "      <td>0.815718</td>\n",
       "      <td>0.809974</td>\n",
       "      <td>0.804055</td>\n",
       "      <td>0.798270</td>\n",
       "      <td>0.809248</td>\n",
       "      <td>0.803575</td>\n",
       "      <td>0.797986</td>\n",
       "      <td>0.774704</td>\n",
       "      <td>0.801413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045847</td>\n",
       "      <td>-0.045907</td>\n",
       "      <td>-0.045965</td>\n",
       "      <td>-0.046022</td>\n",
       "      <td>-0.046077</td>\n",
       "      <td>-0.046131</td>\n",
       "      <td>-0.045981</td>\n",
       "      <td>-0.046035</td>\n",
       "      <td>-0.046086</td>\n",
       "      <td>-0.046137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.847343</td>\n",
       "      <td>0.823385</td>\n",
       "      <td>0.817686</td>\n",
       "      <td>0.811729</td>\n",
       "      <td>0.805946</td>\n",
       "      <td>0.818877</td>\n",
       "      <td>0.813220</td>\n",
       "      <td>0.807659</td>\n",
       "      <td>0.782275</td>\n",
       "      <td>0.812772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046349</td>\n",
       "      <td>-0.046413</td>\n",
       "      <td>-0.046475</td>\n",
       "      <td>-0.046535</td>\n",
       "      <td>-0.046594</td>\n",
       "      <td>-0.046650</td>\n",
       "      <td>-0.046506</td>\n",
       "      <td>-0.046563</td>\n",
       "      <td>-0.046618</td>\n",
       "      <td>-0.046672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.856848</td>\n",
       "      <td>0.831052</td>\n",
       "      <td>0.825398</td>\n",
       "      <td>0.819402</td>\n",
       "      <td>0.813621</td>\n",
       "      <td>0.828506</td>\n",
       "      <td>0.822864</td>\n",
       "      <td>0.817333</td>\n",
       "      <td>0.789847</td>\n",
       "      <td>0.824131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046596</td>\n",
       "      <td>-0.046663</td>\n",
       "      <td>-0.046729</td>\n",
       "      <td>-0.046792</td>\n",
       "      <td>-0.046855</td>\n",
       "      <td>-0.046915</td>\n",
       "      <td>-0.046777</td>\n",
       "      <td>-0.046837</td>\n",
       "      <td>-0.046896</td>\n",
       "      <td>-0.046953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.866352</td>\n",
       "      <td>0.838785</td>\n",
       "      <td>0.833177</td>\n",
       "      <td>0.827139</td>\n",
       "      <td>0.821360</td>\n",
       "      <td>0.838134</td>\n",
       "      <td>0.832509</td>\n",
       "      <td>0.827007</td>\n",
       "      <td>0.797472</td>\n",
       "      <td>0.835205</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.046668</td>\n",
       "      <td>-0.046737</td>\n",
       "      <td>-0.046804</td>\n",
       "      <td>-0.046870</td>\n",
       "      <td>-0.046934</td>\n",
       "      <td>-0.046804</td>\n",
       "      <td>-0.046868</td>\n",
       "      <td>-0.046930</td>\n",
       "      <td>-0.046990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.875857</td>\n",
       "      <td>0.846632</td>\n",
       "      <td>0.841069</td>\n",
       "      <td>0.834987</td>\n",
       "      <td>0.829207</td>\n",
       "      <td>0.847763</td>\n",
       "      <td>0.842153</td>\n",
       "      <td>0.836680</td>\n",
       "      <td>0.805188</td>\n",
       "      <td>0.845715</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046362</td>\n",
       "      <td>-0.046437</td>\n",
       "      <td>-0.046510</td>\n",
       "      <td>-0.046581</td>\n",
       "      <td>-0.046651</td>\n",
       "      <td>-0.046719</td>\n",
       "      <td>-0.046597</td>\n",
       "      <td>-0.046664</td>\n",
       "      <td>-0.046730</td>\n",
       "      <td>-0.046794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.885362</td>\n",
       "      <td>0.854564</td>\n",
       "      <td>0.849046</td>\n",
       "      <td>0.842918</td>\n",
       "      <td>0.837136</td>\n",
       "      <td>0.857392</td>\n",
       "      <td>0.851797</td>\n",
       "      <td>0.846354</td>\n",
       "      <td>0.812973</td>\n",
       "      <td>0.855669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045902</td>\n",
       "      <td>-0.045981</td>\n",
       "      <td>-0.046058</td>\n",
       "      <td>-0.046133</td>\n",
       "      <td>-0.046207</td>\n",
       "      <td>-0.046279</td>\n",
       "      <td>-0.046166</td>\n",
       "      <td>-0.046237</td>\n",
       "      <td>-0.046307</td>\n",
       "      <td>-0.046375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.894625</td>\n",
       "      <td>0.862553</td>\n",
       "      <td>0.857079</td>\n",
       "      <td>0.850903</td>\n",
       "      <td>0.845119</td>\n",
       "      <td>0.866783</td>\n",
       "      <td>0.861205</td>\n",
       "      <td>0.855791</td>\n",
       "      <td>0.820803</td>\n",
       "      <td>0.865073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045227</td>\n",
       "      <td>-0.045310</td>\n",
       "      <td>-0.045392</td>\n",
       "      <td>-0.045471</td>\n",
       "      <td>-0.045549</td>\n",
       "      <td>-0.045626</td>\n",
       "      <td>-0.045522</td>\n",
       "      <td>-0.045597</td>\n",
       "      <td>-0.045671</td>\n",
       "      <td>-0.045743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.227583</td>\n",
       "      <td>0.227506</td>\n",
       "      <td>0.225269</td>\n",
       "      <td>0.223033</td>\n",
       "      <td>0.220826</td>\n",
       "      <td>0.215201</td>\n",
       "      <td>0.213287</td>\n",
       "      <td>0.211122</td>\n",
       "      <td>0.208027</td>\n",
       "      <td>0.195976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000475</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000443</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>-0.000411</td>\n",
       "      <td>-0.000396</td>\n",
       "      <td>-0.000983</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>-0.000946</td>\n",
       "      <td>-0.000927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.225356</td>\n",
       "      <td>0.225687</td>\n",
       "      <td>0.223466</td>\n",
       "      <td>0.221247</td>\n",
       "      <td>0.219056</td>\n",
       "      <td>0.212981</td>\n",
       "      <td>0.211075</td>\n",
       "      <td>0.208931</td>\n",
       "      <td>0.206354</td>\n",
       "      <td>0.194603</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000484</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.000453</td>\n",
       "      <td>-0.000437</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.000406</td>\n",
       "      <td>-0.000989</td>\n",
       "      <td>-0.000971</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.000934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.223090</td>\n",
       "      <td>0.223848</td>\n",
       "      <td>0.221643</td>\n",
       "      <td>0.219440</td>\n",
       "      <td>0.217265</td>\n",
       "      <td>0.210776</td>\n",
       "      <td>0.208879</td>\n",
       "      <td>0.206755</td>\n",
       "      <td>0.204663</td>\n",
       "      <td>0.193212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000494</td>\n",
       "      <td>-0.000478</td>\n",
       "      <td>-0.000463</td>\n",
       "      <td>-0.000448</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>-0.000996</td>\n",
       "      <td>-0.000978</td>\n",
       "      <td>-0.000960</td>\n",
       "      <td>-0.000942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.220784</td>\n",
       "      <td>0.221987</td>\n",
       "      <td>0.219799</td>\n",
       "      <td>0.217612</td>\n",
       "      <td>0.215454</td>\n",
       "      <td>0.208587</td>\n",
       "      <td>0.206699</td>\n",
       "      <td>0.204595</td>\n",
       "      <td>0.202954</td>\n",
       "      <td>0.191804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000504</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.000459</td>\n",
       "      <td>-0.000444</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>-0.001003</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>-0.000967</td>\n",
       "      <td>-0.000950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.218467</td>\n",
       "      <td>0.220106</td>\n",
       "      <td>0.217935</td>\n",
       "      <td>0.215764</td>\n",
       "      <td>0.213622</td>\n",
       "      <td>0.206414</td>\n",
       "      <td>0.204535</td>\n",
       "      <td>0.202451</td>\n",
       "      <td>0.201226</td>\n",
       "      <td>0.190379</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>-0.000500</td>\n",
       "      <td>-0.000485</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>-0.000456</td>\n",
       "      <td>-0.000441</td>\n",
       "      <td>-0.001010</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>-0.000975</td>\n",
       "      <td>-0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.216167</td>\n",
       "      <td>0.218204</td>\n",
       "      <td>0.216050</td>\n",
       "      <td>0.213896</td>\n",
       "      <td>0.211771</td>\n",
       "      <td>0.204256</td>\n",
       "      <td>0.202386</td>\n",
       "      <td>0.200322</td>\n",
       "      <td>0.199480</td>\n",
       "      <td>0.188936</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000526</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>-0.000469</td>\n",
       "      <td>-0.000454</td>\n",
       "      <td>-0.001017</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.000984</td>\n",
       "      <td>-0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.213884</td>\n",
       "      <td>0.216281</td>\n",
       "      <td>0.214145</td>\n",
       "      <td>0.212007</td>\n",
       "      <td>0.209899</td>\n",
       "      <td>0.202114</td>\n",
       "      <td>0.200252</td>\n",
       "      <td>0.198208</td>\n",
       "      <td>0.197716</td>\n",
       "      <td>0.187475</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.000482</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>-0.001026</td>\n",
       "      <td>-0.001009</td>\n",
       "      <td>-0.000992</td>\n",
       "      <td>-0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.211619</td>\n",
       "      <td>0.214338</td>\n",
       "      <td>0.212219</td>\n",
       "      <td>0.210099</td>\n",
       "      <td>0.208008</td>\n",
       "      <td>0.199987</td>\n",
       "      <td>0.198135</td>\n",
       "      <td>0.196110</td>\n",
       "      <td>0.195945</td>\n",
       "      <td>0.186008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000551</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>-0.000523</td>\n",
       "      <td>-0.000509</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.000482</td>\n",
       "      <td>-0.001034</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>-0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.209371</td>\n",
       "      <td>0.212375</td>\n",
       "      <td>0.210273</td>\n",
       "      <td>0.208170</td>\n",
       "      <td>0.206096</td>\n",
       "      <td>0.197876</td>\n",
       "      <td>0.196032</td>\n",
       "      <td>0.194028</td>\n",
       "      <td>0.194179</td>\n",
       "      <td>0.184543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000564</td>\n",
       "      <td>-0.000550</td>\n",
       "      <td>-0.000537</td>\n",
       "      <td>-0.000524</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>-0.000497</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>-0.001027</td>\n",
       "      <td>-0.001011</td>\n",
       "      <td>-0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.207140</td>\n",
       "      <td>0.210391</td>\n",
       "      <td>0.208307</td>\n",
       "      <td>0.206222</td>\n",
       "      <td>0.204165</td>\n",
       "      <td>0.195780</td>\n",
       "      <td>0.193945</td>\n",
       "      <td>0.191960</td>\n",
       "      <td>0.192419</td>\n",
       "      <td>0.183083</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.000565</td>\n",
       "      <td>-0.000552</td>\n",
       "      <td>-0.000539</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.000512</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>-0.001021</td>\n",
       "      <td>-0.001006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.204926</td>\n",
       "      <td>0.208400</td>\n",
       "      <td>0.206334</td>\n",
       "      <td>0.204266</td>\n",
       "      <td>0.202227</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>0.191874</td>\n",
       "      <td>0.189908</td>\n",
       "      <td>0.190665</td>\n",
       "      <td>0.181625</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000593</td>\n",
       "      <td>-0.000580</td>\n",
       "      <td>-0.000567</td>\n",
       "      <td>-0.000554</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>-0.000529</td>\n",
       "      <td>-0.001063</td>\n",
       "      <td>-0.001047</td>\n",
       "      <td>-0.001032</td>\n",
       "      <td>-0.001017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.202729</td>\n",
       "      <td>0.206416</td>\n",
       "      <td>0.204368</td>\n",
       "      <td>0.202318</td>\n",
       "      <td>0.200296</td>\n",
       "      <td>0.191634</td>\n",
       "      <td>0.189817</td>\n",
       "      <td>0.187871</td>\n",
       "      <td>0.188915</td>\n",
       "      <td>0.180172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-0.000596</td>\n",
       "      <td>-0.000583</td>\n",
       "      <td>-0.000571</td>\n",
       "      <td>-0.000558</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.001074</td>\n",
       "      <td>-0.001058</td>\n",
       "      <td>-0.001043</td>\n",
       "      <td>-0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.200549</td>\n",
       "      <td>0.204440</td>\n",
       "      <td>0.202409</td>\n",
       "      <td>0.200376</td>\n",
       "      <td>0.198371</td>\n",
       "      <td>0.189584</td>\n",
       "      <td>0.187776</td>\n",
       "      <td>0.185849</td>\n",
       "      <td>0.187171</td>\n",
       "      <td>0.178722</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>-0.000588</td>\n",
       "      <td>-0.000576</td>\n",
       "      <td>-0.000563</td>\n",
       "      <td>-0.001085</td>\n",
       "      <td>-0.001070</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>-0.001040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.198385</td>\n",
       "      <td>0.202469</td>\n",
       "      <td>0.200456</td>\n",
       "      <td>0.198441</td>\n",
       "      <td>0.196453</td>\n",
       "      <td>0.187550</td>\n",
       "      <td>0.185750</td>\n",
       "      <td>0.183842</td>\n",
       "      <td>0.185433</td>\n",
       "      <td>0.177275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000642</td>\n",
       "      <td>-0.000630</td>\n",
       "      <td>-0.000618</td>\n",
       "      <td>-0.000606</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>-0.000582</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>-0.001082</td>\n",
       "      <td>-0.001067</td>\n",
       "      <td>-0.001053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.196239</td>\n",
       "      <td>0.200506</td>\n",
       "      <td>0.198511</td>\n",
       "      <td>0.196512</td>\n",
       "      <td>0.194542</td>\n",
       "      <td>0.185530</td>\n",
       "      <td>0.183740</td>\n",
       "      <td>0.181850</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.175833</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.000648</td>\n",
       "      <td>-0.000637</td>\n",
       "      <td>-0.000625</td>\n",
       "      <td>-0.000613</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>-0.001109</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>-0.001066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.194109</td>\n",
       "      <td>0.198550</td>\n",
       "      <td>0.196572</td>\n",
       "      <td>0.194591</td>\n",
       "      <td>0.192638</td>\n",
       "      <td>0.183525</td>\n",
       "      <td>0.181744</td>\n",
       "      <td>0.179873</td>\n",
       "      <td>0.181973</td>\n",
       "      <td>0.174394</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>-0.000656</td>\n",
       "      <td>-0.000644</td>\n",
       "      <td>-0.000633</td>\n",
       "      <td>-0.000622</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>-0.001080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.191997</td>\n",
       "      <td>0.196601</td>\n",
       "      <td>0.194641</td>\n",
       "      <td>0.192677</td>\n",
       "      <td>0.190741</td>\n",
       "      <td>0.181536</td>\n",
       "      <td>0.179763</td>\n",
       "      <td>0.177911</td>\n",
       "      <td>0.180252</td>\n",
       "      <td>0.172959</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>-0.000665</td>\n",
       "      <td>-0.000654</td>\n",
       "      <td>-0.000642</td>\n",
       "      <td>-0.001135</td>\n",
       "      <td>-0.001122</td>\n",
       "      <td>-0.001108</td>\n",
       "      <td>-0.001095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.194659</td>\n",
       "      <td>0.192716</td>\n",
       "      <td>0.190770</td>\n",
       "      <td>0.188851</td>\n",
       "      <td>0.179561</td>\n",
       "      <td>0.177798</td>\n",
       "      <td>0.175964</td>\n",
       "      <td>0.178536</td>\n",
       "      <td>0.171527</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>-0.000707</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>-0.000674</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>-0.001150</td>\n",
       "      <td>-0.001136</td>\n",
       "      <td>-0.001123</td>\n",
       "      <td>-0.001110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.187820</td>\n",
       "      <td>0.192725</td>\n",
       "      <td>0.190799</td>\n",
       "      <td>0.188869</td>\n",
       "      <td>0.186968</td>\n",
       "      <td>0.177602</td>\n",
       "      <td>0.175847</td>\n",
       "      <td>0.174031</td>\n",
       "      <td>0.176826</td>\n",
       "      <td>0.170100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000738</td>\n",
       "      <td>-0.000727</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>-0.000695</td>\n",
       "      <td>-0.000684</td>\n",
       "      <td>-0.001165</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>-0.001138</td>\n",
       "      <td>-0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.185757</td>\n",
       "      <td>0.190798</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.186976</td>\n",
       "      <td>0.185092</td>\n",
       "      <td>0.175657</td>\n",
       "      <td>0.173911</td>\n",
       "      <td>0.172114</td>\n",
       "      <td>0.175122</td>\n",
       "      <td>0.168676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>-0.000716</td>\n",
       "      <td>-0.000705</td>\n",
       "      <td>-0.001180</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>-0.001154</td>\n",
       "      <td>-0.001142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.183710</td>\n",
       "      <td>0.188877</td>\n",
       "      <td>0.186986</td>\n",
       "      <td>0.185091</td>\n",
       "      <td>0.183223</td>\n",
       "      <td>0.173727</td>\n",
       "      <td>0.171990</td>\n",
       "      <td>0.170211</td>\n",
       "      <td>0.173424</td>\n",
       "      <td>0.167256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.000737</td>\n",
       "      <td>-0.000726</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>-0.001183</td>\n",
       "      <td>-0.001171</td>\n",
       "      <td>-0.001158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.181679</td>\n",
       "      <td>0.186965</td>\n",
       "      <td>0.185091</td>\n",
       "      <td>0.183212</td>\n",
       "      <td>0.181361</td>\n",
       "      <td>0.171812</td>\n",
       "      <td>0.170084</td>\n",
       "      <td>0.168323</td>\n",
       "      <td>0.171732</td>\n",
       "      <td>0.165840</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000787</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.000767</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>-0.000747</td>\n",
       "      <td>-0.001211</td>\n",
       "      <td>-0.001199</td>\n",
       "      <td>-0.001187</td>\n",
       "      <td>-0.001175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.179665</td>\n",
       "      <td>0.185060</td>\n",
       "      <td>0.183203</td>\n",
       "      <td>0.181341</td>\n",
       "      <td>0.179507</td>\n",
       "      <td>0.169911</td>\n",
       "      <td>0.168193</td>\n",
       "      <td>0.166449</td>\n",
       "      <td>0.170045</td>\n",
       "      <td>0.164428</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000817</td>\n",
       "      <td>-0.000807</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>-0.000778</td>\n",
       "      <td>-0.000768</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>-0.001215</td>\n",
       "      <td>-0.001203</td>\n",
       "      <td>-0.001191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.177666</td>\n",
       "      <td>0.183162</td>\n",
       "      <td>0.181322</td>\n",
       "      <td>0.179477</td>\n",
       "      <td>0.177660</td>\n",
       "      <td>0.168026</td>\n",
       "      <td>0.166316</td>\n",
       "      <td>0.164590</td>\n",
       "      <td>0.168365</td>\n",
       "      <td>0.163020</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000836</td>\n",
       "      <td>-0.000827</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.000808</td>\n",
       "      <td>-0.000799</td>\n",
       "      <td>-0.000789</td>\n",
       "      <td>-0.001243</td>\n",
       "      <td>-0.001231</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>-0.001207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.175684</td>\n",
       "      <td>0.181272</td>\n",
       "      <td>0.179449</td>\n",
       "      <td>0.177621</td>\n",
       "      <td>0.175820</td>\n",
       "      <td>0.166154</td>\n",
       "      <td>0.164454</td>\n",
       "      <td>0.162746</td>\n",
       "      <td>0.166691</td>\n",
       "      <td>0.161617</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.000838</td>\n",
       "      <td>-0.000829</td>\n",
       "      <td>-0.000820</td>\n",
       "      <td>-0.000810</td>\n",
       "      <td>-0.001258</td>\n",
       "      <td>-0.001247</td>\n",
       "      <td>-0.001235</td>\n",
       "      <td>-0.001224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.173718</td>\n",
       "      <td>0.179389</td>\n",
       "      <td>0.177583</td>\n",
       "      <td>0.175772</td>\n",
       "      <td>0.173988</td>\n",
       "      <td>0.164298</td>\n",
       "      <td>0.162607</td>\n",
       "      <td>0.160916</td>\n",
       "      <td>0.165023</td>\n",
       "      <td>0.160217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>-0.000858</td>\n",
       "      <td>-0.000849</td>\n",
       "      <td>-0.000840</td>\n",
       "      <td>-0.000831</td>\n",
       "      <td>-0.001274</td>\n",
       "      <td>-0.001263</td>\n",
       "      <td>-0.001251</td>\n",
       "      <td>-0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.171768</td>\n",
       "      <td>0.177514</td>\n",
       "      <td>0.175725</td>\n",
       "      <td>0.173930</td>\n",
       "      <td>0.172163</td>\n",
       "      <td>0.162456</td>\n",
       "      <td>0.160774</td>\n",
       "      <td>0.159100</td>\n",
       "      <td>0.163362</td>\n",
       "      <td>0.158821</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>-0.000887</td>\n",
       "      <td>-0.000878</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>-0.000861</td>\n",
       "      <td>-0.000852</td>\n",
       "      <td>-0.001289</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>-0.001268</td>\n",
       "      <td>-0.001257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.169834</td>\n",
       "      <td>0.175647</td>\n",
       "      <td>0.173875</td>\n",
       "      <td>0.172097</td>\n",
       "      <td>0.170346</td>\n",
       "      <td>0.160628</td>\n",
       "      <td>0.158955</td>\n",
       "      <td>0.157299</td>\n",
       "      <td>0.161706</td>\n",
       "      <td>0.157430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.000907</td>\n",
       "      <td>-0.000899</td>\n",
       "      <td>-0.000890</td>\n",
       "      <td>-0.000882</td>\n",
       "      <td>-0.000873</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.001294</td>\n",
       "      <td>-0.001284</td>\n",
       "      <td>-0.001273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.167916</td>\n",
       "      <td>0.173788</td>\n",
       "      <td>0.172033</td>\n",
       "      <td>0.170271</td>\n",
       "      <td>0.168536</td>\n",
       "      <td>0.158815</td>\n",
       "      <td>0.157151</td>\n",
       "      <td>0.155512</td>\n",
       "      <td>0.160057</td>\n",
       "      <td>0.156042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000935</td>\n",
       "      <td>-0.000927</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>-0.000894</td>\n",
       "      <td>-0.001321</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>-0.001300</td>\n",
       "      <td>-0.001290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.166013</td>\n",
       "      <td>0.171936</td>\n",
       "      <td>0.170198</td>\n",
       "      <td>0.168453</td>\n",
       "      <td>0.166734</td>\n",
       "      <td>0.157016</td>\n",
       "      <td>0.155361</td>\n",
       "      <td>0.153739</td>\n",
       "      <td>0.158415</td>\n",
       "      <td>0.154659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000955</td>\n",
       "      <td>-0.000947</td>\n",
       "      <td>-0.000939</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>-0.000923</td>\n",
       "      <td>-0.000915</td>\n",
       "      <td>-0.001336</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>-0.001306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.619229  0.639381  0.632596  0.627576  0.621739  0.587789  0.581754   \n",
       "1    0.628734  0.647048  0.640308  0.635249  0.629414  0.597417  0.591398   \n",
       "2    0.638239  0.654715  0.648020  0.642922  0.637089  0.607046  0.601043   \n",
       "3    0.647744  0.662381  0.655732  0.650595  0.644765  0.616675  0.610687   \n",
       "4    0.657248  0.670048  0.663444  0.658268  0.652440  0.626303  0.620332   \n",
       "5    0.666753  0.677715  0.671157  0.665941  0.660115  0.635932  0.629976   \n",
       "6    0.676258  0.685382  0.678869  0.673614  0.667790  0.645561  0.639620   \n",
       "7    0.685763  0.693049  0.686581  0.681287  0.675466  0.655189  0.649265   \n",
       "8    0.695267  0.700716  0.694293  0.688960  0.683141  0.664818  0.658909   \n",
       "9    0.704772  0.708382  0.702005  0.696633  0.690816  0.674447  0.668554   \n",
       "10   0.714277  0.716049  0.709717  0.704306  0.698492  0.684075  0.678198   \n",
       "11   0.723781  0.723716  0.717429  0.711979  0.706167  0.693704  0.687842   \n",
       "12   0.733286  0.731383  0.725141  0.719652  0.713842  0.703333  0.697487   \n",
       "13   0.742791  0.739050  0.732853  0.727325  0.721518  0.712962  0.707131   \n",
       "14   0.752296  0.746717  0.740565  0.734998  0.729193  0.722590  0.716776   \n",
       "15   0.761800  0.754383  0.748277  0.742671  0.736868  0.732219  0.726420   \n",
       "16   0.771305  0.762050  0.755990  0.750344  0.744543  0.741848  0.736064   \n",
       "17   0.780810  0.769717  0.763702  0.758017  0.752219  0.751476  0.745709   \n",
       "18   0.790315  0.777384  0.771414  0.765690  0.759894  0.761105  0.755353   \n",
       "19   0.799819  0.785051  0.779126  0.773363  0.767569  0.770734  0.764998   \n",
       "20   0.809324  0.792718  0.786838  0.781036  0.775245  0.780362  0.774642   \n",
       "21   0.818829  0.800384  0.794550  0.788709  0.782920  0.789991  0.784287   \n",
       "22   0.828333  0.808051  0.802262  0.796382  0.790595  0.799620  0.793931   \n",
       "23   0.837838  0.815718  0.809974  0.804055  0.798270  0.809248  0.803575   \n",
       "24   0.847343  0.823385  0.817686  0.811729  0.805946  0.818877  0.813220   \n",
       "25   0.856848  0.831052  0.825398  0.819402  0.813621  0.828506  0.822864   \n",
       "26   0.866352  0.838785  0.833177  0.827139  0.821360  0.838134  0.832509   \n",
       "27   0.875857  0.846632  0.841069  0.834987  0.829207  0.847763  0.842153   \n",
       "28   0.885362  0.854564  0.849046  0.842918  0.837136  0.857392  0.851797   \n",
       "29   0.894625  0.862553  0.857079  0.850903  0.845119  0.866783  0.861205   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "470  0.227583  0.227506  0.225269  0.223033  0.220826  0.215201  0.213287   \n",
       "471  0.225356  0.225687  0.223466  0.221247  0.219056  0.212981  0.211075   \n",
       "472  0.223090  0.223848  0.221643  0.219440  0.217265  0.210776  0.208879   \n",
       "473  0.220784  0.221987  0.219799  0.217612  0.215454  0.208587  0.206699   \n",
       "474  0.218467  0.220106  0.217935  0.215764  0.213622  0.206414  0.204535   \n",
       "475  0.216167  0.218204  0.216050  0.213896  0.211771  0.204256  0.202386   \n",
       "476  0.213884  0.216281  0.214145  0.212007  0.209899  0.202114  0.200252   \n",
       "477  0.211619  0.214338  0.212219  0.210099  0.208008  0.199987  0.198135   \n",
       "478  0.209371  0.212375  0.210273  0.208170  0.206096  0.197876  0.196032   \n",
       "479  0.207140  0.210391  0.208307  0.206222  0.204165  0.195780  0.193945   \n",
       "480  0.204926  0.208400  0.206334  0.204266  0.202227  0.193700  0.191874   \n",
       "481  0.202729  0.206416  0.204368  0.202318  0.200296  0.191634  0.189817   \n",
       "482  0.200549  0.204440  0.202409  0.200376  0.198371  0.189584  0.187776   \n",
       "483  0.198385  0.202469  0.200456  0.198441  0.196453  0.187550  0.185750   \n",
       "484  0.196239  0.200506  0.198511  0.196512  0.194542  0.185530  0.183740   \n",
       "485  0.194109  0.198550  0.196572  0.194591  0.192638  0.183525  0.181744   \n",
       "486  0.191997  0.196601  0.194641  0.192677  0.190741  0.181536  0.179763   \n",
       "487  0.189900  0.194659  0.192716  0.190770  0.188851  0.179561  0.177798   \n",
       "488  0.187820  0.192725  0.190799  0.188869  0.186968  0.177602  0.175847   \n",
       "489  0.185757  0.190798  0.188889  0.186976  0.185092  0.175657  0.173911   \n",
       "490  0.183710  0.188877  0.186986  0.185091  0.183223  0.173727  0.171990   \n",
       "491  0.181679  0.186965  0.185091  0.183212  0.181361  0.171812  0.170084   \n",
       "492  0.179665  0.185060  0.183203  0.181341  0.179507  0.169911  0.168193   \n",
       "493  0.177666  0.183162  0.181322  0.179477  0.177660  0.168026  0.166316   \n",
       "494  0.175684  0.181272  0.179449  0.177621  0.175820  0.166154  0.164454   \n",
       "495  0.173718  0.179389  0.177583  0.175772  0.173988  0.164298  0.162607   \n",
       "496  0.171768  0.177514  0.175725  0.173930  0.172163  0.162456  0.160774   \n",
       "497  0.169834  0.175647  0.173875  0.172097  0.170346  0.160628  0.158955   \n",
       "498  0.167916  0.173788  0.172033  0.170271  0.168536  0.158815  0.157151   \n",
       "499  0.166013  0.171936  0.170198  0.168453  0.166734  0.157016  0.155361   \n",
       "\n",
       "          7         8         9      ...          490       491       492  \\\n",
       "0    0.575493  0.600561  0.540163    ...     0.049092  0.049046  0.049001   \n",
       "1    0.585167  0.608132  0.551522    ...     0.042865  0.042821  0.042777   \n",
       "2    0.594840  0.615704  0.562880    ...     0.036639  0.036595  0.036552   \n",
       "3    0.604514  0.623275  0.574239    ...     0.030412  0.030369  0.030328   \n",
       "4    0.614187  0.630847  0.585598    ...     0.024186  0.024144  0.024103   \n",
       "5    0.623861  0.638418  0.596956    ...     0.017959  0.017918  0.017879   \n",
       "6    0.633535  0.645989  0.608315    ...     0.011733  0.011693  0.011654   \n",
       "7    0.643208  0.653561  0.619674    ...     0.005506  0.005467  0.005429   \n",
       "8    0.652882  0.661132  0.631033    ...    -0.000506 -0.000544 -0.000581   \n",
       "9    0.662555  0.668704  0.642391    ...    -0.006096 -0.006134 -0.006170   \n",
       "10   0.672229  0.676275  0.653750    ...    -0.011274 -0.011312 -0.011348   \n",
       "11   0.681903  0.683847  0.665109    ...    -0.016051 -0.016089 -0.016125   \n",
       "12   0.691576  0.691418  0.676467    ...    -0.020438 -0.020476 -0.020512   \n",
       "13   0.701250  0.698989  0.687826    ...    -0.024443 -0.024482 -0.024520   \n",
       "14   0.710923  0.706561  0.699185    ...    -0.028079 -0.028119 -0.028157   \n",
       "15   0.720597  0.714132  0.710544    ...    -0.031354 -0.031395 -0.031435   \n",
       "16   0.730271  0.721704  0.721902    ...    -0.034280 -0.034323 -0.034364   \n",
       "17   0.739944  0.729275  0.733261    ...    -0.036867 -0.036912 -0.036955   \n",
       "18   0.749618  0.736847  0.744620    ...    -0.039125 -0.039172 -0.039217   \n",
       "19   0.759291  0.744418  0.755978    ...    -0.041065 -0.041114 -0.041161   \n",
       "20   0.768965  0.751989  0.767337    ...    -0.042697 -0.042748 -0.042798   \n",
       "21   0.778639  0.759561  0.778696    ...    -0.044030 -0.044085 -0.044137   \n",
       "22   0.788312  0.767132  0.790055    ...    -0.045077 -0.045134 -0.045189   \n",
       "23   0.797986  0.774704  0.801413    ...    -0.045847 -0.045907 -0.045965   \n",
       "24   0.807659  0.782275  0.812772    ...    -0.046349 -0.046413 -0.046475   \n",
       "25   0.817333  0.789847  0.824131    ...    -0.046596 -0.046663 -0.046729   \n",
       "26   0.827007  0.797472  0.835205    ...    -0.046597 -0.046668 -0.046737   \n",
       "27   0.836680  0.805188  0.845715    ...    -0.046362 -0.046437 -0.046510   \n",
       "28   0.846354  0.812973  0.855669    ...    -0.045902 -0.045981 -0.046058   \n",
       "29   0.855791  0.820803  0.865073    ...    -0.045227 -0.045310 -0.045392   \n",
       "..        ...       ...       ...    ...          ...       ...       ...   \n",
       "470  0.211122  0.208027  0.195976    ...    -0.000475 -0.000459 -0.000443   \n",
       "471  0.208931  0.206354  0.194603    ...    -0.000484 -0.000468 -0.000453   \n",
       "472  0.206755  0.204663  0.193212    ...    -0.000494 -0.000478 -0.000463   \n",
       "473  0.204595  0.202954  0.191804    ...    -0.000504 -0.000489 -0.000474   \n",
       "474  0.202451  0.201226  0.190379    ...    -0.000514 -0.000500 -0.000485   \n",
       "475  0.200322  0.199480  0.188936    ...    -0.000526 -0.000511 -0.000497   \n",
       "476  0.198208  0.197716  0.187475    ...    -0.000538 -0.000524 -0.000510   \n",
       "477  0.196110  0.195945  0.186008    ...    -0.000551 -0.000537 -0.000523   \n",
       "478  0.194028  0.194179  0.184543    ...    -0.000564 -0.000550 -0.000537   \n",
       "479  0.191960  0.192419  0.183083    ...    -0.000578 -0.000565 -0.000552   \n",
       "480  0.189908  0.190665  0.181625    ...    -0.000593 -0.000580 -0.000567   \n",
       "481  0.187871  0.188915  0.180172    ...    -0.000608 -0.000596 -0.000583   \n",
       "482  0.185849  0.187171  0.178722    ...    -0.000625 -0.000613 -0.000600   \n",
       "483  0.183842  0.185433  0.177275    ...    -0.000642 -0.000630 -0.000618   \n",
       "484  0.181850  0.183700  0.175833    ...    -0.000660 -0.000648 -0.000637   \n",
       "485  0.179873  0.181973  0.174394    ...    -0.000679 -0.000667 -0.000656   \n",
       "486  0.177911  0.180252  0.172959    ...    -0.000698 -0.000687 -0.000676   \n",
       "487  0.175964  0.178536  0.171527    ...    -0.000718 -0.000707 -0.000696   \n",
       "488  0.174031  0.176826  0.170100    ...    -0.000738 -0.000727 -0.000716   \n",
       "489  0.172114  0.175122  0.168676    ...    -0.000758 -0.000747 -0.000737   \n",
       "490  0.170211  0.173424  0.167256    ...    -0.000777 -0.000767 -0.000757   \n",
       "491  0.168323  0.171732  0.165840    ...    -0.000797 -0.000787 -0.000777   \n",
       "492  0.166449  0.170045  0.164428    ...    -0.000817 -0.000807 -0.000797   \n",
       "493  0.164590  0.168365  0.163020    ...    -0.000836 -0.000827 -0.000818   \n",
       "494  0.162746  0.166691  0.161617    ...    -0.000856 -0.000847 -0.000838   \n",
       "495  0.160916  0.165023  0.160217    ...    -0.000876 -0.000867 -0.000858   \n",
       "496  0.159100  0.163362  0.158821    ...    -0.000896 -0.000887 -0.000878   \n",
       "497  0.157299  0.161706  0.157430    ...    -0.000915 -0.000907 -0.000899   \n",
       "498  0.155512  0.160057  0.156042    ...    -0.000935 -0.000927 -0.000919   \n",
       "499  0.153739  0.158415  0.154659    ...    -0.000955 -0.000947 -0.000939   \n",
       "\n",
       "          493       494       495       496       497       498       499  \n",
       "0    0.048956  0.048913  0.048869  0.048891  0.048847  0.048804  0.048762  \n",
       "1    0.042733  0.042691  0.042648  0.042682  0.042640  0.042598  0.042557  \n",
       "2    0.036510  0.036468  0.036427  0.036473  0.036432  0.036391  0.036352  \n",
       "3    0.030286  0.030246  0.030206  0.030264  0.030224  0.030185  0.030146  \n",
       "4    0.024063  0.024024  0.023985  0.024055  0.024016  0.023978  0.023941  \n",
       "5    0.017839  0.017801  0.017764  0.017846  0.017809  0.017772  0.017736  \n",
       "6    0.011616  0.011579  0.011543  0.011637  0.011601  0.011565  0.011531  \n",
       "7    0.005392  0.005357  0.005321  0.005428  0.005393  0.005359  0.005325  \n",
       "8   -0.000617 -0.000652 -0.000686 -0.000568 -0.000602 -0.000635 -0.000667  \n",
       "9   -0.006206 -0.006240 -0.006273 -0.006145 -0.006178 -0.006211 -0.006242  \n",
       "10  -0.011383 -0.011417 -0.011450 -0.011313 -0.011346 -0.011378 -0.011409  \n",
       "11  -0.016161 -0.016195 -0.016227 -0.016083 -0.016116 -0.016148 -0.016178  \n",
       "12  -0.020548 -0.020582 -0.020615 -0.020464 -0.020497 -0.020530 -0.020560  \n",
       "13  -0.024556 -0.024591 -0.024624 -0.024468 -0.024502 -0.024534 -0.024565  \n",
       "14  -0.028194 -0.028230 -0.028264 -0.028104 -0.028138 -0.028172 -0.028204  \n",
       "15  -0.031473 -0.031510 -0.031546 -0.031382 -0.031418 -0.031452 -0.031485  \n",
       "16  -0.034404 -0.034442 -0.034479 -0.034314 -0.034351 -0.034387 -0.034421  \n",
       "17  -0.036996 -0.037036 -0.037074 -0.036909 -0.036947 -0.036985 -0.037021  \n",
       "18  -0.039260 -0.039302 -0.039342 -0.039177 -0.039217 -0.039257 -0.039294  \n",
       "19  -0.041206 -0.041251 -0.041293 -0.041129 -0.041172 -0.041213 -0.041253  \n",
       "20  -0.042845 -0.042892 -0.042937 -0.042775 -0.042820 -0.042864 -0.042906  \n",
       "21  -0.044188 -0.044237 -0.044285 -0.044126 -0.044173 -0.044219 -0.044264  \n",
       "22  -0.045243 -0.045295 -0.045346 -0.045191 -0.045241 -0.045290 -0.045338  \n",
       "23  -0.046022 -0.046077 -0.046131 -0.045981 -0.046035 -0.046086 -0.046137  \n",
       "24  -0.046535 -0.046594 -0.046650 -0.046506 -0.046563 -0.046618 -0.046672  \n",
       "25  -0.046792 -0.046855 -0.046915 -0.046777 -0.046837 -0.046896 -0.046953  \n",
       "26  -0.046804 -0.046870 -0.046934 -0.046804 -0.046868 -0.046930 -0.046990  \n",
       "27  -0.046581 -0.046651 -0.046719 -0.046597 -0.046664 -0.046730 -0.046794  \n",
       "28  -0.046133 -0.046207 -0.046279 -0.046166 -0.046237 -0.046307 -0.046375  \n",
       "29  -0.045471 -0.045549 -0.045626 -0.045522 -0.045597 -0.045671 -0.045743  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "470 -0.000427 -0.000411 -0.000396 -0.000983 -0.000964 -0.000946 -0.000927  \n",
       "471 -0.000437 -0.000422 -0.000406 -0.000989 -0.000971 -0.000953 -0.000934  \n",
       "472 -0.000448 -0.000433 -0.000417 -0.000996 -0.000978 -0.000960 -0.000942  \n",
       "473 -0.000459 -0.000444 -0.000429 -0.001003 -0.000985 -0.000967 -0.000950  \n",
       "474 -0.000470 -0.000456 -0.000441 -0.001010 -0.000992 -0.000975 -0.000958  \n",
       "475 -0.000483 -0.000469 -0.000454 -0.001017 -0.001000 -0.000984 -0.000967  \n",
       "476 -0.000496 -0.000482 -0.000468 -0.001026 -0.001009 -0.000992 -0.000976  \n",
       "477 -0.000509 -0.000496 -0.000482 -0.001034 -0.001018 -0.001002 -0.000985  \n",
       "478 -0.000524 -0.000510 -0.000497 -0.001043 -0.001027 -0.001011 -0.000995  \n",
       "479 -0.000539 -0.000525 -0.000512 -0.001053 -0.001037 -0.001021 -0.001006  \n",
       "480 -0.000554 -0.000541 -0.000529 -0.001063 -0.001047 -0.001032 -0.001017  \n",
       "481 -0.000571 -0.000558 -0.000546 -0.001074 -0.001058 -0.001043 -0.001028  \n",
       "482 -0.000588 -0.000576 -0.000563 -0.001085 -0.001070 -0.001055 -0.001040  \n",
       "483 -0.000606 -0.000594 -0.000582 -0.001096 -0.001082 -0.001067 -0.001053  \n",
       "484 -0.000625 -0.000613 -0.000601 -0.001109 -0.001095 -0.001080 -0.001066  \n",
       "485 -0.000644 -0.000633 -0.000622 -0.001122 -0.001108 -0.001094 -0.001080  \n",
       "486 -0.000665 -0.000654 -0.000642 -0.001135 -0.001122 -0.001108 -0.001095  \n",
       "487 -0.000685 -0.000674 -0.000663 -0.001150 -0.001136 -0.001123 -0.001110  \n",
       "488 -0.000706 -0.000695 -0.000684 -0.001165 -0.001151 -0.001138 -0.001125  \n",
       "489 -0.000726 -0.000716 -0.000705 -0.001180 -0.001167 -0.001154 -0.001142  \n",
       "490 -0.000747 -0.000737 -0.000726 -0.001196 -0.001183 -0.001171 -0.001158  \n",
       "491 -0.000767 -0.000757 -0.000747 -0.001211 -0.001199 -0.001187 -0.001175  \n",
       "492 -0.000788 -0.000778 -0.000768 -0.001227 -0.001215 -0.001203 -0.001191  \n",
       "493 -0.000808 -0.000799 -0.000789 -0.001243 -0.001231 -0.001219 -0.001207  \n",
       "494 -0.000829 -0.000820 -0.000810 -0.001258 -0.001247 -0.001235 -0.001224  \n",
       "495 -0.000849 -0.000840 -0.000831 -0.001274 -0.001263 -0.001251 -0.001240  \n",
       "496 -0.000870 -0.000861 -0.000852 -0.001289 -0.001278 -0.001268 -0.001257  \n",
       "497 -0.000890 -0.000882 -0.000873 -0.001305 -0.001294 -0.001284 -0.001273  \n",
       "498 -0.000911 -0.000903 -0.000894 -0.001321 -0.001310 -0.001300 -0.001290  \n",
       "499 -0.000931 -0.000923 -0.000915 -0.001336 -0.001326 -0.001316 -0.001306  \n",
       "\n",
       "[500 rows x 500 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_matx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------\n",
    "# * Get peak dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some data\n",
    "def loaddata(data_filename):\n",
    "    \"\"\"load matrix data\"\"\"\n",
    "    data = np.genfromtxt(data_filename, delimiter='\\t')\n",
    "    data_nm = data[1:,0]    #wavelength in nm\n",
    "    data_time = data[0,1:]\n",
    "    data_z = data[1:, 1:]\n",
    "\n",
    "    return data_nm, data_time, data_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise\n",
    "def add_noise(nm_array, y_array, noise_coefficient):\n",
    "    # Add noise\n",
    "    np.random.seed(1800)\n",
    "    y_noise = noise_coefficient * np.random.normal(size=nm_array.size)\n",
    "    y_proc = y_array + y_noise\n",
    "    \n",
    "    return y_proc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astropy_smoothing(nm_array, timedelay, noise_coefficient,gg_init):\n",
    "    # Generate fake data\n",
    "    np.random.seed(42)\n",
    "    ydata = timedelay + noise_coefficient*np.random.normal(size=nm_array.size)\n",
    "    # Now to fit the data create a new superposition with initial\n",
    "    # guesses for the parameters:\n",
    "    fitter = fitting.SLSQPLSQFitter()\n",
    "    gg_fit = fitter(gg_init, nm_array, ydata)\n",
    "    return gg_fit(nm_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## astropy and peakutils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def astropy_peak_matrix(nm_array,data_matrix,noise_coefficient,threshold, min_dist,gg_init):\n",
    "    num_array = np.shape(data_matrix)[1]\n",
    "    true_peak = []\n",
    "    smooth_peak = []\n",
    "    \n",
    "    for i in range(num_array):\n",
    "        data_array = data_matrix[:, i]\n",
    "        noise_array = add_noise(nm_array, data_array, noise_coefficient)\n",
    "        smooth_array = astropy_smoothing(nm_array, data_array,noise_coefficient,gg_init)\n",
    "        \n",
    "        # get true peak matrix\n",
    "        indexes=findpeak(data_array, threshold, min_dist).tolist()\n",
    "        true_peak.append(indexes)\n",
    "        #get smooth peak matrix\n",
    "        \n",
    "        indexes1=findpeak(smooth_array, threshold, min_dist).tolist()\n",
    "        smooth_peak.append(indexes1)\n",
    "        \n",
    "        # transfer to dataframe\n",
    "        true_df=pd.DataFrame(true_peak)\n",
    "        smooth_df=pd.DataFrame(smooth_peak)\n",
    "    \n",
    "    return true_df, smooth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findpeak(data_z_array, threshold, min_dist):\n",
    "    \"\"\"find peaks and return indices of the peaks\"\"\"    \n",
    "    peak_indices = peakutils.indexes(data_z_array, thres=threshold, min_dist=min_dist)\n",
    "    \n",
    "    return peak_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matx_filename = '20180418_twogaussian_spectralshfit.txt'\n",
    "datanm, datatime, dataz_matx = loaddata(matx_filename)\n",
    "g1 = models.Gaussian1D(1, 950, 30)\n",
    "g2 = models.Gaussian1D(0.3, 1300, 100)\n",
    "gg_init = g1+g2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7495624261835365\n",
      "            Iterations: 35\n",
      "            Function evaluations: 286\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749416522632002\n",
      "            Iterations: 26\n",
      "            Function evaluations: 213\n",
      "            Gradient evaluations: 26\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749433287148435\n",
      "            Iterations: 35\n",
      "            Function evaluations: 286\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749375198981689\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749431472957076\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749409344316003\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749200312059827\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749305522959776\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749341610095242\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749320229483381\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749404956209617\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749556728076309\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749288978968815\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749487160186972\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749579139834748\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7493488312673495\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749364788920609\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749548188186964\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749472460921579\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749476131671374\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749514754553356\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749526311860512\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749361347630389\n",
      "            Iterations: 27\n",
      "            Function evaluations: 222\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749290477323845\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749253530740409\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749440478050193\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749443685396146\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749262796585006\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749341489705365\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7495461039148665\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749321122123099\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749392845514771\n",
      "            Iterations: 35\n",
      "            Function evaluations: 284\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749352302227528\n",
      "            Iterations: 35\n",
      "            Function evaluations: 284\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749345670041293\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749337052502616\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749386666903677\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749403253158012\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74943937218452\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749231582258712\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749372560100794\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749372368294726\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749402007284543\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749120628475032\n",
      "            Iterations: 37\n",
      "            Function evaluations: 301\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749316680218414\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749372267100967\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749412093576252\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749271343513335\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749136486564211\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749301468876689\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74942842666794\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491513620241\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749236462064379\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749212430977229\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7493380702730725\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749245081925409\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749256913800864\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749183444840559\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7494621141373745\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749416384799405\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749270546505583\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749252247695248\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749408976222682\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749192207775534\n",
      "            Iterations: 37\n",
      "            Function evaluations: 302\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491359404989755\n",
      "            Iterations: 36\n",
      "            Function evaluations: 293\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749260313710795\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749185573649983\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749408035657625\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749106048821613\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748951735787758\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749184348914614\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749094885214447\n",
      "            Iterations: 39\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749205601135504\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491118257669065\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749382665544383\n",
      "            Iterations: 38\n",
      "            Function evaluations: 309\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749405903085465\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749165153052614\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749190553388953\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749211004743304\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749181534395437\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749093908424613\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748982964647777\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749130093999115\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749289068624899\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749215959618139\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491290293996045\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749187656405055\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491637041985815\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749159481774589\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7492333082193685\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749272297819244\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749027049491023\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749070979223582\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74926041809535\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749079371698109\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7491312220013615\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748944514626919\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748953338636654\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749004311056142\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74901032493074\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7490293789098335\n",
      "            Iterations: 43\n",
      "            Function evaluations: 350\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749068920719398\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749091413623764\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74899359839679\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749064972149217\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748976949956735\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749055580667931\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748995725657107\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748982713191491\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748896960608702\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748946666030651\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748905525260417\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748865030148847\n",
      "            Iterations: 44\n",
      "            Function evaluations: 358\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748945989283872\n",
      "            Iterations: 44\n",
      "            Function evaluations: 358\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748907217388468\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748900689925913\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748781862721528\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748996624324925\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7488884416510055\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7487997602008925\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748782798182194\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748754145004412\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748900892978499\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748801029986401\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748746895082606\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748711363917186\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748880849885803\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748752416105077\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748661141921264\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748842285937474\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748800957790325\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748742193943585\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74879151595751\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748605768604892\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74865350621814\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748480403121148\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7486411060249765\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748586215762827\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748612924182304\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748686606096324\n",
      "            Iterations: 37\n",
      "            Function evaluations: 302\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748515350562538\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748582161065579\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748604476904286\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748535036984373\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748493560958088\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748494553291147\n",
      "            Iterations: 45\n",
      "            Function evaluations: 366\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7486679379897145\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748521223952126\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748383480228792\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748426698735318\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748398432277382\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748345433112869\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748429324636312\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7483030721013035\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748428494777546\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748261709256058\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748366767432577\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748337115588772\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748210239071977\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748194346193193\n",
      "            Iterations: 40\n",
      "            Function evaluations: 325\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74832111083588\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748252105176622\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748203925605677\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748257131080866\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748320284191468\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748188325741804\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748235462362633\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748063618358449\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748193669537185\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7481634494978975\n",
      "            Iterations: 43\n",
      "            Function evaluations: 349\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748093303325129\n",
      "            Iterations: 41\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74796916770591\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747916153442661\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7481260610394305\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747999012637914\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747889944000153\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7479975762430495\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747986711530788\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748082809598378\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747879808626496\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747916339284938\n",
      "            Iterations: 47\n",
      "            Function evaluations: 382\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747846955538366\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747849954216267\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747823668332578\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747770416060757\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747686724992781\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747855703114417\n",
      "            Iterations: 48\n",
      "            Function evaluations: 390\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7476844648464205\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747627729841216\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747831596706291\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747749359092728\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747608532795676\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747598379393086\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747657546871226\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747684996470715\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74765149262811\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747426959636813\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747541288826001\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747526752987696\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7475736323967626\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747478833351527\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747533390966419\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7473897531291\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74736378527109\n",
      "            Iterations: 48\n",
      "            Function evaluations: 390\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747430629208637\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747317194444093\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7473499754978885\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747372115786428\n",
      "            Iterations: 44\n",
      "            Function evaluations: 357\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747276954637641\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747259905378247\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747251807554061\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74720190978801\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747095326089495\n",
      "            Iterations: 45\n",
      "            Function evaluations: 366\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747185754238129\n",
      "            Iterations: 47\n",
      "            Function evaluations: 382\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747161905295105\n",
      "            Iterations: 49\n",
      "            Function evaluations: 398\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747165470199147\n",
      "            Iterations: 50\n",
      "            Function evaluations: 406\n",
      "            Gradient evaluations: 50\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747213469700437\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747101075867979\n",
      "            Iterations: 51\n",
      "            Function evaluations: 413\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7472346078466074\n",
      "            Iterations: 50\n",
      "            Function evaluations: 405\n",
      "            Gradient evaluations: 50\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747150564377902\n",
      "            Iterations: 42\n",
      "            Function evaluations: 343\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74716832458271\n",
      "            Iterations: 49\n",
      "            Function evaluations: 399\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747077209858885\n",
      "            Iterations: 51\n",
      "            Function evaluations: 413\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7471288813309584\n",
      "            Iterations: 51\n",
      "            Function evaluations: 413\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747196781960074\n",
      "            Iterations: 52\n",
      "            Function evaluations: 422\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747113668258866\n",
      "            Iterations: 52\n",
      "            Function evaluations: 422\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747193710651607\n",
      "            Iterations: 52\n",
      "            Function evaluations: 423\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747123568681408\n",
      "            Iterations: 52\n",
      "            Function evaluations: 422\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747212291286938\n",
      "            Iterations: 51\n",
      "            Function evaluations: 414\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747115155987256\n",
      "            Iterations: 51\n",
      "            Function evaluations: 414\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.750784644247817\n",
      "            Iterations: 37\n",
      "            Function evaluations: 303\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747046028868947\n",
      "            Iterations: 49\n",
      "            Function evaluations: 399\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7470167793812\n",
      "            Iterations: 51\n",
      "            Function evaluations: 415\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7471967642509725\n",
      "            Iterations: 52\n",
      "            Function evaluations: 422\n",
      "            Gradient evaluations: 52\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747226977064121\n",
      "            Iterations: 53\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747027836706405\n",
      "            Iterations: 53\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747121162495429\n",
      "            Iterations: 53\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747045021405496\n",
      "            Iterations: 50\n",
      "            Function evaluations: 407\n",
      "            Gradient evaluations: 50\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747113976982268\n",
      "            Iterations: 52\n",
      "            Function evaluations: 423\n",
      "            Gradient evaluations: 52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747195678964372\n",
      "            Iterations: 50\n",
      "            Function evaluations: 406\n",
      "            Gradient evaluations: 50\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747117122252923\n",
      "            Iterations: 49\n",
      "            Function evaluations: 398\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747102761675739\n",
      "            Iterations: 49\n",
      "            Function evaluations: 398\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751285750828931\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747392746246069\n",
      "            Iterations: 54\n",
      "            Function evaluations: 437\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74718397002313\n",
      "            Iterations: 54\n",
      "            Function evaluations: 437\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747215990424024\n",
      "            Iterations: 55\n",
      "            Function evaluations: 445\n",
      "            Gradient evaluations: 55\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747227714960811\n",
      "            Iterations: 55\n",
      "            Function evaluations: 445\n",
      "            Gradient evaluations: 55\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7471537547071865\n",
      "            Iterations: 53\n",
      "            Function evaluations: 429\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747239618660497\n",
      "            Iterations: 51\n",
      "            Function evaluations: 414\n",
      "            Gradient evaluations: 51\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7514626663894965\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751609588775356\n",
      "            Iterations: 37\n",
      "            Function evaluations: 302\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7472998440776175\n",
      "            Iterations: 53\n",
      "            Function evaluations: 430\n",
      "            Gradient evaluations: 53\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751665438147538\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747423072809673\n",
      "            Iterations: 54\n",
      "            Function evaluations: 438\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747393268405542\n",
      "            Iterations: 54\n",
      "            Function evaluations: 438\n",
      "            Gradient evaluations: 54\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7517479274923\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751849987135918\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751895991126965\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752018637158235\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.751885938948294\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752031701492686\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752080098569529\n",
      "            Iterations: 39\n",
      "            Function evaluations: 318\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752143378003625\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.747760562294637\n",
      "            Iterations: 55\n",
      "            Function evaluations: 447\n",
      "            Gradient evaluations: 55\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.75222644242307\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752176021150273\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752319589485917\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752387861634235\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7524175457280045\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752497823182225\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752425797201136\n",
      "            Iterations: 40\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752685116091097\n",
      "            Iterations: 40\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.74811464558959\n",
      "            Iterations: 57\n",
      "            Function evaluations: 462\n",
      "            Gradient evaluations: 57\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748148043613547\n",
      "            Iterations: 56\n",
      "            Function evaluations: 454\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7481594000508895\n",
      "            Iterations: 57\n",
      "            Function evaluations: 462\n",
      "            Gradient evaluations: 57\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7482032650013135\n",
      "            Iterations: 56\n",
      "            Function evaluations: 455\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752874090009354\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.75289329308394\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.752901892478635\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753073065157718\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753115752745154\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748707386310372\n",
      "            Iterations: 56\n",
      "            Function evaluations: 456\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.748767697070375\n",
      "            Iterations: 57\n",
      "            Function evaluations: 462\n",
      "            Gradient evaluations: 57\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7487205795910725\n",
      "            Iterations: 56\n",
      "            Function evaluations: 454\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753346898094247\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.75330267004631\n",
      "            Iterations: 38\n",
      "            Function evaluations: 310\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753310979964867\n",
      "            Iterations: 35\n",
      "            Function evaluations: 287\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7489934172404284\n",
      "            Iterations: 56\n",
      "            Function evaluations: 454\n",
      "            Gradient evaluations: 56\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753625012449016\n",
      "            Iterations: 40\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753651799654451\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753706534030714\n",
      "            Iterations: 40\n",
      "            Function evaluations: 327\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753743463787355\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753834393858087\n",
      "            Iterations: 42\n",
      "            Function evaluations: 342\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.749378044095565\n",
      "            Iterations: 58\n",
      "            Function evaluations: 470\n",
      "            Gradient evaluations: 58\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.753853067676875\n",
      "            Iterations: 37\n",
      "            Function evaluations: 303\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754057983785377\n",
      "            Iterations: 36\n",
      "            Function evaluations: 294\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754086878579014\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754138762020551\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754211271061097\n",
      "            Iterations: 37\n",
      "            Function evaluations: 304\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754265798627566\n",
      "            Iterations: 40\n",
      "            Function evaluations: 328\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754405242881142\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7544590255311245\n",
      "            Iterations: 39\n",
      "            Function evaluations: 319\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754452547168025\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754561174650329\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754586061590451\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754719582057401\n",
      "            Iterations: 41\n",
      "            Function evaluations: 334\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754783768614982\n",
      "            Iterations: 38\n",
      "            Function evaluations: 311\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754913858495211\n",
      "            Iterations: 43\n",
      "            Function evaluations: 350\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754952621622719\n",
      "            Iterations: 43\n",
      "            Function evaluations: 352\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.754962077313234\n",
      "            Iterations: 41\n",
      "            Function evaluations: 335\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7550128840354215\n",
      "            Iterations: 41\n",
      "            Function evaluations: 337\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755118647079288\n",
      "            Iterations: 38\n",
      "            Function evaluations: 312\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755032385797021\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7552122159279815\n",
      "            Iterations: 42\n",
      "            Function evaluations: 341\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7553800572646505\n",
      "            Iterations: 40\n",
      "            Function evaluations: 326\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755363030735204\n",
      "            Iterations: 38\n",
      "            Function evaluations: 312\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755553711604055\n",
      "            Iterations: 43\n",
      "            Function evaluations: 350\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755500459962966\n",
      "            Iterations: 42\n",
      "            Function evaluations: 342\n",
      "            Gradient evaluations: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755633165255419\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755515675303961\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755657509661916\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755724289984852\n",
      "            Iterations: 47\n",
      "            Function evaluations: 381\n",
      "            Gradient evaluations: 47\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755840911030926\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.755814705337782\n",
      "            Iterations: 45\n",
      "            Function evaluations: 365\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7559214949339275\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756080657413387\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7560975783965\n",
      "            Iterations: 45\n",
      "            Function evaluations: 366\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7561540878547355\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756364594640262\n",
      "            Iterations: 48\n",
      "            Function evaluations: 389\n",
      "            Gradient evaluations: 48\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772846333779112\n",
      "            Iterations: 29\n",
      "            Function evaluations: 237\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772830138071013\n",
      "            Iterations: 27\n",
      "            Function evaluations: 223\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756514583953676\n",
      "            Iterations: 45\n",
      "            Function evaluations: 367\n",
      "            Gradient evaluations: 45\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772896773172324\n",
      "            Iterations: 30\n",
      "            Function evaluations: 246\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756663961706618\n",
      "            Iterations: 46\n",
      "            Function evaluations: 373\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772916742272347\n",
      "            Iterations: 27\n",
      "            Function evaluations: 223\n",
      "            Gradient evaluations: 27\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756761095645025\n",
      "            Iterations: 44\n",
      "            Function evaluations: 359\n",
      "            Gradient evaluations: 44\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772895604833524\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.756960026947854\n",
      "            Iterations: 49\n",
      "            Function evaluations: 397\n",
      "            Gradient evaluations: 49\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772936031880828\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7728940553616255\n",
      "            Iterations: 30\n",
      "            Function evaluations: 246\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772908338731893\n",
      "            Iterations: 29\n",
      "            Function evaluations: 237\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77286948480983\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772933774424264\n",
      "            Iterations: 30\n",
      "            Function evaluations: 246\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773068172536438\n",
      "            Iterations: 28\n",
      "            Function evaluations: 231\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772913853572449\n",
      "            Iterations: 29\n",
      "            Function evaluations: 239\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.757528491867862\n",
      "            Iterations: 46\n",
      "            Function evaluations: 374\n",
      "            Gradient evaluations: 46\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7730043141486975\n",
      "            Iterations: 29\n",
      "            Function evaluations: 239\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773008228934704\n",
      "            Iterations: 30\n",
      "            Function evaluations: 248\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7730224268167465\n",
      "            Iterations: 28\n",
      "            Function evaluations: 231\n",
      "            Gradient evaluations: 28\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773059377501074\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773041384830977\n",
      "            Iterations: 31\n",
      "            Function evaluations: 256\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773017374025967\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.772961576311316\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773097477755426\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77313751798707\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773176143999249\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773139237893447\n",
      "            Iterations: 28\n",
      "            Function evaluations: 232\n",
      "            Gradient evaluations: 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773114966154575\n",
      "            Iterations: 29\n",
      "            Function evaluations: 238\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77311412793755\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773318663207655\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773146310854472\n",
      "            Iterations: 30\n",
      "            Function evaluations: 245\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773147992252777\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773329450015539\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773165324260232\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773290200179722\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773199245019052\n",
      "            Iterations: 32\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773219385397935\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7734277398837115\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773377931280914\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773228568014874\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773297133330447\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773416957576715\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773374047566849\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773367601758247\n",
      "            Iterations: 31\n",
      "            Function evaluations: 256\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773359871994581\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773465018011027\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773454735987348\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773380799621481\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773381319411396\n",
      "            Iterations: 30\n",
      "            Function evaluations: 247\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7735008458642865\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7734995569070096\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7735196138831775\n",
      "            Iterations: 31\n",
      "            Function evaluations: 253\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773558744780768\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773410254567464\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773493946537339\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773590818251513\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77355731919638\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77359683320087\n",
      "            Iterations: 31\n",
      "            Function evaluations: 254\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773565249698628\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773655239056619\n",
      "            Iterations: 34\n",
      "            Function evaluations: 280\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7736719155268075\n",
      "            Iterations: 32\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773625909102958\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773696208353428\n",
      "            Iterations: 30\n",
      "            Function evaluations: 248\n",
      "            Gradient evaluations: 30\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773754705096071\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773731143512379\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773676879914525\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773758199182567\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77358527448223\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77387972918667\n",
      "            Iterations: 32\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773681707468513\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773816475474296\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773783293994764\n",
      "            Iterations: 31\n",
      "            Function evaluations: 256\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773840196975427\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7737964928605106\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7738112430682165\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773852451574591\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773806594523434\n",
      "            Iterations: 31\n",
      "            Function evaluations: 258\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773933338217876\n",
      "            Iterations: 32\n",
      "            Function evaluations: 266\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773851300083674\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773909152720805\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773947712885036\n",
      "            Iterations: 32\n",
      "            Function evaluations: 265\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773940513543278\n",
      "            Iterations: 32\n",
      "            Function evaluations: 266\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773910178286139\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773954635413543\n",
      "            Iterations: 32\n",
      "            Function evaluations: 265\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774027854803709\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774031903899405\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774102402831328\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774015817032727\n",
      "            Iterations: 33\n",
      "            Function evaluations: 269\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.773959731300182\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774066855640488\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774152025297214\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774092898163669\n",
      "            Iterations: 32\n",
      "            Function evaluations: 262\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774032002620352\n",
      "            Iterations: 32\n",
      "            Function evaluations: 261\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774139141445698\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774147515534414\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774182202270225\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774213700052295\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774323315235808\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77430592454492\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774147894310373\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774278412607508\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774284421567199\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774279829081984\n",
      "            Iterations: 33\n",
      "            Function evaluations: 273\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774255553306047\n",
      "            Iterations: 32\n",
      "            Function evaluations: 265\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774285404601775\n",
      "            Iterations: 33\n",
      "            Function evaluations: 270\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774254719478771\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774320854050344\n",
      "            Iterations: 32\n",
      "            Function evaluations: 265\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774403905042709\n",
      "            Iterations: 32\n",
      "            Function evaluations: 264\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774284561574538\n",
      "            Iterations: 32\n",
      "            Function evaluations: 263\n",
      "            Gradient evaluations: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774356732235045\n",
      "            Iterations: 31\n",
      "            Function evaluations: 255\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774407306811416\n",
      "            Iterations: 32\n",
      "            Function evaluations: 266\n",
      "            Gradient evaluations: 32\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774465312610029\n",
      "            Iterations: 34\n",
      "            Function evaluations: 279\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774384021895722\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774395990397547\n",
      "            Iterations: 33\n",
      "            Function evaluations: 272\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774412121023855\n",
      "            Iterations: 29\n",
      "            Function evaluations: 242\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774513145250202\n",
      "            Iterations: 34\n",
      "            Function evaluations: 279\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774439560127461\n",
      "            Iterations: 33\n",
      "            Function evaluations: 271\n",
      "            Gradient evaluations: 33\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774520515175775\n",
      "            Iterations: 34\n",
      "            Function evaluations: 281\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774489585989851\n",
      "            Iterations: 34\n",
      "            Function evaluations: 282\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774484805827692\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774498809442136\n",
      "            Iterations: 34\n",
      "            Function evaluations: 280\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774536204159903\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774509354642108\n",
      "            Iterations: 34\n",
      "            Function evaluations: 281\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774516068974865\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774548013676938\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774554310154793\n",
      "            Iterations: 35\n",
      "            Function evaluations: 288\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774544111305115\n",
      "            Iterations: 35\n",
      "            Function evaluations: 288\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7746134902315305\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77460195953955\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774523575105703\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774654767722738\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774663250593441\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774602073529332\n",
      "            Iterations: 31\n",
      "            Function evaluations: 260\n",
      "            Gradient evaluations: 31\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774652238885522\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7746717439487565\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774667667494004\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774689665957936\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774689548882403\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77471568263059\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7747407480563595\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774739352996761\n",
      "            Iterations: 36\n",
      "            Function evaluations: 298\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77475405799699\n",
      "            Iterations: 36\n",
      "            Function evaluations: 297\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774769774421261\n",
      "            Iterations: 37\n",
      "            Function evaluations: 308\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774781691885833\n",
      "            Iterations: 36\n",
      "            Function evaluations: 300\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774782198734451\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774781185725278\n",
      "            Iterations: 35\n",
      "            Function evaluations: 290\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774778615319569\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774796725889008\n",
      "            Iterations: 37\n",
      "            Function evaluations: 307\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774820424037973\n",
      "            Iterations: 36\n",
      "            Function evaluations: 300\n",
      "            Gradient evaluations: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774826078750889\n",
      "            Iterations: 35\n",
      "            Function evaluations: 290\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774841925358913\n",
      "            Iterations: 35\n",
      "            Function evaluations: 292\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774845555167865\n",
      "            Iterations: 35\n",
      "            Function evaluations: 291\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774851504280549\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774854701263748\n",
      "            Iterations: 34\n",
      "            Function evaluations: 281\n",
      "            Gradient evaluations: 34\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774885757388015\n",
      "            Iterations: 35\n",
      "            Function evaluations: 289\n",
      "            Gradient evaluations: 35\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774879286064013\n",
      "            Iterations: 37\n",
      "            Function evaluations: 306\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77488114433636\n",
      "            Iterations: 37\n",
      "            Function evaluations: 307\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774897549563491\n",
      "            Iterations: 37\n",
      "            Function evaluations: 308\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774899367988725\n",
      "            Iterations: 38\n",
      "            Function evaluations: 315\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774920393626444\n",
      "            Iterations: 37\n",
      "            Function evaluations: 306\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774931235444745\n",
      "            Iterations: 37\n",
      "            Function evaluations: 306\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774943113921643\n",
      "            Iterations: 36\n",
      "            Function evaluations: 299\n",
      "            Gradient evaluations: 36\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.77495545178495\n",
      "            Iterations: 40\n",
      "            Function evaluations: 333\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7749503260616075\n",
      "            Iterations: 39\n",
      "            Function evaluations: 323\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7749635209348\n",
      "            Iterations: 38\n",
      "            Function evaluations: 317\n",
      "            Gradient evaluations: 38\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.774981036601162\n",
      "            Iterations: 37\n",
      "            Function evaluations: 303\n",
      "            Gradient evaluations: 37\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7749909497776795\n",
      "            Iterations: 39\n",
      "            Function evaluations: 322\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.775014466572431\n",
      "            Iterations: 43\n",
      "            Function evaluations: 359\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.7750121302733985\n",
      "            Iterations: 43\n",
      "            Function evaluations: 360\n",
      "            Gradient evaluations: 43\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.775016537879161\n",
      "            Iterations: 39\n",
      "            Function evaluations: 322\n",
      "            Gradient evaluations: 39\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.775045470466733\n",
      "            Iterations: 42\n",
      "            Function evaluations: 347\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully.    (Exit mode 0)\n",
      "            Current function value: 6.775052005884613\n",
      "            Iterations: 38\n",
      "            Function evaluations: 312\n",
      "            Gradient evaluations: 38\n"
     ]
    }
   ],
   "source": [
    "# get the peak position dataframe of smooth data set\n",
    "true_df1, smooth_df1 = astropy_peak_matrix(datanm, dataz_matx, 0.1, 0, 10,gg_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* true peak position in the two-gaussian_spectralshfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>56</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>144</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>144</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>144</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>146</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>146</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>146</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>146</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>146</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>146</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>148</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>148</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>148</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>148</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>150</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>150</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0     50  400\n",
       "1     50  400\n",
       "2     50  400\n",
       "3     50  400\n",
       "4     51  400\n",
       "5     51  400\n",
       "6     51  400\n",
       "7     51  400\n",
       "8     52  400\n",
       "9     52  400\n",
       "10    52  400\n",
       "11    52  400\n",
       "12    52  400\n",
       "13    53  400\n",
       "14    53  400\n",
       "15    53  400\n",
       "16    53  400\n",
       "17    53  400\n",
       "18    53  400\n",
       "19    54  400\n",
       "20    54  400\n",
       "21    54  400\n",
       "22    54  400\n",
       "23    55  400\n",
       "24    55  400\n",
       "25    55  400\n",
       "26    55  400\n",
       "27    55  400\n",
       "28    55  400\n",
       "29    56  400\n",
       "..   ...  ...\n",
       "470  144  400\n",
       "471  144  399\n",
       "472  144  400\n",
       "473  145  400\n",
       "474  145  400\n",
       "475  145  400\n",
       "476  145  400\n",
       "477  145  400\n",
       "478  146  399\n",
       "479  146  399\n",
       "480  146  400\n",
       "481  146  400\n",
       "482  146  400\n",
       "483  146  400\n",
       "484  147  400\n",
       "485  147  400\n",
       "486  147  400\n",
       "487  147  400\n",
       "488  147  400\n",
       "489  148  400\n",
       "490  148  400\n",
       "491  148  400\n",
       "492  148  400\n",
       "493  149  400\n",
       "494  149  400\n",
       "495  149  400\n",
       "496  149  400\n",
       "497  149  400\n",
       "498  150  400\n",
       "499  150  400\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* smooth peak position in the two-gaussian_spectralshfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>55</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>57</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>152</td>\n",
       "      <td>384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>152</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>152</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>152</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>153</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>153</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>153</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>153</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>153</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>154</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>154</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>154</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>154</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>154</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>155</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>155</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>155</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>155</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>156</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>156</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>156</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>156</td>\n",
       "      <td>369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>156</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>157</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>157</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>157</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>157</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>157</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>158</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0     51  395.0\n",
       "1     51  395.0\n",
       "2     51  395.0\n",
       "3     51  395.0\n",
       "4     51  395.0\n",
       "5     52  395.0\n",
       "6     52  394.0\n",
       "7     52  394.0\n",
       "8     52  394.0\n",
       "9     53  394.0\n",
       "10    53  394.0\n",
       "11    53  394.0\n",
       "12    53  394.0\n",
       "13    53  394.0\n",
       "14    54  394.0\n",
       "15    54  394.0\n",
       "16    54  394.0\n",
       "17    54  394.0\n",
       "18    54  394.0\n",
       "19    55  394.0\n",
       "20    55  394.0\n",
       "21    55  394.0\n",
       "22    55  393.0\n",
       "23    55  393.0\n",
       "24    56  393.0\n",
       "25    56  393.0\n",
       "26    56  393.0\n",
       "27    56  393.0\n",
       "28    56  393.0\n",
       "29    57  393.0\n",
       "..   ...    ...\n",
       "470  152  384.0\n",
       "471  152  383.0\n",
       "472  152  383.0\n",
       "473  152  383.0\n",
       "474  153  382.0\n",
       "475  153  382.0\n",
       "476  153  381.0\n",
       "477  153  381.0\n",
       "478  153  380.0\n",
       "479  154  379.0\n",
       "480  154  379.0\n",
       "481  154  378.0\n",
       "482  154  377.0\n",
       "483  154  377.0\n",
       "484  155  376.0\n",
       "485  155  375.0\n",
       "486  155  374.0\n",
       "487  155  374.0\n",
       "488  156  373.0\n",
       "489  156  372.0\n",
       "490  156  371.0\n",
       "491  156  369.0\n",
       "492  156  368.0\n",
       "493  157  367.0\n",
       "494  157  365.0\n",
       "495  157  363.0\n",
       "496  157  361.0\n",
       "497  157  359.0\n",
       "498  158  355.0\n",
       "499  158    NaN\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* py-earth and peakutils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earth_peak_matrix(nm_array,data_matrix,noise_coefficient,threshold, min_dist):\n",
    "    num_array = np.shape(data_matrix)[1]\n",
    "    \n",
    "    true_peak = []\n",
    "    smooth_peak = []\n",
    "    \n",
    "    for i in range(num_array):\n",
    "        data_array = data_matrix[:, i]\n",
    "        noise_array = add_noise(nm_array, data_array, noise_coefficient)\n",
    "        smooth_array = Earth_Smoothing(nm_array, data_array,noise_coefficient)\n",
    "        \n",
    "        indexes=findpeak(data_array, threshold, min_dist).tolist()\n",
    "        true_peak.append(indexes)\n",
    "        \n",
    "        indexes1=findpeak(smooth_array, threshold, min_dist).tolist()\n",
    "        smooth_peak.append(indexes1)\n",
    "                \n",
    "        # transfer to dataframe\n",
    "        true_df=pd.DataFrame(true_peak)\n",
    "        smooth_df=pd.DataFrame(smooth_peak)\n",
    "    \n",
    "    return true_df, smooth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/demiliu/miniconda3/lib/python3.6/site-packages/sklearn_contrib_py_earth-0.1.0-py3.6-macosx-10.7-x86_64.egg/pyearth/earth.py:802: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  pruning_passer.run()\n",
      "/Users/demiliu/miniconda3/lib/python3.6/site-packages/sklearn_contrib_py_earth-0.1.0-py3.6-macosx-10.7-x86_64.egg/pyearth/earth.py:1055: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
     ]
    }
   ],
   "source": [
    "matx_filename = '20180418_twogaussian_spectralshfit.txt'\n",
    "datanm, datatime, dataz_matx = loaddata(matx_filename)\n",
    "## get the peak position dataframe of true data set\n",
    "true_df, smooth_df = earth_peak_matrix(datanm, dataz_matx, 0.1, 0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>52</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>53</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>54</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>55</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>56</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>144</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>144</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>144</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>145</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>146</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>146</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>146</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>146</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>146</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>146</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>147</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>148</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>148</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>148</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>148</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>149</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>150</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>150</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1\n",
       "0     50  400\n",
       "1     50  400\n",
       "2     50  400\n",
       "3     50  400\n",
       "4     51  400\n",
       "5     51  400\n",
       "6     51  400\n",
       "7     51  400\n",
       "8     52  400\n",
       "9     52  400\n",
       "10    52  400\n",
       "11    52  400\n",
       "12    52  400\n",
       "13    53  400\n",
       "14    53  400\n",
       "15    53  400\n",
       "16    53  400\n",
       "17    53  400\n",
       "18    53  400\n",
       "19    54  400\n",
       "20    54  400\n",
       "21    54  400\n",
       "22    54  400\n",
       "23    55  400\n",
       "24    55  400\n",
       "25    55  400\n",
       "26    55  400\n",
       "27    55  400\n",
       "28    55  400\n",
       "29    56  400\n",
       "..   ...  ...\n",
       "470  144  400\n",
       "471  144  399\n",
       "472  144  400\n",
       "473  145  400\n",
       "474  145  400\n",
       "475  145  400\n",
       "476  145  400\n",
       "477  145  400\n",
       "478  146  399\n",
       "479  146  399\n",
       "480  146  400\n",
       "481  146  400\n",
       "482  146  400\n",
       "483  146  400\n",
       "484  147  400\n",
       "485  147  400\n",
       "486  147  400\n",
       "487  147  400\n",
       "488  147  400\n",
       "489  148  400\n",
       "490  148  400\n",
       "491  148  400\n",
       "492  148  400\n",
       "493  149  400\n",
       "494  149  400\n",
       "495  149  400\n",
       "496  149  400\n",
       "497  149  400\n",
       "498  150  400\n",
       "499  150  400\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>402.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>393.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>393.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53</td>\n",
       "      <td>198.0</td>\n",
       "      <td>392.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55</td>\n",
       "      <td>213.0</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55</td>\n",
       "      <td>211.0</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55</td>\n",
       "      <td>212.0</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>59</td>\n",
       "      <td>210.0</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>55</td>\n",
       "      <td>212.0</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>59</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>58</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>55</td>\n",
       "      <td>388.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>57</td>\n",
       "      <td>390.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>62</td>\n",
       "      <td>390.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>57</td>\n",
       "      <td>386.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>386.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>57</td>\n",
       "      <td>385.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>56</td>\n",
       "      <td>171.0</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>59</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>63</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>63</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>63</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>58</td>\n",
       "      <td>389.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>52</td>\n",
       "      <td>391.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>159</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>159</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>159</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>159</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>159</td>\n",
       "      <td>480.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>132</td>\n",
       "      <td>452.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>132</td>\n",
       "      <td>451.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>132</td>\n",
       "      <td>449.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>132</td>\n",
       "      <td>448.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>132</td>\n",
       "      <td>456.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>132</td>\n",
       "      <td>454.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>132</td>\n",
       "      <td>452.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>132</td>\n",
       "      <td>449.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>134</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1      2\n",
       "0     50  402.0    NaN\n",
       "1     53  393.0    NaN\n",
       "2     54  393.0    NaN\n",
       "3     54  394.0    NaN\n",
       "4     53  198.0  392.0\n",
       "5     55  389.0    NaN\n",
       "6     55  389.0    NaN\n",
       "7     54  389.0    NaN\n",
       "8     54  389.0    NaN\n",
       "9     55  213.0  389.0\n",
       "10    55  211.0  389.0\n",
       "11    55  212.0  389.0\n",
       "12    59  210.0  389.0\n",
       "13    55  212.0  389.0\n",
       "14    59  389.0    NaN\n",
       "15    58  389.0    NaN\n",
       "16    55  388.0    NaN\n",
       "17    59  389.0    NaN\n",
       "18    57  390.0    NaN\n",
       "19    62  390.0    NaN\n",
       "20    57  386.0    NaN\n",
       "21    60  386.0    NaN\n",
       "22    57  385.0    NaN\n",
       "23    56  171.0  380.0\n",
       "24    59  389.0    NaN\n",
       "25    63  389.0    NaN\n",
       "26    63  389.0    NaN\n",
       "27    63  389.0    NaN\n",
       "28    58  389.0    NaN\n",
       "29    52  391.0    NaN\n",
       "..   ...    ...    ...\n",
       "470  158    NaN    NaN\n",
       "471  159  480.0    NaN\n",
       "472  158    NaN    NaN\n",
       "473  124    NaN    NaN\n",
       "474  159  480.0    NaN\n",
       "475  159  480.0    NaN\n",
       "476  159  480.0    NaN\n",
       "477  159  480.0    NaN\n",
       "478  132  452.0    NaN\n",
       "479  132  451.0    NaN\n",
       "480  132  449.0    NaN\n",
       "481  132  448.0    NaN\n",
       "482  132  456.0    NaN\n",
       "483  132  454.0    NaN\n",
       "484  132  452.0    NaN\n",
       "485  132  449.0    NaN\n",
       "486  131    NaN    NaN\n",
       "487  133    NaN    NaN\n",
       "488  133    NaN    NaN\n",
       "489  133    NaN    NaN\n",
       "490  133    NaN    NaN\n",
       "491  133    NaN    NaN\n",
       "492  133    NaN    NaN\n",
       "493  133    NaN    NaN\n",
       "494  133    NaN    NaN\n",
       "495  133    NaN    NaN\n",
       "496  133    NaN    NaN\n",
       "497  133    NaN    NaN\n",
       "498  133    NaN    NaN\n",
       "499  134    NaN    NaN\n",
       "\n",
       "[500 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smooth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 500)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataz_matx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peak width and fwhm Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peakchar(data_nm, data_z_array, peak_index):\n",
    "    \"\"\"find the peak width, and intensity\"\"\"\n",
    "    num_peaks = len(peak_index)\n",
    "    \n",
    "    #array of peak height\n",
    "    height = [data_z_array[idx] for idx in peak_index]\n",
    "    \n",
    "    #array of peak width\n",
    "    half_height = [ht / 2 for ht in height]\n",
    "\n",
    "    fwhm_idx_1 = np.empty_like(half_height)\n",
    "    fwhm_idx_2 = np.empty_like(fwhm_idx_1)\n",
    "    fwhm_nm_1 = np.empty_like(fwhm_idx_1)\n",
    "    fwhm_nm_2 = np.empty_like(fwhm_idx_1)\n",
    "    \n",
    "    for i in range(num_peaks):\n",
    "        #find the index and nmof the left side of the fwhm\n",
    "        if i == 0:\n",
    "            fwhm_idx_1[i] = find_nearest(data_z_array[0:peak_index[i]], half_height[i])\n",
    "        else:\n",
    "            fwhm_idx_1[i] = find_nearest(data_z_array[peak_index[i-1]:peak_index[i]], half_height[i]) + peak_index[i-1]\n",
    "\n",
    "        fwhm_nm_1[i] = data_nm[int(fwhm_idx_1[i])]\n",
    "        \n",
    "        #find the index and nm of the right side of the fwhm   \n",
    "        fwhm_idx_2[i] = find_nearest(data_z_array[peak_index[i]:], half_height[i]) + peak_index[i]\n",
    "\n",
    "        fwhm_nm_2[i] = data_nm[int(fwhm_idx_2[i])]\n",
    "    \n",
    "    #find fwhm\n",
    "    fwhm = fwhm_nm_2 - fwhm_nm_1\n",
    "\n",
    "    return height, fwhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def earth_peak_matrix(nm_array,data_matrix,noise_coefficient,threshold, min_dist):\n",
    "    num_array = np.shape(data_matrix)[1]\n",
    "    \n",
    "    true_peak = []\n",
    "    smooth_peak = []\n",
    "    \n",
    "    for i in range(num_array):\n",
    "        data_array = data_matrix[:, i]\n",
    "        noise_array = add_noise(nm_array, data_array, noise_coefficient)\n",
    "        smooth_array = Earth_Smoothing(nm_array, data_array,noise_coefficient)\n",
    "        \n",
    "        indexes=findpeak(data_array, threshold, min_dist).tolist()\n",
    "        true_peak.append(indexes)\n",
    "        \n",
    "        indexes1=findpeak(smooth_array, threshold, min_dist)\n",
    "        smooth_peak.append(indexes1)\n",
    "                \n",
    "        # transfer to dataframe\n",
    "        true_df=pd.DataFrame(true_peak)\n",
    "        smooth_df=pd.DataFrame(smooth_peak)\n",
    "    \n",
    "    return true_df, smooth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_matrix(nm_array,data_matrix, threshold, mindist):\n",
    "    \"\"\"find peaks in a data matrix\"\"\"\n",
    "    peak_idx_matx = []\n",
    "    peak_height_matx = []\n",
    "    peak_fwhm_matx = []\n",
    "    \n",
    "    for i in range(num_timeslice):\n",
    "        data_timeslice = data_matrix[:, i]\n",
    "        \n",
    "        peak_idx = findpeak(data_timeslice, threshold, mindist).tolist()\n",
    "        peak_idx_matx.append(peak_idx)\n",
    "        \n",
    "        \n",
    "        peak_height, peak_fwhm = peakchar(nm_array, data_timeslice, peak_idx)\n",
    "        \n",
    "        peak_height_matx.append(peak_height)\n",
    "        peak_fwhm_matx.append(peak_fwhm)\n",
    "        \n",
    "        # transfer to dataframe\n",
    "        peak_idx_df=pd.DataFrame(peak_idx_matx)\n",
    "        peak_height_df=pd.DataFrame(peak_height_matx)\n",
    "        peak_fwhm_df=pd.DataFrame(peak_fwhm_matx)\n",
    "        \n",
    "    return peak_idx_df, peak_height_df, peak_fwhm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "peak_idx_df, peak_height_df, peak_fwhm_df = peak_matrix(datanm,smooth_matx, 0.00, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.985442</td>\n",
       "      <td>0.302389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.980625</td>\n",
       "      <td>0.299123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.975647</td>\n",
       "      <td>0.296452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.970760</td>\n",
       "      <td>0.293546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.965868</td>\n",
       "      <td>0.290652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.961060</td>\n",
       "      <td>0.287789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.956346</td>\n",
       "      <td>0.284650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.951495</td>\n",
       "      <td>0.282151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.946728</td>\n",
       "      <td>0.279377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.941967</td>\n",
       "      <td>0.276632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.937283</td>\n",
       "      <td>0.273910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.932610</td>\n",
       "      <td>0.271216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.927954</td>\n",
       "      <td>0.268552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.923302</td>\n",
       "      <td>0.265913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.918753</td>\n",
       "      <td>0.262957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.914109</td>\n",
       "      <td>0.260716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.909550</td>\n",
       "      <td>0.258148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.905087</td>\n",
       "      <td>0.255260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.900557</td>\n",
       "      <td>0.252748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.896046</td>\n",
       "      <td>0.250252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.891597</td>\n",
       "      <td>0.247786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.887151</td>\n",
       "      <td>0.245351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.882719</td>\n",
       "      <td>0.242930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.878190</td>\n",
       "      <td>0.240920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.873815</td>\n",
       "      <td>0.238554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.869472</td>\n",
       "      <td>0.236224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.233905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.860802</td>\n",
       "      <td>0.231618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.856478</td>\n",
       "      <td>0.229344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.852225</td>\n",
       "      <td>0.227096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.104045</td>\n",
       "      <td>0.002628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0.103636</td>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.103214</td>\n",
       "      <td>0.002586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.102794</td>\n",
       "      <td>0.002566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.102361</td>\n",
       "      <td>0.002547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.101980</td>\n",
       "      <td>0.002526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.101589</td>\n",
       "      <td>0.002503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.101168</td>\n",
       "      <td>0.002489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.100762</td>\n",
       "      <td>0.002467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.100362</td>\n",
       "      <td>0.002449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.099964</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.099577</td>\n",
       "      <td>0.002415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0.099188</td>\n",
       "      <td>0.002396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.098786</td>\n",
       "      <td>0.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.098402</td>\n",
       "      <td>0.002366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.098016</td>\n",
       "      <td>0.002343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.097634</td>\n",
       "      <td>0.002329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.097240</td>\n",
       "      <td>0.002298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.096860</td>\n",
       "      <td>0.002291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.002275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.096114</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.095742</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.095372</td>\n",
       "      <td>0.002225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.094982</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.094633</td>\n",
       "      <td>0.002188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0.094271</td>\n",
       "      <td>0.002175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.093917</td>\n",
       "      <td>0.002159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.093544</td>\n",
       "      <td>0.002143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0.093181</td>\n",
       "      <td>0.002126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.092813</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "0    0.985442  0.302389\n",
       "1    0.980625  0.299123\n",
       "2    0.975647  0.296452\n",
       "3    0.970760  0.293546\n",
       "4    0.965868  0.290652\n",
       "5    0.961060  0.287789\n",
       "6    0.956346  0.284650\n",
       "7    0.951495  0.282151\n",
       "8    0.946728  0.279377\n",
       "9    0.941967  0.276632\n",
       "10   0.937283  0.273910\n",
       "11   0.932610  0.271216\n",
       "12   0.927954  0.268552\n",
       "13   0.923302  0.265913\n",
       "14   0.918753  0.262957\n",
       "15   0.914109  0.260716\n",
       "16   0.909550  0.258148\n",
       "17   0.905087  0.255260\n",
       "18   0.900557  0.252748\n",
       "19   0.896046  0.250252\n",
       "20   0.891597  0.247786\n",
       "21   0.887151  0.245351\n",
       "22   0.882719  0.242930\n",
       "23   0.878190  0.240920\n",
       "24   0.873815  0.238554\n",
       "25   0.869472  0.236224\n",
       "26   0.865132  0.233905\n",
       "27   0.860802  0.231618\n",
       "28   0.856478  0.229344\n",
       "29   0.852225  0.227096\n",
       "..        ...       ...\n",
       "470  0.104045  0.002628\n",
       "471  0.103636  0.002612\n",
       "472  0.103214  0.002586\n",
       "473  0.102794  0.002566\n",
       "474  0.102361  0.002547\n",
       "475  0.101980  0.002526\n",
       "476  0.101589  0.002503\n",
       "477  0.101168  0.002489\n",
       "478  0.100762  0.002467\n",
       "479  0.100362  0.002449\n",
       "480  0.099964  0.002431\n",
       "481  0.099577  0.002415\n",
       "482  0.099188  0.002396\n",
       "483  0.098786  0.002379\n",
       "484  0.098402  0.002366\n",
       "485  0.098016  0.002343\n",
       "486  0.097634  0.002329\n",
       "487  0.097240  0.002298\n",
       "488  0.096860  0.002291\n",
       "489  0.096491  0.002275\n",
       "490  0.096114  0.002260\n",
       "491  0.095742  0.002239\n",
       "492  0.095372  0.002225\n",
       "493  0.094982  0.002201\n",
       "494  0.094633  0.002188\n",
       "495  0.094271  0.002175\n",
       "496  0.093917  0.002159\n",
       "497  0.093544  0.002143\n",
       "498  0.093181  0.002126\n",
       "499  0.092813       NaN\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_height_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>111.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>111.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>112.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>112.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>112.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>112.0</td>\n",
       "      <td>356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>112.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>113.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>113.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>113.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>113.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>114.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>114.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>114.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>114.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>114.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>115.0</td>\n",
       "      <td>233.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>115.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>115.0</td>\n",
       "      <td>350.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>115.0</td>\n",
       "      <td>231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>116.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>116.0</td>\n",
       "      <td>349.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>116.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>116.0</td>\n",
       "      <td>232.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>112.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>112.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>113.0</td>\n",
       "      <td>194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>113.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>112.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>112.0</td>\n",
       "      <td>193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>112.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>112.0</td>\n",
       "      <td>192.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>112.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>112.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>112.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>112.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>111.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>111.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>112.0</td>\n",
       "      <td>189.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>112.0</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>111.0</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>111.0</td>\n",
       "      <td>187.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>111.0</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>111.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>111.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>111.0</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>111.0</td>\n",
       "      <td>183.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>111.0</td>\n",
       "      <td>182.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>110.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>110.0</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>110.0</td>\n",
       "      <td>178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>111.0</td>\n",
       "      <td>176.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>110.0</td>\n",
       "      <td>172.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>110.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1\n",
       "0    110.0  233.0\n",
       "1    110.0  233.0\n",
       "2    111.0  233.0\n",
       "3    111.0  233.0\n",
       "4    111.0  233.0\n",
       "5    111.0  233.0\n",
       "6    111.0  233.0\n",
       "7    112.0  233.0\n",
       "8    112.0  233.0\n",
       "9    112.0  233.0\n",
       "10   112.0  356.0\n",
       "11   112.0  232.0\n",
       "12   113.0  232.0\n",
       "13   113.0  232.0\n",
       "14   113.0  232.0\n",
       "15   113.0  232.0\n",
       "16   113.0  232.0\n",
       "17   114.0  233.0\n",
       "18   114.0  233.0\n",
       "19   114.0  233.0\n",
       "20   114.0  233.0\n",
       "21   114.0  233.0\n",
       "22   115.0  233.0\n",
       "23   115.0  231.0\n",
       "24   115.0  350.0\n",
       "25   115.0  231.0\n",
       "26   116.0  232.0\n",
       "27   116.0  349.0\n",
       "28   116.0  232.0\n",
       "29   116.0  232.0\n",
       "..     ...    ...\n",
       "470  112.0  195.0\n",
       "471  112.0  194.0\n",
       "472  113.0  194.0\n",
       "473  113.0  193.0\n",
       "474  112.0  193.0\n",
       "475  112.0  193.0\n",
       "476  112.0  192.0\n",
       "477  112.0  192.0\n",
       "478  112.0  191.0\n",
       "479  112.0  191.0\n",
       "480  112.0  191.0\n",
       "481  112.0  190.0\n",
       "482  111.0  190.0\n",
       "483  111.0  189.0\n",
       "484  112.0  189.0\n",
       "485  112.0  188.0\n",
       "486  111.0  187.0\n",
       "487  111.0  187.0\n",
       "488  111.0  186.0\n",
       "489  111.0  185.0\n",
       "490  111.0  185.0\n",
       "491  111.0  184.0\n",
       "492  111.0  183.0\n",
       "493  111.0  182.0\n",
       "494  110.0  181.0\n",
       "495  110.0  179.0\n",
       "496  110.0  178.0\n",
       "497  111.0  176.0\n",
       "498  110.0  172.0\n",
       "499  110.0    NaN\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_fwhm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>52</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>53</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>54</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>55</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>55</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>55</td>\n",
       "      <td>394.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>55</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>55</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>56</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>57</td>\n",
       "      <td>393.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>152</td>\n",
       "      <td>384.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>152</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>152</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>152</td>\n",
       "      <td>383.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>153</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>153</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>153</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>153</td>\n",
       "      <td>381.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>153</td>\n",
       "      <td>380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>154</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>154</td>\n",
       "      <td>379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>154</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>154</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>154</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>155</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>155</td>\n",
       "      <td>375.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>155</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>155</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>156</td>\n",
       "      <td>373.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>156</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>156</td>\n",
       "      <td>371.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>156</td>\n",
       "      <td>369.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>156</td>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>157</td>\n",
       "      <td>367.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>157</td>\n",
       "      <td>365.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>157</td>\n",
       "      <td>363.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>157</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>157</td>\n",
       "      <td>359.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>158</td>\n",
       "      <td>355.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>158</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0     51  395.0\n",
       "1     51  395.0\n",
       "2     51  395.0\n",
       "3     51  395.0\n",
       "4     51  395.0\n",
       "5     52  395.0\n",
       "6     52  394.0\n",
       "7     52  394.0\n",
       "8     52  394.0\n",
       "9     53  394.0\n",
       "10    53  394.0\n",
       "11    53  394.0\n",
       "12    53  394.0\n",
       "13    53  394.0\n",
       "14    54  394.0\n",
       "15    54  394.0\n",
       "16    54  394.0\n",
       "17    54  394.0\n",
       "18    54  394.0\n",
       "19    55  394.0\n",
       "20    55  394.0\n",
       "21    55  394.0\n",
       "22    55  393.0\n",
       "23    55  393.0\n",
       "24    56  393.0\n",
       "25    56  393.0\n",
       "26    56  393.0\n",
       "27    56  393.0\n",
       "28    56  393.0\n",
       "29    57  393.0\n",
       "..   ...    ...\n",
       "470  152  384.0\n",
       "471  152  383.0\n",
       "472  152  383.0\n",
       "473  152  383.0\n",
       "474  153  382.0\n",
       "475  153  382.0\n",
       "476  153  381.0\n",
       "477  153  381.0\n",
       "478  153  380.0\n",
       "479  154  379.0\n",
       "480  154  379.0\n",
       "481  154  378.0\n",
       "482  154  377.0\n",
       "483  154  377.0\n",
       "484  155  376.0\n",
       "485  155  375.0\n",
       "486  155  374.0\n",
       "487  155  374.0\n",
       "488  156  373.0\n",
       "489  156  372.0\n",
       "490  156  371.0\n",
       "491  156  369.0\n",
       "492  156  368.0\n",
       "493  157  367.0\n",
       "494  157  365.0\n",
       "495  157  363.0\n",
       "496  157  361.0\n",
       "497  157  359.0\n",
       "498  158  355.0\n",
       "499  158    NaN\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_idx_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
