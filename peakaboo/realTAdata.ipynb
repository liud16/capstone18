{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_smoothing\n",
    "import find_peaks\n",
    "import peak_character\n",
    "import peak_classify"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load real TA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_nm, data_time, data_z = data_smoothing.load_data_csv('exp03_20180103 -t0 -chirp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smoothen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/demiliu/miniconda3/lib/python3.6/site-packages/sklearn_contrib_py_earth-0.1.0-py3.6-macosx-10.7-x86_64.egg/pyearth/earth.py:802: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  pruning_passer.run()\n",
      "/Users/demiliu/miniconda3/lib/python3.6/site-packages/sklearn_contrib_py_earth-0.1.0-py3.6-macosx-10.7-x86_64.egg/pyearth/earth.py:1055: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  coef, resid = np.linalg.lstsq(B, weighted_y[:, i])[0:2]\n"
     ]
    }
   ],
   "source": [
    "smooth_matx = data_smoothing.earth_smooth_matrix(data_nm, data_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_matx_np = np.array(smooth_matx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import peakutils\n",
    "from peakutils.plot import plot as pplot\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import interpolate\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def indexes(y, thres=0.3, min_dist=1):\n",
    "    \"\"\"Peak detection routine.\n",
    "\n",
    "    Finds the numeric index of the peaks in *y* by taking its first order difference. By using\n",
    "    *thres* and *min_dist* parameters, it is possible to reduce the number of\n",
    "    detected peaks. *y* must be signed.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y : ndarray (signed)\n",
    "        1D amplitude data to search for peaks.\n",
    "    thres : float between [0., 1.]\n",
    "        Normalized threshold. Only the peaks with amplitude higher than the\n",
    "        threshold will be detected.\n",
    "    min_dist : int\n",
    "        Minimum distance between each detected peak. The peak with the highest\n",
    "        amplitude is preferred to satisfy this constraint.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ndarray\n",
    "        Array containing the numeric indexes of the peaks that were detected\n",
    "    \"\"\"\n",
    "    y_raw = y\n",
    "    y = [abs(k) for k in y_raw]\n",
    "    \n",
    "    if isinstance(y, np.ndarray) and np.issubdtype(y.dtype, np.unsignedinteger):\n",
    "        raise ValueError(\"y must be signed\")\n",
    "\n",
    "    thres = thres * (np.max(y) - np.min(y)) + np.min(y)\n",
    "    min_dist = int(min_dist)\n",
    "\n",
    "    # compute first order difference\n",
    "    dy = np.diff(y)\n",
    "\n",
    "    # propagate left and right values successively to fill all plateau pixels (0-value)\n",
    "    zeros,=np.where(dy == 0)\n",
    "    \n",
    "    # check if the singal is totally flat\n",
    "    if len(zeros) == len(y) - 1:\n",
    "        return np.array([])\n",
    "    \n",
    "    while len(zeros):\n",
    "        # add pixels 2 by 2 to propagate left and right value onto the zero-value pixel\n",
    "        zerosr = np.hstack([dy[1:], 0.])\n",
    "        zerosl = np.hstack([0., dy[:-1]])\n",
    "\n",
    "        # replace 0 with right value if non zero\n",
    "        dy[zeros]=zerosr[zeros]\n",
    "        zeros,=np.where(dy == 0)\n",
    "\n",
    "        # replace 0 with left value if non zero\n",
    "        dy[zeros]=zerosl[zeros]\n",
    "        zeros,=np.where(dy == 0)\n",
    "\n",
    "    # find the peaks by using the first order difference\n",
    "    peaks = np.where((np.hstack([dy, 0.]) < 0.)\n",
    "                     & (np.hstack([0., dy]) > 0.)\n",
    "                     & (y > thres))[0]\n",
    "\n",
    "    # handle multiple peaks, respecting the minimum distance\n",
    "    if peaks.size > 1 and min_dist > 1:\n",
    "        highest = peaks[np.argsort(y[peaks])][::-1]\n",
    "        rem = np.ones(y.size, dtype=bool)\n",
    "        rem[peaks] = False\n",
    "\n",
    "        for peak in highest:\n",
    "            if not rem[peak]:\n",
    "                sl = slice(max(0, peak - min_dist), peak + min_dist + 1)\n",
    "                rem[sl] = True\n",
    "                rem[peak] = False\n",
    "\n",
    "        peaks = np.arange(y.size)[~rem]\n",
    "    \n",
    "    \n",
    "    return peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = (np.abs(array-value)).argmin()\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " # get peak height and fwhm info\n",
    "def peakchar(data_nm, data_z_array, peak_index):\n",
    "    \"\"\"find the peak width, and intensity\"\"\"\n",
    "    num_peaks = len(peak_index)\n",
    "    \n",
    "    #array of peak height\n",
    "    height = [data_z_array[idx] for idx in peak_index]\n",
    "    \n",
    "    #array of peak width\n",
    "    half_height = [ht / 2 for ht in height]\n",
    "\n",
    "    fwhm_idx_1 = np.empty_like(half_height)\n",
    "    fwhm_idx_2 = np.empty_like(fwhm_idx_1)\n",
    "    fwhm_nm_1 = np.empty_like(fwhm_idx_1)\n",
    "    fwhm_nm_2 = np.empty_like(fwhm_idx_1)\n",
    "    \n",
    "    for i in range(num_peaks):\n",
    "        #find the index and nmof the left side of the fwhm\n",
    "        if i == 0:\n",
    "            fwhm_idx_1[i] = find_nearest(data_z_array[0:peak_index[i]], half_height[i])\n",
    "        else:\n",
    "            fwhm_idx_1[i] = find_nearest(data_z_array[peak_index[i-1]:peak_index[i]], half_height[i]) + peak_index[i-1]\n",
    "\n",
    "        fwhm_nm_1[i] = data_nm[int(fwhm_idx_1[i])]\n",
    "        \n",
    "        #find the index and nm of the right side of the fwhm   \n",
    "        fwhm_idx_2[i] = find_nearest(data_z_array[peak_index[i]:], half_height[i]) + peak_index[i]\n",
    "\n",
    "        fwhm_nm_2[i] = data_nm[int(fwhm_idx_2[i])]\n",
    "    \n",
    "    #find fwhm\n",
    "    fwhm = fwhm_nm_2 - fwhm_nm_1\n",
    "\n",
    "    return height, fwhm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_matrix(nm_array,data_matrix, threshold, mindist):\n",
    "    \"\"\"find peaks in a data matrix\n",
    "    and calculate the height and width of the peaks\"\"\"\n",
    "    \n",
    "    peak_idx_matx = []\n",
    "    peak_height_matx = []\n",
    "    peak_fwhm_matx = []\n",
    "    \n",
    "    num_timeslice = np.shape(data_matrix)[1]\n",
    "        \n",
    "\n",
    "    for i in range(num_timeslice):\n",
    "        data_timeslice = data_matrix[:, i]\n",
    "        \n",
    "        peak_idx = indexes(data_timeslice, threshold, mindist).tolist()\n",
    "        peak_idx_matx.append(peak_idx)\n",
    "        \n",
    "        \n",
    "        peak_height, peak_fwhm = peakchar(nm_array, data_timeslice, peak_idx)\n",
    "        \n",
    "        peak_height_matx.append(peak_height)\n",
    "        peak_fwhm_matx.append(peak_fwhm)\n",
    "        \n",
    "        # transfer to dataframe\n",
    "        peak_idx_df=pd.DataFrame(peak_idx_matx)\n",
    "        peak_height_df=pd.DataFrame(peak_height_matx)\n",
    "        peak_fwhm_df=pd.DataFrame(peak_fwhm_matx)\n",
    "        \n",
    "    return peak_idx_df, peak_height_df, peak_fwhm_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I ran the above functions directly, rather than the ones in .py files because I was trouble-shooting the code\n",
    "\n",
    "## i.e. note that I ran *peak_matrix* rather than *character.peak_matrix*\n",
    "\n",
    "## i didn't change the function so you can run the same function from import as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0\n",
    "mindist = 0\n",
    "idx, height, fwhm = peak_matrix(data_nm,smooth_matx_np, threshold, mindist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two peaks were identified: index ~17 and index ~54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1      2   3\n",
      "100  16.0   96.0    NaN NaN\n",
      "101  16.0    NaN    NaN NaN\n",
      "102  17.0    NaN    NaN NaN\n",
      "103  17.0    NaN    NaN NaN\n",
      "104  17.0    NaN    NaN NaN\n",
      "105  17.0    NaN    NaN NaN\n",
      "106  17.0    NaN    NaN NaN\n",
      "107  17.0    NaN    NaN NaN\n",
      "108  17.0    NaN    NaN NaN\n",
      "109  17.0    NaN    NaN NaN\n",
      "110  17.0    NaN    NaN NaN\n",
      "111  17.0    NaN    NaN NaN\n",
      "112  16.0    NaN    NaN NaN\n",
      "113  17.0    NaN    NaN NaN\n",
      "114  17.0    NaN    NaN NaN\n",
      "115  17.0  114.0    NaN NaN\n",
      "116  17.0    NaN    NaN NaN\n",
      "117  17.0    NaN    NaN NaN\n",
      "118  17.0  111.0    NaN NaN\n",
      "119  17.0    NaN    NaN NaN\n",
      "120  17.0    NaN    NaN NaN\n",
      "121  17.0    NaN    NaN NaN\n",
      "122  17.0    NaN    NaN NaN\n",
      "123  17.0    NaN    NaN NaN\n",
      "124  16.0    NaN    NaN NaN\n",
      "125  17.0    NaN    NaN NaN\n",
      "126  17.0    NaN    NaN NaN\n",
      "127  17.0    NaN    NaN NaN\n",
      "128  17.0    NaN    NaN NaN\n",
      "129  17.0    NaN    NaN NaN\n",
      "..    ...    ...    ...  ..\n",
      "170  17.0   51.0    NaN NaN\n",
      "171  17.0   51.0    NaN NaN\n",
      "172  17.0   48.0    NaN NaN\n",
      "173  17.0   46.0    NaN NaN\n",
      "174  17.0   51.0    NaN NaN\n",
      "175  17.0   51.0    NaN NaN\n",
      "176  17.0   54.0    NaN NaN\n",
      "177  17.0   54.0    NaN NaN\n",
      "178  17.0   52.0    NaN NaN\n",
      "179  17.0   49.0    NaN NaN\n",
      "180  17.0   50.0    NaN NaN\n",
      "181  17.0   51.0    NaN NaN\n",
      "182  17.0   49.0    NaN NaN\n",
      "183  17.0   52.0    NaN NaN\n",
      "184  17.0   52.0    NaN NaN\n",
      "185  17.0   51.0    NaN NaN\n",
      "186  19.0   47.0    NaN NaN\n",
      "187  18.0   51.0    NaN NaN\n",
      "188  16.0   50.0    NaN NaN\n",
      "189  17.0   55.0    NaN NaN\n",
      "190  17.0   51.0    NaN NaN\n",
      "191  17.0   55.0  125.0 NaN\n",
      "192  18.0   53.0    NaN NaN\n",
      "193  18.0   54.0    NaN NaN\n",
      "194  18.0   55.0    NaN NaN\n",
      "195  18.0   54.0    NaN NaN\n",
      "196  17.0   51.0    NaN NaN\n",
      "197  17.0   52.0    NaN NaN\n",
      "198  17.0   52.0    NaN NaN\n",
      "199  19.0   54.0    NaN NaN\n",
      "\n",
      "[100 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print (idx[100:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_output = peak_classify.data_grouping(idx, height, fwhm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_dict = peak_classify.cluster_classifier(idx, corrected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here, after clustering, there is only one peak left... :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'peak_0': [], 'peak_1': [], 'peak_2': [Position     51.000000\n",
       "  Height       -0.001273\n",
       "  Width       148.110000\n",
       "  Time        196.000000\n",
       "  Name: 785, dtype: float64], 'peak_3': []}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peak_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
